---
title: "Java面试八股文 - 完整版"
date: 2025-12-24T13:00:00+08:00
draft: false                    
tags: ["Java", "八股"]  
categories: ["技术干货"]
---

# 黑马八股



## 准备篇

必要技术 + 其他技术 （写的就必须能聊）

必要技术：**Spring Boot + SSM + Redis  数据库**



引导面试官问：

WRONG: 熟练使用Redis等非关系型数据库

RIGHT: 精通Redis，深入理解Redis线程模型以及Redis的核心数据结构和使用场景，熟悉多级缓存架构，比如: **缓存雪崩、穿透、击穿、双写一致、缓存失效**等；自主搭建过**Redis高可用集群**。



项目描述： 主导设计模块开发、展示指标数据



深入学习项目：通用模块、功能实现、常见问题、系统设计 



面试流程：自我介绍、项目介绍、具体的模块（业务深度、技术实现）



## Redis 篇



使用场景

- 缓存：穿透、击穿、雪崩；双写一致、持久化；数据过期、淘汰策略。
- 分布式锁：setnv、redisson
- 计数器：redis的 incr 命令实现
- 保存 token（数据类型：String）
- 消息队列（数据类型：List, S）
- 延迟队列（数据类型：Zset）





# JavaGuide



##  Java 基础



### 基础知识

面向对象（封装，继承，多态）



**JDK > JRE > JVM > JIT**

**JDK 包含了开发 Java 程序所需的一切工具和库，而 JRE 则只提供了运行 Java 程序所需的最小环境。**



.java -> javac 编译 -> .class -> 热点代码？-> (yes 解释器) (no JIT) -> 机器



编译型：一次性翻译成机器码，C, C++, GO；解释性：一句一句翻译，Python, JavaScript

Java 编译与解释并存：先编译、后解释。

**AOT(Ahead of Time Compilation)** ：程序被执行前就将其编译成机器码

AOT 更适合当下的云原生场景，对微服务架构的支持也比较友好。除此之外，AOT 编译无法支持 Java 的一些动态特性，如反射、动态代理、动态加载、JNI（Java Native Interface）等。然而，很多框架和库（如 Spring、CGLIB）都用到了这些特性。



Oracle JDK 就是优化版的 Open JDK，但是不开源，收费。



移位操作符：`<<` :左移运算符，`>>` :带符号右移，`>>>` :无符号右移

实际上支持的类型只有`int`和`long`



Java 里使用 `long` 类型的数据一定要在数值后面加上 **L**，否则将作为整型解析。

`char a = 'h'`char :单引号，`String a = "hello"` :双引号。



包装类型的缓存机制是指对于某些范围内的基本数据类型的包装类型，Java使用了一个缓存对象池，以节省内存和提高性能。

`Byte`,`Short`,`Integer`,`Long` 这 4 种包装类默认创建了数值 **[-128，127]** 的相应类型的缓存数据

**所有整型包装类对象之间值的比较，全部使用 equals 方法比较**。



**什么是自动拆装箱？**

- **装箱**：将基本数据类型自动转换为对应的包装类型
- **拆箱**：将包装类型自动转换为对应的基本数据类型



**重载**就是同一个类中多个同名方法根据不同的传参来执行不同的逻辑处理。

**重写**就是子类对父类方法的重新改造，外部样子不能改变，内部逻辑可以改变。



- **面向对象编程（OOP）**：以对象为中心，将程序分解为多个对象，每个对象包含数据（属性）和操作数据的方法（行为）。强调封装、继承和多态等概念，使得代码更加模块化、可重用性更高。
- **面向过程编程（POP）**：以过程或函数为中心，将程序分解为一系列的函数，按照执行顺序依次调用这些函数完成任务。强调对问题的分解和解决方案的逐步求精。



构造方法

构造方法是面向对象编程中的一个特殊方法，用于创建和初始化对象。它通常在对象被实例化时被调用，用来初始化对象的状态。

在大多数面向对象的编程语言中，构造方法的名称通常与类名相同，并且没有返回类型。它的作用是初始化对象的各种属性，确保对象在创建后处于一个合适的状态。

**构造方法的特点包括：**

1. **命名和语法**：构造方法通常与类同名，没有返回类型，并且在对象被实例化时自动调用。
2. **初始化对象状态**：构造方法用于初始化对象的属性，确保对象被创建后处于一个可用的状态。
3. **重载**：有些编程语言支持构造方法的重载，允许定义多个不同参数列表的构造方法，以满足不同的创建对象的需求。
4. **默认构造方法**：如果没有显式定义构造方法，编程语言通常会提供一个默认的构造方法，用于创建对象。

示例：

```java
public class Person {
    private String name;
    private int age;

    // 构造方法
    public Person(String name, int age) {
        this.name = name;
        this.age = age;
    }

    // 获取姓名
    public String getName() {
        return name;
    }

    // 获取年龄
    public int getAge() {
        return age;
    }

    public static void main(String[] args) {
        // 创建对象时调用构造方法进行初始化
        Person person = new Person("Alice", 30);
        System.out.println("Name: " + person.getName());
        System.out.println("Age: " + person.getAge());
    }
}
```

在上面的示例中，`Person` 类有一个构造方法，它接受姓名和年龄作为参数，并在对象被实例化时用这些参数初始化对象的属性。



面向对象编程(OOP)的三大特征是**封装、继承和多态**。

1. **封装（Encapsulation）：**封装是指将数据（属性）和行为（方法）封装在一个单元中，以防止外部对其直接访问和修改。通过封装，对象的内部细节被隐藏起来，只暴露出公共接口，使得对象的使用者无需了解其内部实现细节，从而提高了代码的**安全性**和**可维护性**。
2. **继承（Inheritance）：**继承是指一个类（子类）可以基于另一个类（父类）的定义来创建自己的定义，并且可以继承父类的属性和方法。通过继承，子类可以重用父类的代码，同时可以在不修改父类的情况下扩展或修改其行为，提高了代码的**重用性**和**扩展性**。
3. **多态（Polymorphism）：**多态是指同一个方法名可以在不同的类中具有不同的实现方式，使得程序可以根据对象的实际类型来调用相应的方法。多态性可以通过继承和接口实现，它可以提高代码的**灵活性**和**可扩展性**，使得代码更加通用和易于维护。



继承是实现多态的一种手段，但并不是唯一的手段，接口也可以实现多态性。继承更强调类之间的层次关系和代码复用，而多态更强调同一个方法名在不同类中的不同实现方式。

``` java
// 封装
class EncapsulationExample {
    private int num;

    public int getNum() {
        return num;
    }

    public void setNum(int num) {
        this.num = num;
    }
}


// 继承

// 父类
class Animal {
    String name;

    // 父类构造函数
    public Animal(String name) {
        this.name = name;
    }

    // 父类方法
    void eat() {
        System.out.println(name + " is eating");
    }
}

// 子类
class Dog extends Animal {
    // 子类构造函数
    public Dog(String name) {
        // 调用父类构造函数
        super(name);
    }

    // 子类方法，重写了父类方法
    @Override
    void eat() {
        System.out.println(name + " is eating bones");
    }

    // 子类特有方法
    void bark() {
        System.out.println(name + " is barking");
    }
}

public class InheritanceExample {
    public static void main(String[] args) {
        // 创建父类对象
        Animal animal = new Animal("Generic Animal");
        // 调用父类方法
        animal.eat();

        // 创建子类对象
        Dog dog = new Dog("Buddy");
        // 调用子类方法
        dog.eat();  // 调用子类重写的方法
        dog.bark(); // 调用子类特有方法
    }
}

// 多态
class Animal {
    void makeSound() {
        System.out.println("Animal makes a sound");
    }
}

//子类继承父类
class Dog extends Animal {
    @Override
    void makeSound() {  // 子类重写父类方法
        System.out.println("Dog barks");
    }
}

class Cat extends Animal {
    @Override
    void makeSound() {
        System.out.println("Cat meows");
    }
}

public class PolymorphismExample {
    public static void main(String[] args) {
        Animal dog = new Dog();  // 父类引用指向子类对象
        Animal cat = new Cat();

        dog.makeSound(); // Output: Dog barks
        cat.makeSound(); // Output: Cat meows
    }
}
```



**接口：**接口是一种完全抽象的类型，它只包含方法的声明而没有实现。

``` java
public interface Animal {
    void makeSound();
}

public class Dog implements Animal {
    @Override
    public void makeSound() {
        System.out.println("Woof");
    }
}
```

**抽象类：**抽象类是一个可以包含抽象方法（没有实现）和普通方法（有实现）的类，被声明为抽象的类。

``` java
public abstract class Shape {
    protected int x, y;

    // 普通方法
    public Shape(int x, int y) {
        this.x = x;
        this.y = y;
    }
	
    // 抽象方法
    public abstract void draw();
}

public class Circle extends Shape {
    private int radius;

    public Circle(int x, int y, int radius) {
        super(x, y);
        this.radius = radius;
    }

    @Override
    public void draw() {
        System.out.println("Drawing circle at (" + x + ", " + y + ") with radius " + radius);
    }
}

```



**浅拷贝**：浅拷贝会在堆上创建一个新的对象（区别于引用拷贝的一点）。如果原对象是引用类型的话会直接复制引用地址，也就是拷贝对象和原对象共用同一个内部对象。**创建一个新的对象，其中包含原始对象的所有元素的引用。**

**深拷贝**：深拷贝会完全复制整个对象，包括这个对象所包含的内部对象。**创建一个全新的对象，其中包含原始对象的所有元素的副本。**

**引用拷贝：**两个不同的引用指向同一个对象。

![浅拷贝、深拷贝、引用拷贝示意图](https://oss.javaguide.cn/github/javaguide/java/basis/shallow&deep-copy.png)



Object 类的常见方法：equals(), toString(), hashCode()



- 对于基本数据类型来说，`==` 比较的是值。
- 对于引用数据类型来说，`==` 比较的是对象的内存地址。(new)





`String` 中的 `equals` 方法是被重写过的，因为 `Object` 的 `equals` 方法是比较的对象的内存地址，而 `String` 的 `equals` 方法比较的是对象的值。

  

**基本类型**的值存储在栈内存中，直接存储数值，而不是存储对象的引用。

**引用类型**包括类（Class）、接口（Interface）、数组（Array）等，它们的值存储在堆内存中，栈内存中存储的是对象的引用（地址）。通过关键字`new`来创建对象，`new`关键字会强制在堆内存中创建新的对象。



`hashCode()`是`Object`类中定义的一个方法，它用于返回对象的哈希码值。哈希码值是根据对象的内部信息计算出来的一个整数，用于在哈希表等数据结构中快速定位对象的位置。

如果两个对象的`hashCode` 值相等，那这两个对象不一定相等（哈希碰撞）。

如果两个对象的`hashCode` 值相等并且`equals()`方法也返回 `true`，我们才认为这两个对象相等。

如果两个对象的`hashCode` 值不相等，我们就可以直接认为这两个对象不相等。



重写 equals() 时必须重写 hashCode() : 因为如果重写 equals() 时没有重写 hashCode() 方法的话就可能会导致 equals 方法判断是相等的两个对象，hashCode 值却不相等。



`String` 不可变，`StringBuffer` 和 `StringBuffer`可变。

`StringBuffer` 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。`StringBuilder` 并没有对方法进行加同步锁，所以是非线程安全的。

性能：StringBuilder > StringBuffer > String



**总结：**

1. 操作少量的数据: 适用 `String`
2. 单线程操作字符串缓冲区下操作大量数据: 适用 `StringBuilder`
3. 多线程操作字符串缓冲区下操作大量数据: 适用 `StringBuffer`



`final`关键字用于表示不可变的特性，它可以用于修饰类、方法和变量，具有不同的含义和用途。

修饰类：意味着该类不能被继承，即不能有子类。

修饰方法：意味着该方法不能被子类重写（覆盖）。

修饰变量：意味着该变量的值只能被赋值一次，之后不能再改变。



`String` 类中使用 `final` 关键字。



“+”和“+=”是专门为 String 类重载过的运算符，也是 Java 中仅有的两个重载过的运算符。

字符串对象通过“+”的字符串拼接方式，实际上是通过 `StringBuilder` 调用 `append()` 方法实现的，拼接完成之后调用 `toString()` 得到一个 `String` 对象 。

使用 “+” 进行字符串拼接会产生大量的临时对象的问题在 JDK9 中得到了解决。字符串相加 “+” 改为了用动态方法 `makeConcatWithConstants()` 来实现，而不是大量的 `StringBuilder` 了。



`String s1 = new String("abc");` 这句话创建了几个字符串对象？
会创建 1 或 2 个字符串对象。字符串常量池中已存在字符串对象的引用，则1。否者2。

``` java
String s0 = new String("123");  // 没有引用，2
// 字符串常量池中已存在字符串对象“abc”的引用
String s1 = "abc";
// 下面这段代码只会在堆中创建 1 个字符串对象“abc”
String s2 = new String("abc");  // // 有引用，1
```



`String.intern()` 是一个 native（本地）方法，其作用是将指定的字符串对象的引用保存在字符串常量池中，可以简单分为两种情况：

- 如果字符串常量池中保存了对应的字符串对象的引用，就直接返回该引用。
- 如果字符串常量池中没有保存了对应的字符串对象的引用，那就在常量池中创建一个指向该字符串对象的引用并返回。



**对于编译期可以确定值的字符串，也就是常量字符串 ，jvm 会将其存入字符串常量池。并且，字符串常量拼接得到的字符串常量在编译阶段就已经被存放字符串常量池，这个得益于编译器的优化。**

**常量折叠：**对于 `String str3 = "str" + "ing";` 编译器会给你优化成 `String str3 = "string";` 。

**引用的值在程序编译期是无法确定的，编译器无法对其进行优化。**



![Java 异常类层次结构图](https://oss.javaguide.cn/github/javaguide/java/basis/types-of-exceptions-in-java.png)

**`Exception`** :程序本身可以处理的异常，可以通过 `catch` 来进行捕获。`Exception` 又可以分为 Checked Exception (受检查异常，必须处理) 和 Unchecked Exception (不受检查异常，可以不处理)。

**`Error`**：`Error` 属于程序无法处理的错误 ，不建议通过`catch`捕获 。例如 Java 虚拟机运行错误（`Virtual MachineError`）、虚拟机内存不够错误(`OutOfMemoryError`)、类定义错误（`NoClassDefFoundError`）等 。这些异常发生时，Java 虚拟机（JVM）一般会选择**线程终止**。



**Checked Exception** 即 受检查异常 ，Java 代码在编译过程中，如果受检查异常没有被 `catch`或者`throws` 关键字处理的话，就没办法通过编译。

**Unchecked Exception** 即 **不受检查异常** ，Java 代码在编译过程中 ，我们即使不处理不受检查异常也可以正常通过编译。

`RuntimeException` 及其子类都统称为非受检查异常，常见的有（建议记下来，日常开发中会经常用到）：

- `NullPointerException`(空指针错误)

- `IllegalArgumentException`(参数错误比如方法入参类型错误)

- `ArrayIndexOutOfBoundsException`（数组越界错误）

- `ClassCastException`（类型转换错误）

  

Throwable 类**常用方法**有哪些？

- `String getMessage()`: 返回异常发生时的简要描述
- `String toString()`: 返回异常发生时的详细信息



`try`块：用于捕获异常。其后可接零个或多个 `catch` 块，如果没有 `catch` 块，则必须跟一个 `finally` 块。

`catch`块：用于处理 try 捕获到的异常。

`finally` 块：无论是否捕获或处理异常，`finally` 块里的语句**都会被执行**。当在 `try` 块或 `catch` 块中遇到 `return` 语句时，`finally` 语句块将在方法返回之前被执行。**不要在 finally 语句块中使用 return! 否者直接 return finally中的内容。**



以下 3 种特殊情况下，`finally` 块的代码不会被执行：

- finally 之前虚拟机被终止运行（`System.exit(1); // 退出码为1即为程序非正常退出，为0为正常退出` ）
- 程序所在的线程死亡。
- 关闭 CPU。



`try-with-resources` 语句是一种用于自动关闭资源的特殊语法。它用于确保在代码块结束时自动关闭实现了`AutoCloseable`接口的资源，无论代码块是正常执行完成还是因为异常而退出。这种语法可以有效地避免资源泄漏问题，并简化代码。



**Java 泛型（Generics）** 是 JDK 5 中引入的一个新特性。使用泛型参数，可以增强代码的可读性以及稳定性。

泛型一般有三种使用方式:**泛型类**、**泛型接口**、**泛型方法**。



**反射：**赋予了我们**在运行时**分析类以及执行类中方法的能力。通过反射你可以获取任意一个类的所有属性和方法，你还可以调用这些方法和属性。

缺点：增加了安全问题，性能稍微差一点。

 **注解** 、**动态代理** 的实现也用到了反射。



**`Annotation` （注解） **可以看作是一种特殊的注释，主要用于修饰类、方法或者变量，提供某些信息供程序在编译或者运行时使用。

注解只有被解析之后才会生效，**常见的解析方法** 有两种：

- **编译期直接扫描**：`@Override` 
- **运行期通过反射处理**： `@Value`、`@Component`



SPI 即 Service Provider Interface ，字面意思就是：“服务提供者的接口”，我的理解是：专门提供给服务提供者或者扩展框架功能的开发者去使用的一个接口。

API是实现方提供接口和实现。

SPI是调用方确定接口规则，实现方然后实现。

![img](https://oss.javaguide.cn/github/javaguide/java/basis/spi/1ebd1df862c34880bc26b9d494535b3dtplv-k3u1fbpfcp-watermark.png)

**SPI 的优缺点：**

优点：大大地提高接口设计的灵活性。

缺点：

- 需要遍历加载所有的实现类，不能做到按需加载，这样效率还是相对较低的。
- 当多个 `ServiceLoader` 同时 `load` 时，会有并发问题。



- **序列化**：将数据结构或对象转换成二进制字节流的过程
- **反序列化**：将在序列化过程中所生成的二进制字节流转换成数据结构或者对象的过程

序列化和反序列化常见应用场景：对象在网络传输、存储到文件、存储到数据库、存储到内存。

**序列化的主要目的是通过网络传输对象或者说是将对象存储到文件系统、数据库、内存中。**

属于 OSI 七层协议中的表示层，对应 TCP/IP 协议的应用层。

TCP/IP 四层模型是：网络接口层（比特）、网络层（数据帧）、传输层（数据包）、应用层（数据段）。

![TCP/IP 四层模型](https://oss.javaguide.cn/github/javaguide/cs-basics/network/tcp-ip-4-model.png)



对于不想进行序列化的变量，使用 `transient` 关键字修饰。它只能修饰变量，且在反序列化后会被设置成默认值。



IO 流在 Java 中分为输入流和输出流，而根据数据的处理方式又分为字节流和字符流。

- `InputStream`/`Reader`: 所有输入流的基类，前者是字节输入流，后者是字符输入流。
- `OutputStream`/`Writer`: 所有输出流的基类，前者是字节输出流，后者是字符输出流。

为什么要分为字节流和字符流呢？这是因为在处理数据时，有时候需要考虑数据的语义和编码方式。对于文本数据，字符流更适合，因为它能够正确地处理字符编码、字符集和换行符等文本特性。而对于二进制数据或者与硬件设备进行交互时，字节流更适合，因为它可以直接操作字节数据，不需要考虑字符编码和字符集的问题。

Java将I/O流分为字节流和字符流，以便程序员根据实际情况选择合适的流来处理不同类型的数据。



**语法糖（Syntactic sugar）** 代指的是编程语言为了方便程序员开发程序而设计的一种特殊语法，这种语法对编程语言的功能并没有影响。实现相同的功能，基于语法糖写出来的代码往往更简单简洁且更易阅读。**Java 中真正支持语法糖的是 Java 编译器而不是 JVM。**

Java 中的 `for-each` 就是一个常用的语法糖，其原理其实就是基于普通的 for 循环和迭代器。

``` java
String[] strs = {"JavaGuide", "公众号：JavaGuide", "博客：https://javaguide.cn/"};
for (String s : strs) {
    System.out.println(s);
}
```

Java 中最常用的语法糖主要有泛型、自动拆装箱、变长参数、枚举、内部类、增强 for 循环、try-with-resources 语法、lambda 表达式等。



### 重要知识点



#### 值传递

- **实参（实际参数，Arguments）**：用于传递给函数/方法的参数，必须有确定的值。
- **形参（形式参数，Parameters）**：用于定义函数/方法，接收实参，不需要有确定的值。

``` java 
String hello = "Hello!";
// hello 为实参
sayHello(hello);
// str 为形参
void sayHello(String str) {
    System.out.println(str);
}
```

- **值传递**：方法接收的是实参值的拷贝，会创建副本。(在 Java 中只有值传递。)
- **引用传递**：方法接收的直接是实参所引用的对象在堆中的地址，不会创建副本，对形参的修改将影响到实参。

Java 中将实参传递给方法（或函数）的方式是 **值传递**：

- 如果参数是基本类型的话，很简单，传递的就是基本类型的字面量值的拷贝，会创建副本。
- 如果参数是引用类型，传递的就是实参所引用的对象在堆中地址值的拷贝，同样也会创建副本。



#### 序列化

- **序列化**：将数据结构或对象转换成二进制字节流的过程
- **反序列化**：将在序列化过程中所生成的二进制字节流转换成数据结构或者对象的过程

序列化和反序列化常见应用场景：对象在网络传输、存储到文件、存储到数据库、存储到内存。

**序列化的主要目的是通过网络传输对象或者说是将对象存储到文件系统、数据库、内存中。**

属于 OSI 七层协议中的表示层，对应 TCP/IP 协议的应用层。

TCP/IP 四层模型是：网络接口层（比特）、网络层（数据帧）、传输层（数据包）、应用层（数据段）。

![TCP/IP 四层模型](https://oss.javaguide.cn/github/javaguide/cs-basics/network/tcp-ip-4-model.png)



对于不想进行序列化的变量，使用 `transient` 关键字修饰。它只能修饰变量，且在反序列化后会被设置成默认值。

**不推荐使用 JDK 自带的序列化：**不支持跨语言调用、性能差、存在安全问题

Kryo 是专门针对 Java 语言序列化方式并且性能非常好，如果你的应用是专门针对 Java 语言的话可以考虑使用。

Dubbo(读音[ˈdʌbəʊ])是阿里巴巴公司开源的一个高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring 框架无缝集成。Dubbo是一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。



#### 反射 invoke

反射之所以被称为框架的灵魂，主要是因为它赋予了我们**在运行时分析类以及执行类中方法的能力。**

通过反射你可以获取任意一个类的所有属性和方法，你还可以调用这些方法和属性。

正是因为反射，你才能这么轻松地使用各种框架。像 Spring/Spring Boot、MyBatis 等等框架中都大量使用了反射机制。

**动态代理和注解的实现也依赖反射。**

**动态代理**提供了一种灵活且非侵入式的方式，可以对对象的行为进行定制和扩展。



#### 代理模式

**我们使用代理对象来代替对真实对象(real object)的访问，这样就可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能。**

**代理模式的主要作用是扩展目标对象的功能，比如说在目标对象的某个方法执行前后你可以增加一些自定义的操作。**

**静态代理：**我们对目标对象的每个方法的增强都是手动完成的，非常不灵活且麻烦。从 JVM 层面来说， **静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。**



**动态代理：**我们不需要针对每个目标类都单独创建一个代理类，并且也不需要我们必须实现接口，我们可以直接代理实现类。**从 JVM 角度来说，动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。**

**在 Java 动态代理机制中 `InvocationHandler` 接口和 `Proxy` 类是核心。**



**动态代理类使用步骤：**

1. 定义一个接口及其实现类；
2. 自定义 `InvocationHandler` 并重写`invoke`方法，在 `invoke` 方法中我们会调用原生方法（被代理类的方法）并自定义一些处理逻辑；
3. 通过 `Proxy.newProxyInstance(ClassLoader loader,Class<?>[] interfaces,InvocationHandler h)` 方法创建代理对象；



**JDK 动态代理有一个最致命的问题是其只能代理实现了接口的类。**

**为了解决这个问题，我们可以用 CGLIB (Code Generation Library)动态代理机制来避免，需要引入对应的依赖。**

**在 CGLIB 动态代理机制中 `MethodInterceptor` 接口和 `Enhancer` 类是核心。**



**静态代理和动态代理的对比**

1. **灵活性**：动态代理更加灵活，不需要必须实现接口，可以直接代理实现类，并且可以不需要针对每个目标类都创建一个代理类。另外，静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改，这是非常麻烦的！
2. **JVM 层面**：静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。而动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。



#### BigDecimal

**创建：**`BigDecimal(String val)`构造方法或者 `BigDecimal.valueOf(double val)` 静态方法来创建对象。

``` java
BigDecimal g = new BigDecimal(0.1F);  // 不好，存在精度丢失
BigDecimal recommand1 = new BigDecimal("0.1");  // 推荐方法，其实用到了 Double 的 toString
BigDecimal recommand2 = BigDecimal.valueOf(0.1);  // 按Double实际能表达精度对尾数截断
```

比较大小用`compareTo()`，这是因为 `equals()` 方法不仅仅会比较值的大小（value）还会比较精度（scale），而 `compareTo()` 方法比较的时候会忽略精度。



#### Unsafe

`Unsafe` 是位于 `sun.misc` 包下的一个类，主要提供一些用于执行低级别、不安全操作的方法。`Unsafe` 提供的这些功能的实现需要依赖本地方法（Native Method）。

**为什么要使用本地方法 native method 呢？**

1. 需要用到 Java 中不具备的依赖于操作系统的特性，Java 在实现跨平台的同时要实现对底层的控制，需要借助其他语言发挥作用。
2. 对于其他语言已经完成的一些现成功能，可以使用 Java 直接调用。
3. 程序对时间敏感或对性能要求非常高时，有必要使用更加底层的语言，例如 C/C++甚至是汇编。

`Unsafe` 类实现功能可以被分为下面 8 类：

1. 内存操作
2. 内存屏障
3. 对象操作
4. 数据操作
5. CAS 操作
6. 线程调度
7. Class 操作
8. 系统信息



#### SPI机制详解

Java SPI 就是提供了这样一个机制：**为某个接口寻找服务实现的机制。这有点类似 IoC 的思想，将装配的控制权移交到了程序之外。**

SPI 即 Service Provider Interface ，字面意思就是：“服务提供者的接口”，我的理解是：专门提供给服务提供者或者扩展框架功能的开发者去使用的一个接口。对应API

SLF4J （Simple Logging Facade for Java）是 Java 的一个日志门面（接口），其具体实现有几种，比如：Logback、Log4j、Log4j2 等等，而且还可以切换，在切换日志具体实现的时候我们是不需要更改项目代码的，只需要在 Maven 依赖里面修改一些 pom 依赖就好。

SPI 机制的具体实现本质上还是通过反射完成的。即：**我们按照规定将要暴露对外使用的具体实现类在 `META-INF/services/` 文件下声明。**

通过 SPI 机制能够大大地提高接口设计的灵活性，但是 SPI 机制也存在一些缺点，比如：

1. 遍历加载所有的实现类，这样效率还是相对较低的；
2. 当多个 `ServiceLoader` 同时 `load` 时，会有并发问题。



#### 语法糖

语法糖让程序更加简洁，有更高的可读性。

Java 虚拟机并不支持这些语法糖。这些语法糖在**编译阶段**就会被还原成简单的基础语法结构，这个过程就是解语法糖。（`javac`）

常见的语法糖：

- Switch支持String与枚举

- 泛型
  - 类型擦除的主要过程如下：1.将所有的泛型参数用其最左边界（最顶级的父类型）类型替换。 2.移除所有的类型参数。
  - **坑：**`List<Integer> list`和`List<Stirng> list`在重载时类型擦除变得一模一样；无法用在catch语句中；泛型的静态变量共享

- 自动装箱与拆箱
  - 自动装箱就是 Java 自动将原始类型值转换成对应的对象，比如将 int 的变量转换成 Integer 对象，这个过程叫做装箱valueOf(int)，反之将 Integer 对象转换成 int 类型值，这个过程叫做拆箱intValue()。
  - **坑：**自动装箱Integer在-128 至 +127范围内有缓存，值相等；超出范围值不等。

- 可变长参数

  - ```java
    public static transient void print(String... strs) {}  // 创建数组 String strs[]
    ```

- 枚举

  - 关键字`enum`可以将一组具名的值的有限集合创建为一种新的类型

  - **枚举类型不能被继承**

  - ``` java
    enum Day {
        SUNDAY, MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY
    }  // 枚举的定义
    ```

- 内部类

  - **内部类的名字完全可以和它的外部类名字相同**，因为一旦编译成功，**就会生成两个完全不同的`.class`文件了，分别是`outer.class`和`outer$inner.class`。**当尝试对`outer.class`反编译时，会把两个文件一起进行反编译。

- 条件编译

  - **根据 if 判断条件的真假，编译器直接把分支为 false 的代码块消除。**有总比没有强，虽然只能在方法体内实现。

- 断言

  - **其实断言的底层实现就是 if 语言，如果断言结果为 true，则什么都不做，程序继续执行，如果断言结果为 false，则程序抛出 AssertError 来打断程序的执行。**

- 数值字面量

  - 整数和浮点数都允许在数字之间插入任意多个下划线，方便阅读。

- for-each

  - **for-each 的实现原理其实就是使用了普通的 for 循环和迭代器。**
  - **坑：**不能remove()，需要使用`Iterator.remove()`

- try-with-resource

  - ``` java
    //我们没有做的关闭资源的操作，编译器都帮我们做了。
    try (BufferedReader br = new BufferedReader(new FileReader("d:\\ hollischuang.xml"))) { } catch () {} 
    ```

- lambda 表达式

  - **Lambda 表达式不是匿名内部类的语法糖，但是他也是一个语法糖。实现方式其实是依赖了几个 JVM 底层提供的 lambda 相关 api。**



## 集合 Collection



### 基础知识

![Java 集合框架概览](https://oss.javaguide.cn/github/javaguide/java/collection/java-collection-hierarchy.png)



List, Set, Queue, Map 四者的区别？

- `List`(对付顺序的好帮手): 存储的元素是有序的、可重复的。
- `Set`(注重独一无二的性质): 存储的元素不可重复的。
- `Queue`(实现排队功能的叫号机): 按特定的排队规则来确定先后顺序，存储的元素是有序的、可重复的。
- `Map`(用 key 来搜索的专家): 使用键值对（key-value）存储，类似于数学上的函数 y=f(x)，"x" 代表 key，"y" 代表 value，key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。



ArrayList 动态数组，Array数组

ArrayList 数组存储（Object 数组），LinkedList 链表存储（双向链表）



**HashMap的底层实现：**

**JDK1.8之前：**

HashMap 通过 key 的 `hashcode` 经过扰动函数处理过后得到 hash 值，然后通过 `(n - 1) & hash` 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过**拉链法**解决冲突。

所谓 **“拉链法”** 就是：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。

![jdk1.8 之前的内部结构-HashMap](https://oss.javaguide.cn/github/javaguide/java/collection/jdk1.7_hashmap.png)

**JDK1.8之后：**

相比于之前的版本， JDK1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。

![jdk1.8之后的内部结构-HashMap](https://oss.javaguide.cn/github/javaguide/java/collection/jdk1.8_hashmap.png)

红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。



**“取余(%)操作中如果除数是 2 的幂次则等价于与其除数减一的与(&)操作（也就是说 hash%length==hash&(length-1)的前提是 length 是 2 的 n 次方；）。”** 并且采用二进制位操作 &，相对于%能够提高运算效率，这就解释了 **HashMap 的长度为什么是 2 的幂次方。**

``` java
// 高位也就是2的n次方中的 n 位
1101 % 0100 = 0001  // 高位不用管，后面的就是余数
1101 & 0011 = 0001  // 与操作，结果就是hash的地位
```



`HashMap` 在JDK 1.8之前的版本用的是头插法，之后用的是**尾插法**，避免了环形结构。但还是建议在多线程操作下使用。推荐使用`ConcurrentHashMap`。



### 集合注意事项



**判断所有集合内部的元素是否为空，使用 `isEmpty()` 方法，而不是 `size()==0` 的方式。**



**在使用 `java.util.stream.Collectors` 类的 `toMap()` 方法转为 `Map` 集合时，一定要注意当 value 为 null 时会抛 NPE 异常。**`tomap()`调用了`merge()` ，`merge()`会先调用`Object.requireNonNull()`判空。



**不要在 foreach 循环里进行元素的 `remove/add` 操作。remove 元素请使用 `Iterator` 方式，如果并发操作，需要对 `Iterator` 对象加锁。**fail-fast 机制：多个线程对 fail-fast 集合进行修改的时候，可能会抛出`ConcurrentModificationException`。



**可以利用 `Set` 元素唯一的特性，可以快速对一个集合进行去重操作，避免使用 `List` 的 `contains()` 进行遍历去重或者判断包含操作。**一个 `O(n)`， 一个 `O(1)`



**使用集合转数组的方法，必须使用集合的 `toArray(T[] array)`，传入的是类型完全一致、长度为 0 的空数组。**

**使用工具类 `Arrays.asList()` 把数组转换成集合时，不能使用其修改集合相关的方法， 它的 `add/remove/clear` 方法会抛出 `UnsupportedOperationException` 异常。**

**1、`Arrays.asList()`是泛型方法，传递的数组必须是对象数组，而不是基本类型。**

``` java
int[] myArray = {1, 2, 3};  // 不正确
Integer[] myArray = {1, 2, 3};  // 正确,但仍不是正确将数组转换成集合的方式
List myList = Arrays.asList(myArray);  // 此时myList.size() = 1
List<Integer> myList = Arrays.stream(myArray).collect(Collectors.toList());  // 数组转集合的正确方式，myList.size() = 3
```

**2、使用集合的修改方法: `add()`、`remove()`、`clear()`会抛出异常。**

`Arrays.asList()` 方法返回的并不是 `java.util.ArrayList` ，而是 `java.util.Arrays` 的一个内部类,这个内部类并没有实现集合的修改方法或者说并没有重写这些方法。



### 源码分析



#### ArrayList

`ArrayList` 的底层是数组队列，相当于动态数组。不保证线程安全。



**`int newCapacity = oldCapacity + (oldCapacity >> 1)`,所以 ArrayList 每次扩容之后容量都会变为原来的 1.5 倍左右（oldCapacity 为偶数就是 1.5 倍，否则是 1.5 倍左右）！**



**ArrayList 与 LinkedList 区别：**

- **是否保证线程安全：** `ArrayList` 和 `LinkedList` 都是不同步的，也就是不保证线程安全；
- **底层数据结构：** `ArrayList` 底层使用的是 **`Object` 数组**；`LinkedList` 底层使用的是 **双向链表** 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！）
- 插入和删除是否受元素位置的影响：
  - `ArrayList` 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行`add(E e)`方法的时候， `ArrayList` 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（`add(int index, E element)`），时间复杂度就为 O(n)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。
  - `LinkedList` 采用链表存储，所以在头尾插入或者删除元素不受元素位置的影响（`add(E e)`、`addFirst(E e)`、`addLast(E e)`、`removeFirst()`、 `removeLast()`），时间复杂度为 O(1)，如果是要在指定位置 `i` 插入和删除元素的话（`add(int index, E element)`，`remove(Object o)`,`remove(int index)`）， 时间复杂度为 O(n) ，因为需要先移动到指定位置再插入和删除。
- **是否支持快速随机访问：** `LinkedList` 不支持高效的随机元素访问，而 `ArrayList`（实现了 `RandomAccess` 接口） 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于`get(int index)`方法)。
- **内存空间占用：** `ArrayList` 的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）



#### LinkedList



`LinkedList` 是一个基于双向链表实现的集合类，经常被拿来和 `ArrayList` 做比较。

不过，我们在项目中一般是不会使用到 `LinkedList` 的，需要用到 `LinkedList` 的场景几乎都可以使用 `ArrayList` 来代替，并且，性能通常会更好！



#### HashMap



HashMap 主要用来存放键值对，它基于哈希表的 Map 接口实现，是常用的 Java 集合之一，是非线程安全的。

`HashMap` 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个。



**HashMap的底层实现：**

**JDK1.8之前：**

HashMap 通过 key 的 `hashcode` 经过扰动函数处理过后得到 hash 值，然后通过 `(n - 1) & hash` 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过**拉链法**解决冲突。

所谓 **“拉链法”** 就是：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。

![jdk1.8 之前的内部结构-HashMap](https://oss.javaguide.cn/github/javaguide/java/collection/jdk1.7_hashmap.png)

**JDK1.8之后：**

相比于之前的版本， JDK1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。

![jdk1.8之后的内部结构-HashMap](https://oss.javaguide.cn/github/javaguide/java/collection/jdk1.8_hashmap.png)

红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。



**“取余(%)操作中如果除数是 2 的幂次则等价于与其除数减一的与(&)操作（也就是说 hash%length==hash&(length-1)的前提是 length 是 2 的 n 次方；）。”** 并且 **采用二进制位操作 &，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是 2 的幂次方。

``` java
// 高位也就是2的n次方中的 n 位
1101 % 0100 = 0001  // 高位不用管，后面的就是余数
1101 & 0011 = 0001  // 与操作，结果就是hash的地位
```



`HashMap` 在JDK 1.8之前的版本用的是头插法，之后用的是**尾插法**，避免了环形结构。但还是建议在多线程操作下使用。推荐使用`ConcurrentHashMap`。



## 并发编程



### 基础知识



进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。

线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的**堆**和**方法区**资源，但每个线程有自己的**程序计数器**、**虚拟机栈**和**本地方法栈**，所以系统在产生一个线程，或是在各个线程之间做切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。



**一个 Java 程序的运行是 main 线程和多个其他线程同时运行**。



**现在的 Java 线程的本质其实就是操作系统的线程**。



- 用户线程：由用户空间程序管理和调度的线程，运行在用户空间（专门给应用程序使用）。
- 内核线程：由操作系统内核管理和调度的线程，运行在内核空间（只有内核程序可以访问）。



线程模型是用户线程和内核线程之间的关联方式，常见的线程模型有这三种：

1. 一对一（一个用户线程对应一个内核线程）
2. 多对一（多个用户线程映射到一个内核线程）
3. 多对多（多个用户线程映射到多个内核线程）

在 Windows 和 Linux 等主流操作系统中，Java 线程采用的是一对一的线程模型。

![常见的三种线程模型](https://oss.javaguide.cn/github/javaguide/java/concurrent/three-types-of-thread-models.png)



 **总结：线程是进程划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。**



为什么 **程序计数器**、**虚拟机栈**和**本地方法栈** 是线程私有的呢？

程序计数器私有主要是为了**线程切换后能恢复到正确的执行位置**。

为了**保证线程中的局部变量不被别的线程访问到**，虚拟机栈和本地方法栈是线程私有的。



- **并发（Parallel）**：两个及两个以上的作业在同一 **时间段** 内执行。
- **并行（Concurrent）**：两个及两个以上的作业在同一 **时刻** 执行。

最关键的点是：是否是 **同时** 执行。



- **同步**：发出一个调用之后，在没有得到结果之前， 该调用就不可以返回，一直等待。
- **异步**：调用在发出之后，不用等待返回结果，该调用直接返回。



线程安全指的是在多线程环境下，对于同一份数据，不管有多少个线程同时访问，都能保证这份数据的正确性和一致性。

线程不安全则表示在多线程环境下，对于同一份数据，多个线程同时访问时可能会导致数据混乱、错误或者丢失



对于单核 CPU 来说，如果任务是 CPU 密集型的，那么开很多线程会影响效率；如果任务是 IO 密集型的，那么开很多线程会提高效率。当然，这里的“很多”也要适度，不能超过系统能够承受的上限。



严格来说，Java 就只有一种方式可以创建线程，那就是通过`new Thread().start()`创建。不管是哪种方式，最终还是依赖于`new Thread().start()`。



Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态：

- NEW: 初始状态，线程被创建出来但没有被调用 `start()` 。
- RUNNABLE: 运行状态，线程被调用了 `start()`等待运行的状态。（包括running和ready，不区分是因为线程切换快。）
- BLOCKED：阻塞状态，需要等待锁释放。
- WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。
- TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。
- TERMINATED：终止状态，表示该线程已经运行完毕。



线程在执行过程中会有自己的运行条件和状态（也称上下文）。线程切换意味着需要保存当前线程的上下文，留待线程下次占用 CPU 的时候恢复现场。并加载下一个将要占用 CPU 的线程上下文。这就是所谓的 **上下文切换**。



产生死锁的四个必要条件：

1. 互斥条件：该资源任意一个时刻只由一个线程占用。
2. 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
3. 不剥夺条件：线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
4. 循环等待条件：若干线程之间形成一种头尾相接的循环等待资源关系。



**如何预防死锁？** 破坏死锁的产生的必要条件即可：

1. **破坏请求与保持条件**：一次性申请所有的资源。
2. **破坏不剥夺条件**：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
3. **破坏循环等待条件**：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。



**如何避免死锁？**

避免死锁就是在资源分配时，借助于算法（比如银行家算法）对资源分配进行计算评估，使其进入安全状态。

**安全状态** 指的是系统能够按照某种线程推进顺序（P1、P2、P3……Pn）来为每个线程分配所需资源，直到满足每个线程对资源的最大需求，使每个线程都可顺利完成。称 `<P1、P2、P3.....Pn>` 序列为安全序列。



**`sleep()` 方法没有释放锁，而 `wait()` 方法释放了锁** 。两者都可以暂停线程的执行。

`wait()`不定义在`Thread`中，`sleep()`定义在`Thread`中



**调用 `start()` 方法方可启动线程并使线程进入就绪状态，直接执行 `run()` 方法的话不会以多线程的方式执行。**



`volatile` 关键字通常用于**多线程编程中标记共享变量**

`volatile` 关键字可以保证变量的可见性，如果我们将变量声明为 **`volatile`** ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。

`volatile` 关键字**能保证数据的可见性，但不能保证数据的原子性**。`synchronized` 关键字两者都能保证。

**在 Java 中，`volatile` 关键字除了可以保证变量的可见性，还有一个重要的作用就是防止 JVM 的指令重排序。** 



**双重校验锁实现对象单例（线程安全）**：

``` java
public class Singleton {

    private volatile static Singleton uniqueInstance;

    private Singleton() {
    }

    public  static Singleton getUniqueInstance() {
       //先判断对象是否已经实例过，没有实例化过才进入加锁代码
        if (uniqueInstance == null) {
            //类对象加锁
            synchronized (Singleton.class) {
                if (uniqueInstance == null) {
                    uniqueInstance = new Singleton();
                }
            }
        }
        return uniqueInstance;
    }
}
```

但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1->3->2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 `getUniqueInstance`() 后发现 `uniqueInstance` 不为空，因此返回 `uniqueInstance`，但此时 `uniqueInstance` 还未被初始化。



**悲观锁：共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程**。synchronized和ReentrantLock

高并发下系统开销大，且存在死锁问题。



**乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源是否被其它线程修改。**AtomicInteger 和 LongAdder

写占比比较多时，冲突频繁发生，影响性能。

乐观锁使用版本号机制或 CAS 算法实现。后者相对更多。

版本号机制：线程读取和提交时版本号相同才会更新，否则重试。

CAS算法（**Compare And Swap**）：CAS 是一个原子操作，底层依赖于一条 CPU 的原子指令。

CAS 涉及到三个操作数：

- **V**：要更新的变量值(Var)
- **E**：预期值(Expected)
- **N**：拟写入的新值(New)

当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新。

ABA 问题是 CAS 算法最常见的问题。即当 V 的值等于 E 时，也不能说明没有其他线程修改过资源，因为可能从a改成b又改成a。

ABA 问题的解决思路是在变量前面追加上**版本号或者时间戳**。



**悲观锁通常多用于写比较多的情况（多写场景，竞争激烈）**

**乐观锁通常多用于写比较少的情况（多读场景，竞争较少）**



`synchronized` 主要解决的是多个线程之间访问资源的同步性，可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。

使用方式主要有下面 3 种：

1. 修饰实例方法
2. 修饰静态方法
3. 修饰代码块

**总结：**

- `synchronized` 关键字加到 `static` 静态方法和 `synchronized(class)` 代码块上都是是给 Class 类上锁；
- `synchronized` 关键字加到实例方法上是给对象实例上锁；
- 尽量不要使用 `synchronized(String a)` 因为 JVM 中，字符串常量池具有缓存功能。

**构造方法不能使用 synchronized 关键字修饰。**构造方法本身就属于线程安全的，不存在同步的构造方法一说。

`synchronized` 同步语句块的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置。

`synchronized` 修饰的方法并没有 `monitorenter` 指令和 `monitorexit` 指令，取得代之的确实是 `ACC_SYNCHRONIZED` 标识，该标识指明了该方法是一个同步方法。

**不过两者的本质都是对对象监视器 monitor 的获取。**



**synchronized 和 volatile 有什么区别？**

`synchronized` 关键字和 `volatile` 关键字是两个互补的存在，而不是对立的存在！

- `volatile` 关键字是线程同步的轻量级实现，所以 `volatile`性能肯定比`synchronized`关键字要好 。但是 `volatile` 关键字只能用于变量而 `synchronized` 关键字可以修饰方法以及代码块 。
- `volatile` 关键字能保证数据的可见性（一个线程对共享变量的修改其他线程也能看到），但不能保证数据的原子性。`synchronized` 关键字两者都能保证。
- `volatile`关键字主要用于解决变量在多个线程之间的可见性，而 `synchronized` 关键字解决的是多个线程之间访问资源的同步性。



`ReentrantLock` 实现了 `Lock` 接口，是一个可重入且独占式的锁，和 `synchronized` 关键字类似。不过，`ReentrantLock` 更灵活、更强大，增加了轮询、超时、中断、公平锁和非公平锁等高级功能。

**公平锁** : 锁被释放之后，先申请的线程先得到锁。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。

**非公平锁**：锁被释放之后，后申请的线程可能会先获取到锁，是随机或者按照其他优先级排序的。性能更好，但可能会导致某些线程永远无法获取到锁。



`synchronized` 和 `ReetrantLock` 都是可重入锁。**可重入锁** 也叫递归锁，指的是线程可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果是不可重入锁的话，就会造成死锁。

可重入锁的一个典型应用场景是线程递归调用。这种锁的主要特性是重入性，同一个线程可以多次获得该锁，而不会被自己所持有的锁所阻塞。

**synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API**



**可中断锁**：获取锁的过程中可以被中断，不需要一直等到获取锁之后 才能进行其他逻辑处理。`ReentrantLock` 就属于是可中断锁。

**不可中断锁**：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。 `synchronized` 就属于是不可中断锁。



`ReentrantReadWriteLock` 其实是两把锁，一把是 `WriteLock` (写锁)，一把是 `ReadLock`（读锁） 。读锁是共享锁，写锁是独占锁。读锁可以被同时读，可以同时被多个线程持有，而写锁最多只能同时被一个线程持有。**只有读读不互斥。**

- **共享锁**：一把锁可以被多个线程同时获得。
- **独占锁**：一把锁只能被一个线程获得。

**在线程持有读锁的情况下，该线程不能取得写锁**（因为获取写锁的时候，如果发现当前的读锁被占用，就马上获取失败，不管读锁是不是被当前线程持有）。

**在线程持有写锁的情况下，该线程可以继续获取读锁**（获取读锁时如果发现写锁被占用，只有写锁没有被当前线程占用的情况才会获取失败）。

写锁可以降级为读锁，但是读锁却不能升级为写锁。



**`ThreadLocal`类主要解决的就是让每个线程绑定自己的值，可以将`ThreadLocal`类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。**

**每个`Thread`中都具备一个`ThreadLocalMap`，而`ThreadLocalMap`可以存储以`ThreadLocal`为 key ，Object 对象为 value 的键值对。**

`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用，而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。**可能导致内存泄漏。**



![image-20240405201825802](.././assets/image-20240405201825802.png)



1. **强引用（Strong Reference）：**
   - 强引用是最常见的引用类型，也是默认的引用类型。
   - 当一个对象被一个强引用所引用时，垃圾回收器不会回收该对象，即使内存不足时也不会回收，直到该对象没有任何强引用指向它时，才会被回收。
2. **弱引用（Weak Reference）：**
   - 弱引用是一种比较弱的引用类型，它不会阻止对象被垃圾回收器回收。
   - 当一个对象只被弱引用所引用时，垃圾回收器会在下一次垃圾回收时将该对象回收，即使内存充足也会回收。
   - 弱引用通常用于建立缓存或映射表等数据结构，当对象不再被其他强引用引用时，就可以自动清理这些无用的缓存项。



**线程池**就是管理一系列线程的资源池。当有任务要处理时，直接从线程池中获取线程来处理，处理完之后线程并不会立即被销毁，而是等待下一个任务。

**使用线程池的好处**：

1. **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。

2. **提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。

3. **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。



**池化技术是一种常见的资源管理技术，它旨在通过预先分配和重复使用资源，来提高系统的性能和资源利用率。**在池化技术中，资源被预先创建并放置在一个池中，当需要使用资源时，不是直接创建新的资源，而是从池中获取已有的资源。使用完毕后，资源不被销毁，而是放回到池中以便后续重复利用。这样可以避免频繁地创建和销毁资源，提高了系统的性能和响应速度，减少了资源的浪费。



**线程池创建方式：**

1. **通过`ThreadPoolExecutor`构造函数来创建（推荐）。**
2. **通过 `Executor` 框架的工具类 `Executors` 来创建。**（OOM问题）



核心参数：corePoolSize, maximumPoolSize, workQueue

**核心线程池满了，放到任务队列，任务队列满了，放到最大线程池帮忙处理。处理完空闲时间超时后销毁。**

![image-20240405204149197](.././assets/image-20240405204149197.png)



**任务从保存到再加载的过程就是一次上下文切换**。

如何设定线程池大小：

1. CPU密集型任务（N+1）
2. I/O密集型任务（2N）

动态设定更好，通过修改三个核心参数。

假如我们需要实现一个优先级任务线程池的话，那可以考虑使用 `PriorityBlockingQueue` （优先级阻塞队列）作为任务队列。



多线程中经典的 **Future 模式**，你可以将其看作是一种设计模式，核心思想是**异步调用**，主要用在多线程领域，并非 Java 语言独有。

Future的功能：取消任务；判断任务是否被取消；判断任务是否已经执行完成；获取任务执行结果。



**AQS 的全称为 `AbstractQueuedSynchronizer` ，翻译过来的意思就是抽象队列同步器。**AQS 就是一个抽象类，主要用来构建锁和同步器。

**AQS 核心思想**是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 **CLH 队列锁** 实现的，即将暂时获取不到锁的线程加入到队列中。

AQS 使用 **int 成员变量 `state` 表示同步状态**，通过内置的 **线程等待队列** 来完成获取资源线程的排队工作。



`synchronized` 和 `ReentrantLock` 都是一次只允许一个线程访问某个资源，而**`Semaphore`(信号量)**可以用来控制同时访问特定资源的线程数量。

`Semaphore` 是共享锁的一种实现，它默认构造 AQS 的 `state` 值为 `permits`，你可以将 `permits` 的值理解为许可证的数量，只有拿到许可证的线程才能执行。



**`CountDownLatch` **允许 `count` 个线程阻塞在一个地方，直至所有线程的任务都执行完毕。

`CountDownLatch` 是共享锁的一种实现,它默认构造 AQS 的 `state` 值为 `count`。

`CountDownLatch` 的作用就是 允许 count 个线程阻塞在一个地方，直至所有线程的任务都执行完毕。场景：六个无序任务，使用 count = 6 的CountDownLatch，count= 0 的时候执行后续逻辑。



`CyclicBarrier` 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是：让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。

`CyclicBarrier` 和 `CountDownLatch` 非常类似，它也可以实现线程间的技术等待，但是它的功能比 `CountDownLatch` 更加复杂和强大。主要应用场景和 `CountDownLatch` 类似。



### 乐观锁和悲观锁详解



**悲观锁：共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程**。`synchronized` 和 `ReentrantLock`

高并发下系统开销大，且存在死锁问题。



乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源是否被其它线程修改。`AtomicInteger `和 `LongAdder`

写占比比较多时，冲突频繁发生，影响性能。

乐观锁使用版本号机制或 CAS 算法实现。后者相对更多。

版本号机制：线程读取和提交时版本号相同才会更新，否则重试。

CAS算法（**Compare And Swap**）：CAS 是一个原子操作，底层依赖于一条 CPU 的原子指令。

CAS 涉及到三个操作数：

- **V**：要更新的变量值(Var)
- **E**：预期值(Expected)
- **N**：拟写入的新值(New)

当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新。

ABA 问题是 CAS 算法最常见的问题。即当 V 的值等于 E 时，也不能说明没有其他线程修改过资源，因为可能从a改成b又改成a。

ABA 问题的解决思路是在变量前面追加上**版本号或者时间戳**。



**悲观锁通常多用于写比较多的情况（多写场景，竞争激烈）**

**乐观锁通常多用于写比较少的情况（多读场景，竞争较少）**



**总结**

- 高并发的场景下，激烈的锁竞争会造成线程阻塞，大量阻塞线程会导致系统的上下文切换，增加系统的性能开销。并且，悲观锁还可能会存在死锁问题，影响代码的正常运行。乐观锁相比悲观锁来说，不存在锁竞争造成线程阻塞，也不会有死锁的问题，在性能上往往会更胜一筹。不过，如果冲突频繁发生（写占比非常多的情况），会频繁失败和重试，这样同样会非常影响性能，导致 CPU 飙升。
- 乐观锁一般会使用版本号机制或 CAS 算法实现，CAS 算法相对来说更多一些，这里需要格外注意。
- CAS 的全称是 **Compare And Swap（比较与交换）** ，用于实现乐观锁，被广泛应用于各大框架中。**CAS 的思想很简单，就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。**
- CAS 算法的问题：ABA 问题、循环时间长开销大、只能保证一个共享变量的原子操作。



### JMM（Java 内存模型）详解



JMM(Java 内存模型)主要定义了对于一个共享变量，当另一个线程对这个共享变量执行写操作后，这个线程对这个**共享变量的可见性**。



**CPU缓存模型**

**CPU Cache 缓存的是内存数据用于解决 CPU 处理速度和内存不匹配的问题，内存缓存的是硬盘数据用于解决硬盘访问速度过慢的问题。**

**CPU 为了解决内存缓存不一致性问题可以通过制定缓存一致协议（比如 MESI 协议）或者其他手段来解决。**

![image-20240406140306163](.././assets/image-20240406140306163.png)



**指令重排序**

**什么是指令重排序？** 简单来说就是系统在执行代码的时候并不一定是按照你写的代码的顺序依次执行。

常见的指令重排序有下面 2 种情况：

- **编译器优化重排**：编译器（包括 JVM、JIT 编译器等）在不改变单线程程序语义的前提下，重新安排语句的执行顺序。
- **指令并行重排**：现代处理器采用了指令级并行技术(Instruction-Level Parallelism，ILP)来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。

另外，内存系统也会有“重排序”，但又不是真正意义上的重排序。在 JMM 里表现为主存和本地内存的内容可能不一致，进而导致程序在多线程下执行可能出现问题。

Java 源代码会经历 **编译器优化重排 —> 指令并行重排 —> 内存系统重排** 的过程，最终才变成操作系统可执行的指令序列。

**指令重排序可以保证串行语义一致，但是没有义务保证多线程间的语义也一致** ，所以在多线程下，指令重排序可能会导致一些问题。





**JMM （Java Memory Model）**

Java 语言是跨平台的，它需要自己提供一套内存模型以屏蔽系统差异。

JMM 说白了就是定义了一些规范来解决这些问题，开发者可以利用这些规范更方便地开发多线程程序。对于 Java 开发者说，你不需要了解底层原理，直接使用并发相关的一些关键字和类（比如 `volatile`、`synchronized`、各种 `Lock`）即可开发出并发安全的程序。

**Java 内存模型（JMM）** 抽象了线程和主内存之间的关系，就比如说线程之间的共享变量必须存储在主内存中。

- 主内存是所有线程共享的物理存储空间，用于存储程序的数据和指令。
- 本地内存是每个线程私有的内存空间，用于存储线程的本地变量和方法调用信息。

![image-20240406141227650](.././assets/image-20240406141227650.png)



 **Java 内存区域和内存模型是完全不一样的两个东西**：



**happens-before 原则**的设计思想其实非常简单：

- 为了对编译器和处理器的约束尽可能少，只要不改变程序的执行结果（单线程程序和正确执行的多线程程序），编译器和处理器怎么进行重排序优化都行。
- 对于会改变程序执行结果的重排序，JMM 要求编译器和处理器必须禁止这种重排序。

happens-before 原则表达的意义其实并不是一个操作发生在另外一个操作的前面，虽然这从程序员的角度上来说也并无大碍。更准确地来说，它更想表达的意义是**前一个操作的结果对于后一个操作是可见的，无论这两个操作是否在同一个线程里。**



并发编程的三个重要特征：

原子性：操作要么都执行，要么都不执行。

可见性：共享变量的修改对于其他线程都是可见的。

有序性：代码的执行顺序按照编写代码时候的顺序。



### Java线程池详解

**线程池一般用于执行多个不相关联的耗时任务，没有多线程的情况下，任务顺序执行，使用了线程池的话可让多个不相关联的任务同时执行。**



`Executor` 框架是 Java5 之后引进的，在 Java 5 之后，通过 `Executor` 来启动线程比使用 `Thread` 的 `start` 方法更好，除了更易管理，效率更好（用线程池实现，节约开销）外，还有关键的一点：有助于避免 this 逃逸问题。



线程池实现类 `ThreadPoolExecutor` 是 `Executor` 框架最核心的类。

**线程池创建方式：**

1. **通过`ThreadPoolExecutor`构造函数来创建（推荐）。**
2. **通过 `Executor` 框架的工具类 `Executors` 来创建。**（OOM问题）



核心参数：corePoolSize, maximumPoolSize, workQueue

**过程原理（重要）：核心线程池满了，放到任务队列，任务队列满了，放到最大线程池帮忙处理。处理完空闲时间超时后销毁。**

![image-20240405204149197](.././assets/image-20240405204149197.png)







### Java 线程池最佳实践

**线程池必须手动通过 `ThreadPoolExecutor` 的构造函数来声明，避免使用`Executors` 类创建线程池，会有 OOM 风险。**

**使用有界队列，控制线程创建数量。**

**不同类型的业务用不同的线程池，父子任务用同一个线程池可能死锁。**

**别忘记给线程池命名，关闭线程池。尽量不要放耗时任务。**

**正确配置线程池参数：**

任务从保存到再加载的过程就是一次**上下文切换**。

如何设定线程池大小：

1. CPU密集型任务（N+1）
2. I/O密集型任务（2N）

动态设定更好，通过修改三个核心参数。

假如我们需要实现一个优先级任务线程池的话，那可以考虑使用 `PriorityBlockingQueue` （优先级阻塞队列）作为任务队列。



### Java常见并发容器总结



**`ConcurrentHashMap`** : 线程安全的 `HashMap`

**`CopyOnWriteArrayList`** : 线程安全的 `List`，在读多写少的场合性能非常好，远远好于 `Vector`。**写时复制（Copy-On-Write）** 的策略

**`ConcurrentLinkedQueue`** : 高效的并发队列，使用链表实现。可以看做一个线程安全的 `LinkedList`，这是一个非阻塞队列。**阻塞队列可以通过加锁来实现，非阻塞队列可以通过 CAS 操作实现。**

**`BlockingQueue`** : 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。

**`ConcurrentSkipListMap`** : 跳表的实现。这是一个 Map，使用跳表的数据结构进行快速查找。**跳表是一种利用空间换时间的算法。**



### AQS 详解

AQS 的全称为 `AbstractQueuedSynchronizer` ，翻译过来的意思就是抽象队列同步器。.

AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是基于 **CLH 锁** （Craig, Landin, and Hagersten locks） 实现的。

AQS 使用 **int 成员变量 `state` 表示同步状态**，通过内置的 **FIFO 线程等待/等待队列** 来完成获取资源线程的排队工作。

基于 AQS 的常见同步工具类：semaphore, CountDownLatch, CyclicBarrier



### Atomic 原子类总结



所谓原子类说简单点就是具有原子/原子操作特征的类。

**基本类型**

使用原子的方式更新基本类型

- `AtomicInteger`：整型原子类
- `AtomicLong`：长整型原子类
- `AtomicBoolean`：布尔型原子类

**数组类型**

使用原子的方式更新数组里的某个元素

- `AtomicIntegerArray`：整型数组原子类
- `AtomicLongArray`：长整型数组原子类
- `AtomicReferenceArray`：引用类型数组原子类

**引用类型**

- `AtomicReference`：引用类型原子类
- `AtomicMarkableReference`：原子更新带有标记的引用类型。该类将 boolean 标记与引用关联起来，也可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。
- `AtomicStampedReference`：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。



### ThreadLocal 详解

`ThreadLocal`对象可以提供线程局部变量，每个线程`Thread`拥有一份自己的**副本变量**，多个线程互不干扰。



### CompletableFuture 详解



### 虚拟线程极简入门



## IO



### Java IO 基础知识总结



Java IO 流的 40 多个类都是从如下 4 个抽象类基类中派生出来的。

- `InputStream`/`Reader`: 所有的输入流的基类，前者是字节输入流（文件读取到内存,原始字节），后者是字符输入流（文本）。
- `OutputStream`/`Writer`: 所有输出流的基类，前者是字节输出流（数据写入到文件，原始字节），后者是字符输出流（文本）。

**字节缓冲流：**IO 操作是很消耗性能的，缓冲流将数据加载至缓冲区，一次性读取/写入多个字节，从而避免频繁的 IO 操作，提高流的传输效率。

`BufferedInputStream` （字节缓冲输入流）从源头（通常是文件）读取数据（字节信息）到内存的过程中不会一个字节一个字节的读取，而是会先将读取到的字节存放在缓存区，并从内部缓冲区中单独读取字节。这样大幅减少了 IO 次数，提高了读取效率。

`BufferedOutputStream` （字节缓冲输出流）将数据（字节信息）写入到目的地（通常是文件）的过程中不会一个字节一个字节的写入，而是会先将要写入的字节存放在缓存区，并从内部缓冲区中单独写入字节。这样大幅减少了 IO 次数，提高了读取效率

**字符缓冲流：**`BufferedReader` （字符缓冲输入流）和 `BufferedWriter`（字符缓冲输出流）类似于 `BufferedInputStream`（字节缓冲输入流）和`BufferedOutputStream`（字节缓冲输入流），内部都维护了一个字节数组作为缓冲区。不过，前者主要是用来操作字符信息。

打印流：`System.out.print("Hello world!");`用到的是 `PrintStream` 对象，它是 `OutputStream` 的子类

**随机访问流**指的是支持随意跳转到文件的任意位置进行读写的 `RandomAccessFile` 。



### Java IO 设计模式总结



**装饰器（Decorator）模式** 可以在不改变原有对象的情况下拓展其功能。

**适配器（Adapter Pattern）模式** 主要用于接口互不兼容的类的协调工作，你可以将其联想到我们日常经常使用的电源适配器。



**装饰器模式** 更侧重于动态地增强原始类的功能，装饰器类需要跟原始类继承相同的抽象类或者实现相同的接口。

**适配器模式** 更侧重于让接口不兼容而不能交互的类可以一起工作



**工厂模式**用于创建对象，NIO 中大量用到了工厂模式。（New IO）

NIO 中的文件目录监听服务使用到了**观察者模式**。



### Java IO 模式详解



根据冯.诺依曼结构，计算机结构分为 5 大部分：输入设备、输出设备、控制器、运算器、存储器。

**从计算机结构的视角来看的话， I/O 描述了计算机系统与外部设备之间通信的过程。**

为了保证操作系统的稳定性和安全性，一个进程的地址空间划分为 **用户空间（User space）** 和 **内核空间（Kernel space ）** 。

在平常开发过程中接触最多的就是 **磁盘 IO（读写文件）** 和 **网络 IO（网络请求和响应）**。

从应用程序的视角来看的话，我们的应用程序对操作系统的内核发起 IO 调用（系统调用），操作系统负责的内核执行具体的 IO 操作。也就是说，我们的应用程序实际上只是发起了 IO 操作的调用而已，具体 IO 的执行是由操作系统的内核来完成的。

**UNIX 系统下， IO 模型一共有 5 种：**

1. **同步阻塞 I/O：**调用IO操作时，程序会一直等待直到IO操作完成才返回结果。

2. **同步非阻塞 I/O：**调用IO操作后，会立即返回结果，无论IO操作是否完成。轮询检查 IO 是否完成。

3. **I/O 多路复用：**监听多个IO操作的完成状态。完成后被唤醒。

4. **信号驱动 I/O：**发起IO操作后，会向操作系统注册一个信号处理函数。完成后会收到系统信号。

5. **异步 I/O：**发起IO操作后，无需等待操作完成，可以继续执行其他任务。完成后系统会收到通知。





**Java中的3种常见 IO 模型：**

**BIO (Blocking I/O)属于同步阻塞 IO 模型** 。应用程序发起 read 调用后，会一直阻塞，直到内核把数据拷贝到用户空间。只能应对低并发。

**NIO (Non-blocking/New I/O)属于 I/O 多路复用模型。**有一个非常重要的**选择器 ( Selector )** 的概念，也可以被称为 **多路复用器**。

**AIO （Asynchronous I/O）也就是 NIO 2，是异步 IO 模型。**

![image-20240406163435260](.././assets/image-20240406163435260.png)



### Java NIO 核心知识总结



NIO 主要包括以下三个核心组件：

- **Buffer（缓冲区）**：NIO 读写数据都是通过缓冲区进行操作的。读操作的时候将 Channel 中的数据填充到 Buffer 中，而写操作时将 Buffer 中的数据写入到 Channel 中。

- **Channel（通道）**：Channel 是一个双向的、可读可写的数据传输通道，NIO 通过 Channel 来实现数据的输入输出。通道是一个抽象的概念，它可以代表文件、套接字或者其他数据源之间的连接。

- **Selector（选择器）**：允许一个线程处理多个 Channel，基于事件驱动的 I/O 多路复用模型。所有的 Channel 都可以注册到 Selector 上，由 Selector 来分配线程来处理事件。

  ![image-20240406172852932](.././assets/image-20240406172852932.png)



**Buffer**

在传统的 BIO 中，数据的读写是面向流的， 分为字节流和字符流。

在 Java 1.4 的 NIO 库中，**所有数据都是用缓冲区处理的**，这是新库和之前的 BIO 的一个重要区别，有点类似于 BIO 中的缓冲流。NIO 在读取数据时，它是直接读到缓冲区中的。在写入数据时，写入到缓冲区中。 使用 NIO 在读写数据时，都是通过缓冲区进行操作。

Buffer 有读模式和写模式这两种模式，分别用于从 Buffer 中读取数据或者向 Buffer 中写入数据。Buffer 被创建之后默认是写模式，调用 `flip()` 可以切换到读模式。如果要再次切换回写模式，可以调用 `clear()` 或者 `compact()` 方法。

1. 容量（`capacity`）：`Buffer`可以存储的最大数据量，`Buffer`创建时设置且不可改变；

2. 界限（`limit`）：`Buffer` 中可以读/写数据的边界。写模式下，`limit` 代表最多能写入的数据，一般等于 `capacity`（可以通过`limit(int newLimit)`方法设置）；读模式下，`limit` 等于 Buffer 中实际写入的数据大小。

3. 位置（`position`）：下一个可以被读写的数据的位置（索引）。从写操作模式到读操作模式切换的时候（flip），`position` 都会归零，这样就可以从头开始读写了。

4. 标记（`mark`）：`Buffer`允许将位置直接定位到该标记处，这是一个可选属性；

Buffer 最核心的两个方法：

1. `get` : 读取缓冲区的数据
2. `put` ：向缓冲区写入数据



`flip` ：将缓冲区从写模式切换到读模式，它会将 `limit` 的值设置为当前 `position` 的值，将 `position` 的值设置为 0。

`clear`: 清空缓冲区，将缓冲区从读模式切换到写模式，并将 `position` 的值设置为 0，将 `limit` 的值设置为 `capacity` 的值。

![image-20240406185241611](.././assets/image-20240406185241611.png)



**Channel**

Channel 是一个通道，它建立了与数据源（如文件、网络套接字等）之间的连接。我们可以利用它来读取和写入数据，就像打开了一条自来水管，让数据在 Channel 中自由流动。**（File - Channel - Buffer）**

Channel 与前面介绍的 Buffer 打交道，读操作的时候将 Channel 中的数据填充到 Buffer 中，而写操作时将 Buffer 中的数据写入到 Channel 中。

Channel 最核心的两个方法：

1. `read` ：读取数据并写入到 Buffer 中。
2. `write` ：将 Buffer 中的数据写入到 Channel 中。



**Selector**

elector（选择器） 是 NIO 中的一个关键组件，它允许一个线程处理多个 Channel。Selector 是基于事件驱动的 I/O 多路复用模型，主要运作原理是：通过 Selector 注册通道的事件，Selector 会不断地轮询注册在其上的 Channel。



**零拷贝**是提升 IO 操作性能的一个常用手段，像 ActiveMQ、Kafka 、RocketMQ、QMQ、Netty 等顶级开源项目都用到了零拷贝。

**零拷贝是指计算机执行 IO 操作时，CPU 不需要将数据从一个存储区域复制到另一个存储区域，从而可以减少上下文切换以及 CPU 的拷贝时间。**也就是说，零拷贝主主要解决操作系统在处理 I/O 操作时频繁复制数据的问题。零拷贝的常见实现技术有： `mmap+write`、`sendfile`和 `sendfile + DMA gather copy` 。



如果我们需要使用 NIO 构建网络程序的话，不建议直接使用原生 NIO，编程复杂且功能性太弱，推荐使用一些成熟的基于 NIO 的网络编程框架比如 Netty。Netty 在 NIO 的基础上进行了一些优化和扩展比如支持多种协议、支持 SSL/TLS 等等。



## JVM



### Java 内存区域详解（重点）



如果没有特殊说明，都是针对的是 HotSpot 虚拟机。

常见面试题：

- 介绍下 Java 内存区域（运行时数据区）
- Java 对象的创建过程（五步，建议能默写出来并且要知道每一步虚拟机做了什么）
- 对象的访问定位的两种方式（句柄和直接指针两种方式）



**Java 虚拟机在执行 Java 程序的过程中会把它管理的内存划分成若干个不同的数据区域。**



**线程私有的：**

- 程序计数器：程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。
- 虚拟机栈：它的生命周期和线程相同，随着线程的创建而创建，随着线程的死亡而死亡。**栈由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法返回地址。**和数据结构上的栈类似，两者都是先进后出的数据结构，只支持出栈和入栈两种操作。
  - **栈帧随着方法调用而创建，随着方法结束而销毁。无论方法正常完成还是异常完成都算作方法结束。**
- 本地方法栈
  - **虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。**

**线程共享的：**

- 堆：**此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。**
- 方法区：存储已被虚拟机加载的 **类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据**。
- 直接内存 (非运行时数据区的一部分)：一种特殊的内存缓冲区，并不在 Java 堆或方法区中分配的，而是通过 JNI 的方式在本地内存上分配的。



![image-20240406194549442](.././assets/image-20240406194549442.png)



**运行时常量池（Runtime Constant Pool）**是一种用于存储编译时常量和运行时生成的一些常量的内存区域。

**字符串常量池** 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。



**Java 对象的创建过程：**

1. **类加载检查：**加载对象所属的类。
2. **分配内存：分配方式有 “指针碰撞” 和 “空闲列表” 两种。**以上两种方式中的哪一种，取决于 Java 堆内存是否规整（规整：指针碰撞；不规整：空闲列表）。而 **Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定**。虚拟机采用两种方式来保证线程安全：CAS + 失败重试；TLAB。
3. **初始化零值：**对对象进行初始化。
4. **设置对象头：**虚拟机要对对象进行必要的设置。
5. **执行 `init` 方法**：把对象按照程序员的意愿进行初始化。



**对象就是类的实例化。**



**对象的内存布局：**

包括3个区域：

1. **对象头：**包括两部分信息：第一部分用于存储对象自身的运行时数据，另一部分是指针。

2. **实例数据：**对象真正存储的有效信息。

3. **对象填充：**不是必然存在的，也没有什么特别的含义，仅仅起站占位作用。对象的大小必须是 8 字节的整数倍。



对象的访问方式由虚拟机实现而定，目前主流的访问方式有：**使用句柄**、**直接指针**（HotSpot主要使用）。

- reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与对象类型数据各自的具体地址信息。
- reference 中存储的直接就是对象的地址。









### JVM 垃圾回收详解（重点）



常见面试题：

- 如何判断对象是否死亡（两种方法）。
- 简单的介绍一下强引用、软引用、弱引用、虚引用（虚引用与软引用和弱引用的区别、使用软引用能带来的好处）。
- 如何判断一个常量是废弃常量
- 如何判断一个类是无用的类
- 垃圾收集有哪些算法，各自的特点？
- HotSpot 为什么要分为新生代和老年代？
- 常见的垃圾回收器有哪些？
- 介绍一下 CMS,G1 收集器。
- Minor Gc 和 Full GC 有什么不同呢？



Java 的自动内存管理主要是针对**对象内存的回收和对象内存的分配。**同时，Java 自动内存管理最核心的功能是 **堆** 内存中对象的分配与回收。

Java 堆是垃圾收集器管理的主要区域，因此也被称作 **GC 堆（Garbage Collected Heap）**。



JDK 1.7 之前堆内存：新生代、老生代、永久代。

JDK 1.8 之后堆内存：新生代、老生代、**元空间（使用的是直接内存，不在堆内存）**



针对 HotSpot VM 的实现，它里面的 **GC** 其实准确分类只有两大种：

部分收集 (Partial GC)：

- 新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集；
- 老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集；
- 混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。

整堆收集 (Full GC)：收集整个 Java 堆和方法区。



**空间分配担保**是为了确保在 Minor GC 之前老年代本身还有容纳新生代所有对象的剩余空间。



堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断哪些对象已经死亡。

- **引用计数器：**有引用加1，引用失效减1。**实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间循环引用的问题。**
- **可达性分析算法：**通过一系列的称为 **“GC Roots”** 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的，需要被回收。



**引用类型：（引用强度逐渐减弱）**

- **强引用：**使用最普通的引用。
- **软引用**：可有可无的生活用品。内存空间足够，就不会回收。
- 弱引用：可有可无的生活用品。垃圾回收器线程发现就回收。
- 虚引用：任何时候都有可能被垃圾回收。主要用来跟踪对象被垃圾回收的活动。



如何判断一个常量是废弃常量：没有任何引用的常量。

如何判断一个类是无用的类：（先要满足以下三个条件）

1. 该类的所有实例都已经被回收
2. 加载该类的 `ClassLoader` 已经被回收
3. 该类对应的 `java.lang.Class` 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。



**垃圾收集算法：**

- **标记-清除算法：**首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。**（存在算法的效率和内存碎片问题）**
- **标记-复制算法：**它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。**（可用内存减半，不适合老年代）**
- **标记-整理算法：**标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。**（效率不高，适合老年代这种回收频率不高的场景）**
- **分代收集算法：**新生代用复制算法，老年代用标记-清除或者标记-整理算法。



一般将 Java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。



**如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。**

没有万能的垃圾收集器，**我们能做的就是根据具体应用场景选择适合自己的垃圾收集器**。

- Serial收集器：**新生代采用标记-复制算法，老年代采用标记-整理算法。**单线程，简单而高效。
- ParNew收集器：Serial的多线程版本。
- Parallel Scavenge收集器：和 ParNew 也差不多，但是提供了很多参数供用户找到最合适的停顿时间或最大吞吐量。
- Serial Old收集器：Serial收集器的老年代版本。
- Parallel Old收集器：Parallel Scavenge 收集器的老年代版本。
- CMS收集器：**一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。**第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。**并发收集、低停顿**。
- G1收集器：**一款面向服务器的垃圾收集器，主要针对配备多颗处理器及大容量内存的机器。以极高概率满足 GC 停顿时间要求的同时，还具备高吞吐量性能特征。在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来)** 。
- ZGC收集器：可以将暂停时间控制在几毫秒以内，且暂停时间不受堆内存大小的影响，出现 Stop The World 的情况会更少，但代价是牺牲了一些吞吐量。ZGC 最大支持 16TB 的堆内存。



### 类加载器详解（重点）



- 类加载过程：**加载->连接->初始化**。
- 连接过程又可分为三步：**验证->准备->解析**。



## Linux



一切被操作系统管理的资源，如网络接口卡、磁盘驱动器、打印机、输入输出设备、普通文件或目录等，都被视为文件。这是 Linux 系统中一个重要的概念，即**"一切都是文件"**。

**存储文件元信息的区域就叫 inode**，译为索引节点：**i（index）+node**。 **每个文件都有一个唯一的 inode，存储文件的元信息。**



- **硬链接：**硬链接和源文件的 inode 节点号相同，两者对文件系统来说是完全平等的（可以看作是互为硬链接，源头是同一份文件）
- **软链接：**软链接和源文件的 inode 节点号不同，而是指向一个文件路径。可以理解为windows的快捷方式。



**Shell 编程就是对一堆 Linux 命令的逻辑化处理。**

运行脚本:`./helloworld.sh` （注意不要只用`helloworld.sh`）



## 开发工具



### Maven




**Apache Maven 的本质是一个软件项目管理和理解工具。**基于**项目对象模型 (Project Object Model，POM) **的概念，Maven 可以从一条中心信息管理项目的构建、报告和文档。

**`pom.xml` 文件，位于根目录中，包含项目构建生命周期的详细信息。**通过 `pom.xml` 文件，我们可以定义项目的坐标、项目依赖、项目信息、插件信息等等配置。

**Maven的主要作用：项目构建、依赖管理和统一开发结构。**



**项目中依赖的第三方库以及插件可统称为构件。**每一个构建都有坐标唯一标识：

- **groupId**(必须): 定义了当前 Maven 项目隶属的组织或公司。

- **artifactId**(必须)：定义了当前 Maven 项目的名称，项目的唯一的标识符，对应项目根目录的名称。
- **version**(必须)：定义了 Maven 项目当前所处版本。

``` xml
<dependency>
    <groupId>com.alibaba</groupId>
    <artifactId>easyexcel</artifactId>
    <version>3.1.1</version>
</dependency>
```

**如果使用 Maven 构建产生的构件（例如 Jar 文件）被其他的项目引用，那么该构件就是其他项目的依赖。**



**classpath** 用于指定 `.class` 文件存放的位置，类加载器会从该路径中加载所需的 `.class` 文件到内存中。

Maven 在编译、执行测试、实际运行有着三套不同的 classpath：

- **编译 classpath**：编译主代码有效
- **测试 classpath**：编译、运行测试代码有效
- **运行 classpath**：项目运行时有效



**依赖冲突：**

1. **对于 Maven 而言，同一个 groupId 同一个 artifactId 下，只能使用一个 version。**（两个版本存在于同一个pom文件，引入后者）

2. **项目的两个依赖同时引入了某个依赖。**

   1. 路径最短优先：选择依赖链路短的。
   2. 声明顺序优先：在依赖路径长度相等的前提下，顺序最前的那个依赖优先。

   

单存依赖Maven来进行依赖调解，可能会有问题，所以需要用到 `exclusion` 标签来手动排除。一般排除低版本。但如果高版本修改了低版本的类或者方法时，就应该考虑优化上层依赖。（升级上层依赖版本）



Maven 仓库分为：

- **本地仓库**：运行 Maven 的计算机上的一个目录，它缓存远程下载的构件并包含尚未发布的临时构件。`settings.xml` 文件中可以看到 Maven 的本地仓库路径配置，默认本地仓库路径是在 `${user.home}/.m2/repository`。
- **远程仓库**：官方或者其他组织维护的 Maven 仓库。



Maven 依赖包寻找顺序：

1. 先去本地仓库找寻，有的话，直接使用。
2. 本地仓库没有找到的话，会去远程仓库找寻，下载包到本地仓库。
3. 远程仓库没有找到的话，会报错。



**Maven 的生命周期就是为了对所有的构建过程进行抽象和统一，包含了项目的清理、初始化、编译、测试、打包、集成测试、验证、部署和站点生成等几乎所有构建步骤。**

Maven 定义了 3 个生命周期`META-INF/plexus/components.xml`：

- `default` 生命周期：在没有任何关联插件的情况下定义的，是 Maven 的主要生命周期，用于构建应用程序，共包含 23 个阶段。
- `clean`生命周期：目的是清理项目，共包含 3 个阶段：pre-claen, clean, post-clean
- `site`生命周期：目的是建立和发布项目站点，共包含 4 个阶段：pre-site, site, post-site, site-deploy.



**Maven 本质上是一个插件执行框架，所有的执行过程，都是由一个一个插件独立完成的。**像咱们日常使用到的 install、clean、deploy 等命令，其实底层都是一个一个的 Maven 插件。



**Maven多模块管理简单地来说就是将一个项目分为多个模块，每个模块只负责单一的功能实现。**直观的表现就是一个 Maven 项目中不止有一个 `pom.xml` 文件，会在不同的目录中有多个 `pom.xml` 文件，进而实现多模块管理。

多模块管理除了可以更加便于项目开发和管理，还有如下**好处**：

1. 降低代码之间的耦合性（从类级别的耦合提升到 jar 包级别的耦合）；
2. 减少重复，提升复用性；
3. 每个模块都可以是自解释的（通过模块名或者模块文档）；
4. 模块还规范了代码边界的划分，开发者很容易通过模块确定自己所负责的内容。



Maven项目的标准目录结构：

``` bash
project
│
├── src
│   ├── main
│   │   ├── java        # Java 源代码目录
│   │   ├── resources   # 资源文件目录（例如application.yml配置文件、XML 文件等）
│   │
│   └── test
│       ├── java        # 测试用例 Java 源代码目录
│       └── resources   # 测试资源文件目录
│
├── target              # 编译输出目录，包括编译生成的 class 文件、打包文件等
├── pom.xml             # Maven 项目配置文件
└── (其他项目相关文件和目录)
```



在父模块的`pom.xml`文件中使用`<dependencyManagement>`标签来定义子模块中的版本。

**Maven 配置文件允许我们配置不同环境的构建设置**，例如开发、测试和生产。在 `pom.xml` 文件中定义配置文件并使用命令行参数激活它们。

**维护干净的 `pom.xml` 的一些技巧：**

- 将相似的依赖项和插件组合在一起。
- 使用注释来描述特定依赖项或插件的用途。
- 将插件和依赖项的版本号保留在 `<properties>` 标签内以便于管理。

**Maven Wrapper 是一种简单的方法，可以确保 Maven 构建的用户拥有运行 Maven 构建所需的一切。**



### Git



**版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。**



**Git 就是一个典型的分布式版本控制系统。**

这类系统，**客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。 **这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。 因为每一次的克隆操作，实际上都是一次对代码仓库的完整备份。



**Git 采用的是直接记录快照的方式，而非差异比较。我后面会详细介绍这两种方式的差别。**

- **其他：将它们保存的信息看作是一组基本文件和每个文件随时间逐步累积的差异。**（增量，内容多的话浪费时间和性能）
- **Git：把数据看作是对小型文件系统的一组快照。**



**Git 有三种状态**，你的文件可能处于其中之一：

1. **已提交（committed）**：数据已经安全的保存在本地数据库中。
2. **已修改（modified）**：已修改表示修改了文件，但还没保存到数据库中。
3. **已暂存（staged）**：表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。



**基本的 Git 工作流程如下：**

1. 在工作目录中修改文件。
2. 暂存文件，将文件的快照放入暂存区域。
3. 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。



有两种取得 Git 项目仓库的方法。

1. 在现有目录中初始化仓库: 进入项目目录运行 `git init` 命令,该命令将创建一个名为 `.git` 的子目录。
2. 从一个服务器克隆一个现有的 Git 仓库: `git clone [url]` 自定义本地仓库的名字: `git clone [url] directoryname`



**推送改动到远程仓库**

- 如果你还没有克隆现有仓库，并欲将你的仓库连接到某个远程服务器，你可以使用如下命令添加：`git remote add origin <server>` ,比如我们要让本地的一个仓库和 GitHub 上创建的一个仓库关联可以这样`git remote add origin https://github.com/Snailclimb/test.git`

- 将这些改动提交到远端仓库：`git push origin master` (可以把 *master* 换成你想要推送的任何分支)

  如此你就能够将你的改动推送到所添加的服务器上去了。



**分支是用来将特性开发绝缘开来的。**在你创建仓库的时候，*master* 是“默认”的分支。在其他分支上进行开发，完成后再将它们合并到主分支上。

**使用分支其实就相当于在说：“我想基于这个提交以及它所有的父提交进行新的工作。”**

我们通常在开发新功能、修复一个紧急 bug 等等时候会选择创建分支。单分支开发好还是多分支开发好，还是要看具体场景来说。



## 常用框架



### Spring 常见面试题总结



Spring 是一款开源的轻量级 Java 开发框架，旨在提高开发人员的开发效率以及系统的可维护性。

**Spring 最核心的思想就是不重新造轮子，开箱即用，提高开发效率。**

**语言的流行通常需要一个杀手级的应用，Spring 就是 Java 生态的一个杀手级的应用框架。**

**Spring 提供的核心功能主要是 IoC 和 AOP。**





**Spring,Spring MVC,Spring Boot 之间什么关系?**

**Spring 包含了多个功能模块**，其中最重要的是 Spring-Core（主要提供 IoC 依赖注入功能的支持） 模块， Spring 中的其他模块（比如 Spring MVC）的功能实现基本都需要依赖于该模块。

**Spring MVC 是 Spring 中的一个很重要的模块，主要赋予 Spring 快速构建 MVC 架构的 Web 程序的能力。**MVC 是模型(Model)、视图(View)、控制器(Controller)的简写，其核心思想是通过将业务逻辑、数据、显示分离来组织代码。

**Spring Boot 旨在简化 Spring 开发（减少配置文件，开箱即用！）。**

Spring Boot 只是简化了配置，如果你需要构建 MVC 架构的 Web 程序，你还是需要使用 Spring MVC 作为 MVC 框架，只是说 Spring Boot 帮你简化了 Spring MVC 的很多配置，真正做到开箱即用！

**总结来说，Spring Framework 是整个 Spring 生态系统的核心和基础，Spring MVC 是 Spring Framework 中用于构建 Web 应用程序的模块，而 Spring Boot 是 Spring Framework 的一个扩展，用于简化和加速 Spring 应用程序的开发和部署。**Spring Boot 可以与 Spring MVC 结合使用，也可以与其他 Spring 模块（如 Spring Data、Spring Security 等）结合使用，以构建完整的企业级应用程序。



**IoC（Inversion of Control:控制反转）** 是一种设计思想，而不是一个具体的技术实现。**IoC 的思想就是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理。**不过， IoC 并非 Spring 特有，在其他语言中也有应用。

**为什么叫控制反转？**

- **控制**：指的是对象创建（实例化、管理）的权力
- **反转**：控制权交给外部环境（Spring 框架、IoC 容器）

在 Spring 中， IoC 容器是 Spring 用来实现 IoC 的载体， IoC 容器实际上就是个 Map（key，value），Map 中存放的是各种对象。

Spring 时代我们一般通过 XML 文件来配置 Bean，后来开发人员觉得 XML 文件来配置不太好，于是 SpringBoot **注解**配置就慢慢开始流行起来。



**Bean 代指的就是那些被 IoC 容器所管理的对象。**

**将一个类声明为 Bean 的注解有哪些?**

- `@Component`：通用的注解，可标注任意类为 `Spring` 组件。如果一个 Bean 不知道属于哪个层，可以使用`@Component` 注解标注。
- `@Repository` : 对应持久层即 Dao 层，主要用于数据库相关操作。
- `@Service` : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。
- `@Controller` : 对应 Spring MVC 控制层，主要用于接受用户请求并调用 `Service` 层返回数据给前端页面。

@Component 和 @Bean 的区别是什么？@Component 注解作用于类，而@Bean注解作用于方法。@Component通常是通过类路径扫描来自动侦测以及自动装配到 Spring 容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。@Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean,@Bean告诉了 Spring 这是某个类的实例，当我需要用它的时候还给我。@Bean 注解比 @Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 Spring容器时，则只能通过 @Bean来实现。



**@Component 和 @Bean 的区别是什么？**

- **`@Component` 注解作用于类，而`@Bean`注解作用于方法。**
- `@Component`通常是通过类路径扫描来自动侦测以及自动装配到 Spring 容器中（我们可以使用 `@ComponentScan` 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。`@Bean` 注解通常是我们在标有该注解的方法中定义产生这个 bean,`@Bean`告诉了 Spring 这是某个类的实例，当我需要用它的时候还给我。
- `@Bean` 注解比 `@Component` 注解的自定义性更强，而且很多地方我们只能通过 `@Bean` 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 `Spring`容器时，则只能通过 `@Bean`来实现。



Spring 内置的 `@Autowired` 以及 JDK 内置的 `@Resource` 和 `@Inject` 都可以用于注入 Bean。`@Autowired` 和`@Resource`使用的比较多一些。



Bean的生命周期：

1. 创建 Bean 的实例
2. Bean 属性赋值/填充
3. Bean 初始化
4. 销毁 Bean



**AOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。**



**MVC 是模型(Model)、视图(View)、控制器(Controller)的简写，其核心思想是通过将业务逻辑、数据、显示分离来组织代码。**

**MVC 是一种设计模式，Spring MVC 是一款很优秀的 MVC 框架。Spring MVC 可以帮助我们进行更简洁的 Web 层的开发，并且它天生与 Spring 框架集成。Spring MVC 下我们一般把后端项目分为 Service 层（处理业务）、Dao 层（数据库操作）、Entity 层（实体类）、Controller 层(控制层，返回数据给前台页面)。**



当 `@Transactional` 注解作用于类上时，该类的所有 public 方法将都具有该类型的事务属性，同时，我们也可以在方法级别使用该标注来覆盖类级别的定义。





### Spring&SpringBoot 常用注解总结



1. `@SpringBootApplication`：放在启动类上。可以看做以下三者的集合。

   1. `@Configuration`：允许在 Spring 上下文中注册额外的 bean 或导入其他配置类
   2. `@EnableAutoConfiguration`：启用 SpringBoot 的自动配置机制
   3. `@ComponentScan`：扫描被`@Component` (`@Repository`,`@Service`,`@Controller`)注解的 bean，注解默认会扫描该类所在的包下所有的类。

2. Spring Bean 相关

   1.  `@Autowired`：自动导入对象到类中

      1. ``` java
         @Service
         public class UserService {
           ......
         }
         
         @RestController
         @RequestMapping("/users")
         public class UserController {
            @Autowired
            private UserService userService;
            ......
         }
         ```

   2.  `@Component`,`@Repository`,`@Service`, `@Controller`

       1.  要想把类标识成可用于 `@Autowired` 注解自动装配的 bean 的类,可以采用以下注解实现：
           - `@Component`：通用的注解，可标注任意类为 `Spring` 组件。如果一个 Bean 不知道属于哪个层，可以使用`@Component` 注解标注。
           - `@Repository` : 对应持久层即 Dao 层，主要用于数据库相关操作。
           - `@Service` : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。
           - `@Controller` : 对应 Spring MVC 控制层，主要用于接受用户请求并调用 Service 层返回数据给前端页面。

   3.  `@RestController`：是`@Controller`和`@ResponseBody`的合集,表示这是个控制器 bean,并且是将函数的返回值直接填入 HTTP 响应体中,是 REST 风格的控制器。

   4.  `@Scope`：声明 Spring Bean 的作用域

       1.  **四种常见的 Spring Bean 的作用域：**
           - singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。
           - prototype : 每次请求都会创建一个新的 bean 实例。
           - request : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。
           - session : 每一个 HTTP Session 会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。

   5.  `@Configration`：声明配置类

3. **处理常见的 HTTP 请求类型**

   1.  **GET请求：请求从服务器获取特定资源。（查）**
       1.  `@GetMapping("users")` 等价于`@RequestMapping(value="/users",method=RequestMethod.GET)`

   2.  **POST请求：在服务器上创建一个新的资源。（客户端提供更新后的整个资源）（增）**
       1.  `@PostMapping("users")`等价于`@RequestMapping(value="/users",method=RequestMethod.POST)`

   3.  **PUT请求：更新服务器上的资源。（改）**
       1.  `@PutMapping("/users/{userId}")` 等价于`@RequestMapping(value="/users/{userId}",method=RequestMethod.PUT)`

   4.  **DELETE请求：从服务器删除特定的资源。（删）**
       1.  `@DeleteMapping("/users/{userId}")`等价于`@RequestMapping(value="/users/{userId}",method=RequestMethod.DELETE)`

   5.  **PATCH请求：更新服务器上的资源（客户端提供更改的属性，可以看做作是部分更新）**
       1.  一般实际项目中，我们都是 PUT 不够用了之后才用 PATCH 请求去更新数据。

4. 前后端传值

   1. `@PathVariable`用于获取路径参数，`@RequestParam`用于获取查询参数。
   2. `@RequestBody`用于读取 Request 请求（可能是 POST,PUT,DELETE,GET 请求）的 body 部分并且**Content-Type 为 application/json** 格式的数据，接收到数据之后会自动将数据绑定到 Java 对象上去。

5. 读取配置信息

   1. `@Value("${xxx}")`读取简单配置信息。
   2. `@ConfigurationProperties`读取配置信息并与 bean 绑定。

6. 参数校验

   1. **即使在前端对数据进行校验的情况下，我们还是要对传入后端的数据再进行一遍校验，避免用户绕过浏览器直接通过一些 HTTP 工具直接向后端请求一些违法数据**

   2. 引入 `spring-boot-starter-validation` 依赖

   3. 一些常用的字段验证的注解

      - `@NotEmpty` 被注释的字符串的不能为 null 也不能为空
      - `@NotBlank` 被注释的字符串非 null，并且必须包含一个非空白字符
      - `@Null` 被注释的元素必须为 null
      - `@NotNull` 被注释的元素必须不为 null
      - `@AssertTrue` 被注释的元素必须为 true
      - `@AssertFalse` 被注释的元素必须为 false
      - `@Pattern(regex=,flag=)`被注释的元素必须符合指定的正则表达式
      - `@Email` 被注释的元素必须是 Email 格式。
      - `@Min(value)`被注释的元素必须是一个数字，其值必须大于等于指定的最小值
      - `@Max(value)`被注释的元素必须是一个数字，其值必须小于等于指定的最大值
      - `@DecimalMin(value)`被注释的元素必须是一个数字，其值必须大于等于指定的最小值
      - `@DecimalMax(value)` 被注释的元素必须是一个数字，其值必须小于等于指定的最大值
      - `@Size(max=, min=)`被注释的元素的大小必须在指定的范围内
      - `@Digits(integer, fraction)`被注释的元素必须是一个数字，其值必须在可接受的范围内
      - `@Past`被注释的元素必须是一个过去的日期
      - `@Future` 被注释的元素必须是一个将来的日期

   4. 验证请求体(RequestBody)
   5. 验证请求参数(Path Variables 和 Request Parameters)：**一定一定不要忘记在类上加上 `@Validated` 注解了，这个参数可以告诉 Spring 去校验方法参数。**

7. 全局处理 Controller 层异常

   1. `@ControllerAdvice` :注解定义全局异常处理类
   2. `@ExceptionHandler` :注解声明异常处理方法

8. JPA 相关（Java Persistence API，即 Java 持久化 API）

   1. 创建表：`@Entity`声明一个类对应一个数据库实体；`@Table` 设置表名
   2. 创建主键：`@Id`：声明一个字段为主键。还可以使用 `@GeneratedValue` 指定主键生成策略。
   3. 设置字段类型：`@Column` 声明字段。
   4. 指定不持久化特定字段：`@Transient`：声明不需要与数据库映射的字段，在保存的时候不需要保存进数据库 。
      1. 在对象关系映射（ORM）领域中，**持久化通常指将内存中的对象状态转换为永久存储的状态**，以便在应用程序重新启动或重新加载时恢复对象的状态。

   5. 声明大字段：`@Lob`:声明某个字段为大字段。
   6. 创建枚举类型的字段：枚举字段要用`@Enumerated`注解修饰。
   7. 增加审计功能
   8. 删除/修改数据：`@Modifying` 注解提示 JPA 该操作是修改操作,注意还要配合`@Transactional`注解使用。
   9. 关联关系

9. 事务 `@Transactional`注解一般可以作用在`类`或者`方法`上。

10. json 数据处理

    1. 过滤 json 数据：
       1. **`@JsonIgnoreProperties` 作用在类上用于过滤掉特定字段不返回或者不解析。**
       2. **`@JsonIgnore`一般用于类的属性上，作用和上面的`@JsonIgnoreProperties` 一样。**

    2. 格式化 json 数据：`@JsonFormat`一般用来格式化 json 数据。
    3. 扁平化对象

11. 测试相关

    1. **`@ActiveProfiles`一般作用于测试类上， 用于声明生效的 Spring 配置文件。**
    2. **`@Test`声明一个方法为测试方法**
    3. **`@Transactional`被声明的测试方法的数据会回滚，避免污染测试数据。**
    4. **`@WithMockUser` Spring Security 提供的，用来模拟一个真实用户，并且可以赋予权限。**




**短链接中的常见注解：**



**`@RequiredArgsConstructor`是 Lombok 提供的一个注解，用于自动生成一个包含所有未初始化（即未被赋值）属性的构造函数。它可以减少代码量，并且使得代码更加简洁。**

``` java
import lombok.RequiredArgsConstructor;

@RequiredArgsConstructor
public class MyClass {
    private final int id;
    private String name;
}
```



**`@Override` 是 Java 中的一个注解，用于标识方法重写（Override）父类或接口中的方法。当一个方法被 `@Override` 注解标记时，编译器会检查该方法是否确实覆盖了父类或接口中的方法，如果没有覆盖成功则会报编译错误。**

**serviceImpl文件中比较多。**

``` java
public class Animal {
    public void eat() {
        System.out.println("Animal is eating");
    }
}

public class Dog extends Animal {
    @Override
    public void eat() {
        System.out.println("Dog is eating");
    }
}
```



**`@Slf4j` 是 Lombok 提供的一个注解，用于自动生成日志记录器（Logger）的代码。它可以减少代码量，并且使得添加日志记录功能更加方便。**

``` java
import lombok.extern.slf4j.Slf4j;

@Slf4j
public class MyClass {
    public void myMethod() {
        log.info("This is a log message");
    }
}
```





### IoC & AOP 详解（快速搞懂）

- 什么是 IoC？
- IoC 解决了什么问题？
- IoC 和 DI 的区别？
- 什么是 AOP？
- AOP 解决了什么问题？
- AOP 的应用场景有哪些？
- AOP 为什么叫做切面编程？
- AOP 实现方式有哪些？



**IoC （Inversion of Control ）即控制反转/反转控制。**它是一种思想不是一个技术实现。描述的是：Java 开发领域对象的创建以及管理的问题。

- **传统的开发方式** ：往往是在类 A 中手动通过 new 关键字来 new 一个 B 的对象出来

- **使用 IoC 思想的开发方式** ：不通过 new 关键字来创建对象，而是**通过 IoC 容器(Spring 框架) 来帮助我们实例化对象。我们需要哪个对象，直接从 IoC 容器里面去取即可。**



**为什么叫控制反转?**

- **控制** ：指的是对象创建（实例化、管理）的权力
- **反转** ：控制权交给外部环境（IoC 容器）



IoC 的思想就是两方之间不互相依赖，由第三方容器来管理相关资源。这样有什么好处呢？

1. 对象之间的耦合度或者说依赖程度降低；
2. 资源变的容易管理；比如你用 Spring 容器提供的话很容易就可以实现一个单例。



IoC（Inverse of Control:控制反转）是一种设计思想或者说是某种模式。这个设计思想就是 **将原本在程序中手动创建对象的控制权交给第三方比如 IoC 容器。**



**IoC 最常见以及最合理的实现方式叫做依赖注入（Dependency Injection，简称 DI）。**



**AOP（Aspect Oriented Programming）即面向切面编程，AOP 是 OOP（面向对象编程）的一种延续，二者互补，并不对立。**

**AOP 的目的是将横切关注点（如日志记录、事务管理、权限控制、接口限流、接口幂等等）从核心业务逻辑中分离出来，通过动态代理、字节码操作等技术，实现代码的复用和解耦，提高代码的可维护性和可扩展性。**

**OOP 的目的是将业务逻辑按照对象的属性和行为进行封装，通过类、对象、继承、多态等概念，实现代码的模块化和层次化（也能实现代码的复用），提高代码的可读性和可维护性。**



**横切关注点（cross-cutting concerns）** ：多个类或对象中的公共行为（如日志记录、事务管理、权限控制、接口限流、接口幂等等）。

## 系统设计



### RestFul API



**API Application Programming Interface ** ：应用程序编程接口

**REST Resource Representational State Transfer**：资源代表状态转移

**RESTful API** 可以通过 URL + HTTP Method 知道请求要干嘛，可以通过 HTTP 状态码知道请求的结果如何。



**常见状态码**

1xx：提示信息，表示中间状态

2xx：成功，报文已经被正确处理

3xx：重定向（301 永久重定向，302 临时重定向，304资源未修改走缓存）

4xx：客户端错误

5xx：服务器错误



### 软件工程



软件开发过程：需求分析、软件设计、编码、测试、交付、维护



软件开发模型

- 瀑布模型：通过设计一系列阶段顺序展开的
- 敏捷开发：以人为核心、迭代、循序渐进，把一个大项目分为多个相互联系，但也可独立运行的小项目。



### 代码命名指南



1. 大驼峰命名法：类名 `UpperCamelCase`
2. 小驼峰命名法：方法名、参数名、成员变量、局部变量 `lowerCamelCase`
3. 蛇形命名法： 下划线链接`_`
    1. 测试方法名：全部小写 `xxx_is_valid`
    2. 常量、枚举名称 `CLIENT_CONNECT_SERVER_FAILURE`
4. 串式命名法：项目文件夹 `dubbo-registry`
5. 包名尽量使用单个名词单数小写，通过 `.`



### 软件重构



重构就是利用设计模式、软件设计原则和重构手段来让代码更容易理解，更易于修改。

重构的最终目标是 **提高软件开发速度和质量**。



**设计模式 23 种**

- 创建型：单例、工厂、建造者、原型
- 结构性：代理、桥接、门面、享元、适配器、装饰器、组合
- 中介者：模版、观察者、责任链、策略、命令、迭代器、访问者、备忘录、解释器、状态



**软件设计原则 7个（SOLID 5个）**

- 单一职责原则：强调一个类或模块应该只有一个原因来发生变化
- 开闭原则：对修改关闭、对拓展开放
- 里氏替换原则：强调子类应该能够替代其基类而不引起错误
- 接口隔离原则：将大型接口拆分为多个小型接口，以便客户端只需依赖于其需要的接口
- 依赖反转原则：强调高级模块不应该依赖于低级模块，都应该依赖于抽象



### 单元测试



单元测试（Unit Testing）是针对程序模块进行的正确性检验测试工作。



TDD 即 Test-Driven Development（ 测试驱动开发），原理是在开发功能代码之前，先编写测试用例代码，然后针对测试用例编写功能代码，使其能够通过。


## 分布式



### 分布式锁



**为什么需要分布式锁？**

在多线程环境中，如果多个线程同时访问共享资源（例如商品库存、外卖订单），会发生数据竞争，可能会导致出现脏数据或者系统问题，威胁到程序的正常运行。



**如何才能实现共享资源的互斥访问呢？** 

锁是一个比较通用的解决方案，更准确点来说是**悲观锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程**）



对于单机多线程来说，在 Java 中，我们通常使用 `ReentrantLock` 类、`synchronized` 关键字这类 JDK 自带的 **本地锁** 来控制一个 JVM 进程内的多个线程对本地共享资源的访问。



分布式系统下，不同的服务/客户端通常运行在独立的 JVM 进程上。如果多个 JVM 进程共享同一份资源的话，使用本地锁就没办法实现资源的互斥访问了。于是，**分布式锁** 就诞生了。



**一个最基本的分布式锁需要满足：**

- **互斥**：任意一个时刻，锁只能被一个线程持有。
- **高可用**：锁服务是高可用的，当一个锁服务出现问题，能够自动切换到另外一个锁服务。并且，即使客户端的释放锁的代码逻辑出现问题，锁最终一定还是会被释放，不会影响其他线程对共享资源的访问。这一般是通过**超时机制**实现的。
- **可重入**：一个节点获取了锁之后，还可以再次获取锁。

**除了上面这三个基本条件之外，一个好的分布式锁还需要满足下面这些条件：**

- **高性能**：获取和释放锁的操作应该快速完成，并且不应该对整个系统的性能造成过大影响。
- **非阻塞**：如果获取不到锁，不能无限期等待，避免对系统正常运行造成影响。



常见分布式锁实现方案如下：

- 基于关系型数据库比如 MySQL 实现分布式锁。
- 基于分布式协调服务 ZooKeeper 实现分布式锁。
- 基于分布式键值存储系统比如 Redis 、Etcd 实现分布式锁。



**这篇文章我们主要介绍了：**

- 分布式锁的用途：分布式系统下，不同的服务/客户端通常运行在独立的 JVM 进程上。如果多个 JVM 进程共享同一份资源的话，使用本地锁就没办法实现资源的互斥访问了。
- 分布式锁的应该具备的条件：互斥、高可用、可重入、高性能、非阻塞。
- 分布式锁的常见实现方式：关系型数据库比如 MySQL、分布式协调服务 ZooKeeper、分布式键值存储系统比如 Redis 、Etcd 。



**不论是本地锁还是分布式锁，核心都在于“互斥”。**



**基于 Redis 实现分布式锁：SETNX（SET if Not eXists）加锁，基于 lua 脚本释放锁**

为了避免锁无法被释放，我们可以想到的一个解决办法就是：**给这个 key（也就是锁） 设置一个过期时间** 。

**一定要保证设置指定 key 的值和过期时间是一个原子操作！！！**



**为什么要给锁设置一个过期时间：**

**如果操作共享资源的时间大于过期时间，就会出现锁提前过期的问题，进而导致分布式锁直接失效。如果锁的超时时间设置过长，又会影响到性能。**



**如何实现锁的优雅续期？**

**Redisson 中的分布式锁自带自动续期机制**，使用起来非常简单，原理也比较简单，其提供了一个专门用来监控和续期锁的 **Watch Dog（ 看门狗）**，如果操作共享资源的线程还未执行完成的话，Watch Dog 会不断地延长锁的过期时间，进而保证锁不会因为超时而被释放。



**如何实现可重入锁？**

可重入锁指的是在一个线程中可以多次获取同一把锁。

**不可重入的分布式锁基本可以满足绝大部分业务场景了，一些特殊的场景可能会需要使用可重入的分布式锁。**

可重入分布式锁的实现**核心思路是线程在获取锁的时候判断是否为自己的锁。**

具体实现：Redisson，其内置了多种类型的锁比如可重入锁（Reentrant Lock）、自旋锁（Spin Lock）、公平锁（Fair Lock）、多重锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）。





**Redis如何解决集群情况下分布式锁的可靠性？**

**Redlock 算法**的思想是让客户端向 Redis 集群中的多个独立的 Redis 实例依次请求申请加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败。



## 高性能



### 数据库优化



**读写分离主要是为了将对数据库的读写操作分散到不同的数据库节点上。**

一般情况下，我们都会选择一主多从，也就是一台主数据库负责写，其他的从数据库负责读。主库和从库之间会进行数据同步，以保证从库中数据的准确性。这样的架构实现起来比较简单，并且也符合系统的写少读多的特点。



**实现读写分离一般包含如下几步：**

1. 部署多台数据库，选择其中的一台作为主数据库，其他的一台或者多台作为从数据库。
2. 保证主数据库和从数据库之间的数据是实时同步的，这个过程也就是我们常说的**主从复制**。
3. 系统将写请求交给主数据库处理，读请求交给从数据库处理。



**具体实现：代理方式，组件方式（推荐方式，sharding-jdbc）。**



**主从复制原理：**

**MySQL binlog(binary log 即二进制日志文件) 主要记录了 MySQL 数据库中数据的所有变化(数据库执行的所有 DDL 和 DML 语句)。因此，我们根据主库的 MySQL binlog 日志就能够将主库的数据同步到从库中。**

**一般看到 binlog 就要想到主从复制。当然，除了主从复制之外，binlog 还能帮助我们实现数据恢复。**

分布式缓存组件 Redis 也是通过主从复制实现的读写分离。

**MySQL 主从复制是依赖于 binlog 。另外，常见的一些同步 MySQL 数据到其他数据源的工具（比如 canal）的底层一般也是依赖 binlog 。**



主库和从库的数据存在延迟，比如你写完主库之后，主库的数据同步到从库是需要时间的，这个时间差就导致了主库和从库的数据不一致性问题。这也就是我们经常说的 **主从同步延迟** 。

解决方案：

- 强制将读请求路由到主库处理
- 延迟读取



**MySQL 主从同步延时是指从库的数据落后于主库的数据，这种情况可能由以下两个原因造成：**

1. 从库 I/O 线程接收 binlog 的速度跟不上主库写入 binlog 的速度，导致从库 relay log 的数据滞后于主库 binlog 的数据；
2. 从库 SQL 线程执行 relay log 的速度跟不上从库 I/O 线程接收 binlog 的速度，导致从库的数据滞后于从库 relay log 的数据。



**什么情况下会出现出从延迟呢？**

- 从库机器性能比主库差
- 从库处理的读请求过多
- 大事务：运行时间比较长，长时间未提交的事务就可以称为大事务。
- 从库太多
- 网络延迟
- 单线程复制
- 复制模式



**分库** 就是将数据库中的数据分散到不同的数据库上，可以垂直分库，也可以水平分库。

**垂直分库** 就是把单一数据库按照业务进行划分，不同的业务使用不同的数据库，进而将一个数据库的压力分担到多个数据库。

**水平分库** 是把同一个表按一定规则拆分到不同的数据库中，每个库可以位于不同的服务器上，这样就实现了水平扩展，解决了单表的存储和性能瓶颈的问题。



**分表** 就是对单表的数据进行拆分，可以是垂直拆分，也可以是水平拆分。

**垂直分表** 是对数据表列的拆分，把一张列比较多的表拆分为多张表。

**水平分表** 是对数据表行的拆分，把一张行比较多的表拆分为多张表，可以解决单一表数据量过大的问题。



遇到下面几种场景可以考虑分库分表：

- 单表的数据达到千万级别以上，数据库读写速度比较缓慢。
- 数据库中的数据占用的空间越来越大，备份时间越来越长。
- 应用的并发量太大（应该优先考虑其他性能优化方法，而非分库分表）。



**分片算法主要解决了数据被水平分片之后，数据究竟该存放在哪个表的问题。**

常见的分片算法有：

- **哈希分片**：求指定分片键的哈希，然后根据哈希值确定数据应被放置在哪个表中。**哈希分片比较适合随机读写的场景，不太适合经常需要范围查询的场景。**哈希分片可以使每个表的数据分布相对均匀，但对动态伸缩（例如新增一个表或者库）不友好。
- **范围分片**：按照特定的范围区间（比如时间区间、ID 区间）来分配数据，比如 将 `id` 为 `1~299999` 的记录分到第一个表， `300000~599999` 的分到第二个表。范围分片适合需要经常进行范围查找且数据分布均匀的场景，不太适合随机读写的场景（数据未被分散，容易出现热点数据的问题）。
- **映射表分片**：使用一个单独的表（称为映射表）来存储分片键和分片位置的对应关系。
- **一致性哈希分片**：将哈希空间组织成一个环形结构，将分片键和节点（数据库或表）都映射到这个环上，然后根据顺时针的规则确定数据或请求应该分配到哪个节点上，解决了传统哈希对动态伸缩不友好的问题。
- **地理位置分片**：很多 NewSQL 数据库都支持地理位置分片算法，也就是根据地理位置（如城市、地域）来分配数据。
- **融合算法分片**：灵活组合多种分片算法，比如将哈希分片和范围分片组合



**分片键（Sharding Key）是数据分片的关键字段。**分片键的选择非常重要，它关系着数据的分布和查询效率。一般来说，分片键应该具备以下特点：

- **具有共性，**即能够覆盖绝大多数的查询场景，尽量减少单次查询所涉及的分片数量，降低数据库压力；

- **具有离散性**，即能够将数据均匀地分散到各个分片上，避免数据倾斜和热点问题；

- **具有稳定性**，即分片键的值不会发生变化，避免数据迁移和一致性问题；

- **具有扩展性**，即能够支持分片的动态增加和减少，避免数据重新分片的开销。

  

**引入分库分表之后，会给系统带来什么挑战呢？**

- **join 操作**：同一个数据库中的表分布在了不同的数据库中，导致**无法使用 join 操作**。这样就导致我们需要手动进行数据的封装，比如你在一个数据库中查询到一个数据之后，再根据这个数据去另外一个数据库中找对应的数据。不过，很多大厂的资深 DBA 都是建议尽量不要使用 join 操作。因为 join 的效率低，并且会对分库分表造成影响。对于需要用到 join 操作的地方，可以采用多次查询业务层进行数据组装的方法。不过，这种方法需要考虑业务上多次查询的事务性的容忍度。
- **事务问题**：同一个数据库中的表分布在了不同的数据库中，如果单个操作涉及到多个数据库，那么数据库自带的事务就无法满足我们的要求了。这个时候，我们就需要引入分布式事务了。
- **分布式 ID**：分库之后， 数据遍布在不同服务器上的数据库，数据库的自增主键已经没办法满足生成的主键唯一了。我们如何为不同的数据节点生成全局唯一主键呢？这个时候，我们就需要为我们的系统引入分布式 ID 了。
- **跨库聚合查询问题**：分库分表会导致常规聚合查询操作，如 group by，order by 等变得异常复杂。这是因为这些操作需要在多个分片上进行数据汇总和排序，而不是在单个数据库上进行。为了实现这些操作，需要编写复杂的业务代码，或者使用中间件来协调分片间的通信和数据传输。这样会增加开发和维护的成本，以及影响查询的性能和可扩展性。



**ShardingSphere 绝对可以说是当前分库分表的首选！**ShardingSphere 的功能完善，除了支持读写分离和分库分表，还提供分布式事务、数据库治理、影子库、数据加密和脱敏等功能。



**分库分表后数据迁移：停机迁移，双写方案，或者借助数据同步工具Cannal做增量数据迁移（依赖binlog）**



**总结：**

- **读写分离主要是为了将对数据库的读写操作分散到不同的数据库节点上。 **这样的话，就能够小幅提升写性能，大幅提升读性能。

- **读写分离基于主从复制，MySQL 主从复制是依赖于 binlog 。**

- **分库** 就是将数据库中的数据分散到不同的数据库上。**分表** 就是对单表的数据进行拆分，可以是垂直拆分，也可以是水平拆分。

- **引入分库分表之后，需要系统解决事务、分布式 id、无法 join 操作问题。**

- 现在很多公司都是用的类似于 TiDB 这种分布式关系型数据库，不需要我们手动进行分库分表（数据库层面已经帮我们做了），也不需要解决手动分库分表引入的各种问题，直接一步到位，内置很多实用的功能（如无感扩容和缩容、冷热存储分离）！如果公司条件允许的话，个人也是比较推荐这种方式！

- 如果必须要手动分库分表的话，ShardingSphere 是首选！ShardingSphere 的功能完善，除了支持读写分离和分库分表，还提供分布式事务、数据库治理等功能。另外，ShardingSphere 的生态体系完善，社区活跃，文档完善，更新和发布比较频繁。



**热数据是指经常被访问和修改且需要快速访问的数据，冷数据是指不经常访问，对当前项目价值较低，但需要长期保存的数据。**

区分方法：时间维度区分，访问频率区分。

冷热分离的思想非常简单，就是对数据进行分类，然后分开存储。



### 消息队列



#### 基础知识



消息队列的作用：

- 异步：订票
- 削峰：秒杀
- 解耦：使用发布-订阅模式
  - 消息队列还有 点对点模式（一个消息只有一个消费者）



消息队列带来的问题：

- 可用性降低
- 复杂度提高
- 一致性问题



消息模型：

- 点对点模式：使用队列作为消息通信载体

- 发布-订阅模式：使用 主题（Topic）作为消息通信载体，类似于广播模式



#### Kafka



Kafka 是一个分布式流式处理平台

- 三个关键功能

  - 消息队列：发布和订阅消息流

  - 容错的持久方式存储记录消息流：消息持久化到磁盘

  - 流式处理平台：提供了完整的流式处理类库

- 两大应用场景

  - 消息队列
  - 数据处理

- 对比其他消息队列，主要的优势：极致的性能、生态系统兼容性强



*Tips：RocketMQ 的消息模型和 Kafka 基本是完全一样的（发布订阅模式）。唯一的区别是 Kafka 中没有队列这个概念，与之对应的是 Partition（分区）*



| 名称          | 解释                                                         |
| ------------- | ------------------------------------------------------------ |
| Producer      | 消息生产者                                                   |
| Consumer      | 消息消费者                                                   |
| ConsumerGroup | 每个 Consumer 属于一个特定的 Consumer Group，一条消息可以被多个不同的 Consumer Group 消费，但是一个 Consumer Group 中只能有一个 Consumer 能够消费该消息 |
| Broker        | 可以看做 Kafka 实例，一个或者多个 Broker 可以组成一个 Kafka 集群 |
| Topic         | Kafka 根据 topic 对消息进行归类，发布到 Kafka 集群的每条消息都需要指定一个 Topic |
| Partition     | 每个 partition 中的消息是有序的，一个 topic 可以分为多个 partition，partition 也有主从，主 挂了选举 从 顶上（提高容灾能力） |
| Zookeeper     | Kafka 的注册中心，监控整个 Kafka 集群的状态（心跳机制），同时实现负载均衡 |



**多分区（Partition）机制**：Topic 可以对应多个 Partition,  Partition 又可以分布在不同的 Broker 上, 提高并发能力（负载均衡）

**多副本（Replica）机制**：Partition 可以指定对应的副本数，提高了容灾能力，不过也相应的增加了所需要的存储空间。



Kafka 发送消息的时候可以指定：topic, partition, key, data



- 消息保序：kafka 保证同一个 partition 中顺序执行
  - 发送消息的时候指定 key（这样消息就会被放入同一个 partition）
- 消息不丢失
  - 生产者：使用回调函数异步获取结果（get 也可以获取结果，但是是同步）
  - 消费者：关闭自动提交 offset，等真正消费完消息之后再自己手动提交 offset （仍存在重复消费，消费完成还未提交offset时挂掉）
  - broker：从副本 升级为 主副本
- 不重复消费：没有成功提交 offset
  - 幂等校验：通过 Redis 的 set 或者 MySQL 的主键 实现幂等



**Kafka的重试机制**：Kafka 在消息消费异常时会进行重试，重试多次后跳过当前消息（放入死信队列），执行后续消息。（默认情况下重试10次，异常后立即重试）

可以通过 重写 DefaultErrorHandler 的 handleRemaining 函数 实现自定义重试失败后的告警逻辑

**死信队列**：消费者处理失败，或者超过一定的重试次数仍无法被成功处理，消息会被发送到死信队列中，而不是被丢弃。



#### RocketMQ



RocketMQ 具有**高性能、高可靠、高实时、分布式** 的特点。



| 名称          | 解释                                                         |
| ------------- | ------------------------------------------------------------ |
| Producer      | 消息生产者                                                   |
| ProducerGroup | 生产者组                                                     |
| Consumer      | 消息消费者                                                   |
| ConsumerGroup | 消费者组                                                     |
| Broker        | 消息队列服务器，生产者发送消息到 Broker，消费者从 Broker 中拿消息 |
| Topic         | 根据 topic 对消息进行归类，**包含多个队列**（和 Broker 是多对多的关系） |
| NameServer    | 注册中心，提供了 Broker 管理 和 路由信息管理                 |

*Tips：主题模型的实现：`Kafka` 用 分区 Partition ，`RocketMQ` 用 队列。*

`RocketMQ` 通过**使用在一个 `Topic` 中配置多个队列并且每个队列维护每个消费者组的消费位置** 实现了 **主题模式/发布订阅模式**。



- 消息保序：在队列层面上是有序的
  - 通过 重写 MessageQueueSelector 的 select 方法来 **自定义队列选择**，将要顺序执行的消息放到同一队列中
    - RocketMQ 提供的队列选择算法：
      - 轮询算法：各队列依次发送消息（默认）
      - 最小投递延迟算法：选择消息延时小的队列投递
- 不重复消费：没有成功提交 offset
  - 幂等校验：通过 Redis 的 set 或者 MySQL 的主键 实现幂等
- 分布式事务：要么都执行，要么都不执行
  - 事务消息（half 半消息机制） + 事务反查机制
    - half 消息：在事务提交之前，对于消费者来说是不可见的（收到half消息后会备份原消息队列，并改名放入）
    - 事务反差机制：事务执行结果 commit/rollback 如果没有正常发送给消息队列，消息队列会主动发送消息回查
- 消息堆积
  - 生产者端：限流降级
  - 消费者端：增加消费者和队列数量（一个队列只会被一个消费者消费，所以也需要增加队列数量）



RocketMQ 的特性：

- 支持回溯消费：消费之前的消息
- 高性能读写：基于 mmap 实现的零拷贝
  - mmap：共享内核缓冲区和应用缓冲区（减少了一次 IO 拷贝）











# 小林coding



## 图解 MySQL



### 基础篇



#### 执行一条select语句，期间发生了什么？



**MySQL执行流程：**

MySQL 的架构共分为两层：**Server 层和存储引擎层**，

- **Server 层负责建立连接、分析和执行 SQL**。
- **存储引擎层负责数据的存储和提取**。索引默认是B+ 树索引

![查询语句执行流程](https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/sql%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/mysql%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B.png)



**第一步：连接器**

连接的过程需要先经过 TCP 三次握手.

MySQL 的连接也跟 HTTP 一样，有短连接和长连接的概念，它们的区别如下：

``` java
// 短连接
连接 mysql 服务（TCP 三次握手）
执行sql
断开 mysql 服务（TCP 四次挥手）

// 长连接(推荐使用，减少频繁建立断开连接过程，但是可能占用内存较多)
连接 mysql 服务（TCP 三次握手）
执行sql
执行sql
执行sql
....
断开 mysql 服务（TCP 四次挥手）
```



解决长连接占用内存的问题？

1. 定期断开长连接
2. 客户端主动重置连接（代码里调用 mysql_reset_connection 函数）



至此，连接器的工作做完了，简单总结一下：

- 与客户端进行 TCP 三次握手建立连接；
- 校验客户端的用户名和密码，如果用户名或密码不对，则会报错；
- 如果用户名和密码都对了，会读取该用户的权限，然后后面的权限逻辑判断都基于此时读取到的权限；



**第二步：查询缓存**



MySQL 8.0之前会查询缓存。

但是对于更新比较频繁的表，查询缓存的命中率很低的，因为只要一个表有更新操作，那么这个表的查询缓存就会被清空。

MySQL 8.0之后取消此功能。

这里说的查询缓存是 server 层的，即移除的是 server 层的查询缓存，并不是 Innodb 存储引擎中的 buffer pool。



**第三步：解析SQL**



解析SQL由解析器完成，解析器会做如下两件事情：

1. 词法分析：识别关键字
2. 语法分析：构建SQL语法树

**解析器只负责检查语法和构建语法树，但是不会去查表或者字段存不存在（第四步就做了 ，prepare）。**



**第四步：执行SQL**



每条`SELECT` 查询语句流程主要可以分为下面这三个阶段：

- prepare 阶段，也就是预处理阶段；
- optimize 阶段，也就是优化阶段；
- execute 阶段，也就是执行阶段；



1. **预处理器：**检查 SQL 查询语句中的表或者字段是否存在；将 `select *` 中的 `*` 符号，扩展为表上的所有列；
2. **优化器：**将 SQL 查询语句的执行方案确定下来（存在覆盖索引就用覆盖索引）
   1. **覆盖索引**是指一个索引包含了查询语句所需的所有数据，不仅能够提供索引的搜索能力，还可以完全覆盖查询需求，避免了**回表操作**（即根据索引查找到主键，再根据主键获取数据的额外操作），从而提高查询性能和效率。
3. **执行器：**三种方式执行过程；
   1. 主键索引查询：访问类型为 const
   2. 全表扫描：访问类型为 ALL，每次查询到记录都会返回给客户端，客户端遍历完才显示。
   3. 索引下推：（联合索引，两个二级索引一起构成）
      1. 没有索引下推的时候，每查询到一条二级索引记录，都要进行回表操作，然后将记录返回给客户端判断
      2. 二级索引2交给存储引擎层。查询二级索引1，不回表，先判断，二级索引2成立才回表。



**总结**

执行一条 SQL 查询语句，期间发生了什么？

- 连接器：建立连接，管理连接、校验用户身份；
- 查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块；
- 解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；
- 执行 SQL：执行 SQL 共有三个阶段：
  - 预处理阶段：检查表或字段是否存在；将 `select *` 中的 `*` 符号扩展为表上的所有列。
  - 优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；
  - 执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端；



#### MySQL 一行记录是怎么存储的？



- MySQL 的 NULL 值会占用空间吗？
- MySQL 怎么知道 varchar(n) 实际占用数据的大小？
- varchar(n) 中 n 最大取值为多少？
- 行溢出后，MySQL 是怎么处理的？

**其实都是围绕着 MySQL 一行记录的存储结构**



InnoDB 是我们常用的存储引擎，也是 MySQL 默认的存储引擎。

一张数据库表的数据是保存在「 表名字.ibd 」的文件里的。

**表空间由段（segment）、区（extent）、页（page）、行（row）组成**。

1. **行：**数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构。
2. **页：InnoDB 的数据是按「页」为单位来读写的**
3. **区：**InnoDB 存储引擎是用 B+ 树来组织数据的。如果是以页为单位来分配存储空间，那么链表中相邻的两个页之间的物理位置并不是连续的，可能离得非常远，那么磁盘查询时就会有大量的随机I/O，随机 I/O 是非常慢的。**在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了**。
4. **段：**表空间是由各个段（segment）组成的，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。
   - 索引段：存放 B + 树的非叶子节点的区的集合；
   - 数据段：存放 B + 树的叶子节点的区的集合；
   - 回滚段：存放的是回滚数据的区的集合，之前讲事务隔离的时候就介绍到了 MVCC 利用了回滚段实现了多版本查询数据。

![image-20240408150357088](.././assets/image-20240408150357088.png)



InnoDB 提供了 4 种行格式，分别是 Redundant、Compact、Dynamic和 Compressed 行格式。

Compact 行格式：一条完整的记录分为**「记录的额外信息」和「记录的真实数据」**两个部分。

- **记录的额外信息：**
  - 变长字段长度列表：变长字段的真实数据占用的字节数会按照列的顺序**逆序存放** 在「变长字段长度列表」里。
    - **NULL 是不会存放在行格式中记录的真实数据部分里的**
    - 之所以要逆序存放，是因为这样可以**使得位置靠前的记录的真实数据和数据对应的字段长度信息可以同时在一个 CPU Cache Line 中，这样就可以提高 CPU Cache 的命中率**。（向左读就是记录头信息，向右读就是真实数据）
    - 如果变长字段允许存储的最大字节数小于等于 255 字节，就会用 1 字节表示「变长字段长度」；
    - 如果变长字段允许存储的最大字节数大于 255 字节，就会用 2 字节表示「变长字段长度」；
    - 「变长字段长度列表」只出现在数据表有变长字段的时候
  - NULL值列表：值为 NULL 的列 **逆序存放** 在 NULL值列表中。
    - **NULL 值列表必须用整数个字节的位表示（1字节8位）**，如果使用的二进制位个数不足整数个字节，则在字节的高位补 `0`。
    - {name: ccc, phone: null, age: null}  = 0000 0110，对应十六进制表示即为 0x06
    - **当数据表的字段都定义成 NOT NULL 的时候，这时候表里的行格式就不会有 NULL 值列表了**。
  - 记录头信息：
    - delete_mask ：标识此条数据是否被删除。（说明 detele 删除数据时并不是真正删除）
    - next_record：下一条记录的位置。从这里可以知道，记录与记录之间是通过链表组织的。**在前面也提到了，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便。**
    - record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录
- **记录的真实数据：**
  - 自定义的字段
  - 三个隐藏字段
    - row_id：如果指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。
    - trx_id：事务id，表示这个数据是由哪个事务生成的。 trx_id是必需的，占用 6 个字节。
    - roll_pointer：这条记录上一个版本的指针。roll_pointer 是必需的，占用 7 个字节。

​	

**varchar(n)中n最大取值为多少？**

**MySQL 规定除了 TEXT、BLOBs 这种大对象类型之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过 65535 个字节**。

单字段情况下：65535 - 2（变长字段长度列表） - 1（NULL值列表） = 65532

多字段情况下：得考虑其他字段的变长字段列表大小（1或2 * 字段数）和 NULL值列表（可以为空字段数 / 8+ 1）



行溢出时：InnoDB 的数据都是存放在 「数据页」中。但是当发生行溢出时，溢出的数据会存放到「溢出页」中。



### 索引篇



#### 索引常见面试题



![image-20240408155426622](.././assets/image-20240408155426622.png)



**索引是数据的目录**。

所谓的存储引擎，说白了就是如何存储数据、如何为存储的数据建立索引和如何更新、查询数据等技术的实现方法。

![image-20240408160128620](.././assets/image-20240408160128620.png)



**按照四个角度来分类索引：**

- 按「数据结构」分类：**B+tree索引、Hash索引、Full-text索引**。
- 按「物理存储」分类：**聚簇索引（主键索引）、二级索引（辅助索引）**。
- 按「字段特性」分类：**主键索引、唯一索引、普通索引、前缀索引**。
- 按「字段个数」分类：**单列索引、联合索引**。



**按数据结构分类**



在创建表时，InnoDB 存储引擎会根据不同的场景选择不同的列作为索引：

- 如果有主键，默认会使用主键作为聚簇索引的索引键（key）；
- 如果没有主键，就选择**第一个不包含 NULL 值的唯一列**作为聚簇索引的索引键（key）；
- 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键（key）；

其它索引都属于辅助索引（Secondary Index），也被称为二级索引或非聚簇索引。**创建的主键索引和二级索引默认使用的是 B+Tree 索引**。

**B+Tree 是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，而且每个节点里的数据是按主键顺序存放的。**每一层父节点的索引值都会出现在下层子节点的索引值中，因此在叶子节点中，包括了所有的索引值信息，并且每一个叶子节点都有两个指针，分别指向下一个叶子节点和上一个叶子节点，形成一个双向链表。

**B+Tree 相比于 B 树和二叉树来说，最大的优势在于查询效率很高，因为即使在数据量很大的情况，查询一个数据的磁盘 I/O 依然维持在 3-4次。**



**通过二级索引查询：**

主键索引的 B+Tree 和二级索引的 B+Tree 区别如下：

- 主键索引的 B+Tree 的**叶子节点存放的是实际数据**，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
- 二级索引的 B+Tree 的**叶子节点存放的是主键值，而不是实际数据。**



使用二级索引查询：会先检二级索引中的 B+Tree 的索引值（商品编码，product_no），找到对应的叶子节点，然后获取主键值，然后再通过主键索引中的 B+Tree 树查询到对应的叶子节点，然后获取整行数据。**这个过程叫「回表」，也就是说要查两个 B+Tree 才能查到数据**。

如何使用二级索引查询的是主键，就只需要一次查询。**这种在二级索引的 B+Tree 就能查询到结果的过程就叫作「覆盖索引」，也就是只需要查一个 B+Tree 就能找到数据**。



**为什么 MySQL InnoDB 选择 B+ tree 作为索引的数据结构？**

***1、B+Tree vs B Tree***

B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。

另外，B+Tree 叶子节点采用的是**双链表连接**，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。

***2、B+Tree vs 二叉树***

对于有 N 个叶子节点的 B+Tree，其搜索复杂度为`O(logdN)`，其中 d 表示节点允许的最大子节点个数为 d 个。

在实际的应用当中， d 值是大于100的，这样就保证了，即使数据达到千万级别时，B+Tree 的高度依然维持在 3~4 层左右，也就是说一次数据查询操作只需要做 3~4 次的磁盘 I/O 操作就能查询到目标数据。

而二叉树的每个父节点的儿子节点个数只能是 2 个，意味着其搜索复杂度为 `O(logN)`，这已经比 B+Tree 高出不少，因此二叉树检索到目标数据所经历的磁盘 I/O 次数要更多。

***3、B+Tree vs Hash***

Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。

但是 Hash 表不适合做范围查询，它更适合做等值的查询，这也是 B+Tree 索引要比 Hash 表索引有着更广泛的适用场景的原因。



**什么时候使用索引？**

- 字段有唯一性限制的，比如商品编码；
- 经常用于 WHERE 查询条件的字段；
- 经常用于 GROUP BY 和 ORDER BY 的字段。



**什么时候不需要创建索引？**

- WHERE 条件, GROUP BY, ORDER BY 里用不到的字段；
- 字段中存在大量重复数据，不需要创建索引。
- 表数据太少的时候，不需要创建索引。
- 经常更新的字段不用创建索引。



**按物理存储分类**

从物理存储的角度来看，索引分为聚簇索引（主键索引）、二级索引（辅助索引）。

这两个区别在前面也提到了：

- 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
- 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。



**按字段特性分类**

- 主键索引：建立在主键字段上的索引，通常在创建表的时候一起创建，一张表最多只有一个主键索引，索引列的值不允许有空值。
- 唯一索引：建立在 UNIQUE 字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许有空值。
- 普通索引：建立在普通字段上的索引，既不要求字段为主键，也不要求字段为 UNIQUE。
- 前缀索引：对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。使用前缀索引的目的是为了减少索引占用的存储空间，提升查询效率。



**按字段个数分类**

- 建立在单列上的索引称为单列索引，比如主键索引；
- 建立在多列上的索引称为联合索引。

使用联合索引时，存在**最左匹配原则**。

创建了一个 `(a, b, c)` 联合索引，前面三个可行，后面三个不可行。**b 和 c 是全局无序，局部相对有序的**

- where a=1；
- where a=1 and b=2 and c=3；
- where a=1 and b=2；

- where b=2；
- where c=3；
- where b=2 and c=3；



这里说一下几种**常见优化索引的方法：**

- 前缀索引优化：使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。
- 覆盖索引优化：SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作。
- 主键索引最好是自增的：每次**插入一条新记录，都是追加操作，不需要重新移动数据**（和UUID对比）
- 索引最好设置为 NOT NULL：占用物理空间，优化器难以优化。
- 防止索引失效：

**发生索引失效的情况：**

- 当我们使用左或者左右模糊匹配的时候，也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；
- 当我们在查询条件中对索引列做了计算、函数、类型转换操作，这些情况下都会造成索引失效；
- 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。
- 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。



查询语句之前加上 `explain` 并通过查看 `type` 判断扫描方式，`all` 为全表扫描。**执行效率从低到高的顺序为**：

- All（全表扫描）；
- index（全索引扫描）：遍历整颗索引树
- range（索引范围扫描）；
- ref（非唯一索引扫描）；
- eq_ref（唯一索引扫描）；
- const（结果只有一条的主键或唯一索引扫描）。



#### 从数据页的角度看 B+ 树



**InnoDB 的数据是按「数据页」为单位来读写的**

数据库的 I/O 操作的最小单位是页，**InnoDB 数据页的默认大小是 16KB**。

**数据页包括七个部分：文件头，页头，最小和最大记录，用户记录，空闲空间，页目录，文件尾。**

文件头有两个指针，分别指向上一个数据页和下一个数据页，相当于一个双向链表。这样可以让数据页之间逻辑上连续。

**数据页中的记录按照「主键」顺序组成单向链表**

页目录起到索引作用。**页目录就是由多个槽组成的，槽相当于分组记录的索引**。然后，因为记录是按照「主键值」从小到大排序的，所以**我们通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录**，无需从最小记录开始遍历整个页中的记录链表。

**每个槽相当于指针指向了不同组的最后一个记录**。**槽对应的值都是这个组的主键最大的记录。**

InnoDB 对每个分组中的记录条数都是有规定的，槽内的记录就只有几条：（避免槽内记录多，时间复杂度到O(n)）

- 第一个分组中的记录只能有 1 条记录；
- 最后一个分组中的记录条数范围只能在 1-8 条之间；
- 剩下的分组中记录条数范围只能在 4-8 条之间。



**InnoDB 采用了 B+ 树作为索引**。InnoDB 里的 B+ 树中的**每个节点都是一个数据页**

**B+ 树的特点：**

- 只有叶子节点（最底层的节点）才存放了数据，非叶子节点（其他上层节）仅用来存放目录项作为索引。
- 非叶子节点分为不同层次，通过分层来降低每一层的搜索量；
- 所有节点按照索引键大小排序，构成一个双向链表，便于范围查询；





![image-20240410151801666](.././assets/image-20240410151801666.png)

我们再看看 B+ 树如何实现快速查找主键为 6 的记录，以上图为例子：

- 从根节点开始，通过二分法快速定位到符合页内范围包含查询值的页，因为查询的主键值为 6，在[1, 7)范围之间，所以到页 30 中查找更详细的目录项；
- 在非叶子节点（页30）中，继续通过二分法快速定位到符合页内范围包含查询值的页，主键值大于 5，所以就到叶子节点（页16）查找记录；
- 接着，在叶子节点（页16）中，通过槽查找记录时，使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到主键为 6 的记录。

可以看到，**在定位记录所在哪一个页时，也是通过二分法快速定位到包含该记录的页。定位到该页后，又会在该页内进行二分法快速定位记录所在的分组（槽号），最后在分组内进行遍历查找。**



索引又可以分成**聚簇索引和非聚簇索引（二级索引）**，它们区别就在于叶子节点存放的是什么数据：

- 聚簇索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚簇索引的叶子节点；
- 二级索引的叶子节点存放的是主键值，而不是实际数据。



InnoDB 在创建聚簇索引时，会根据不同的场景选择不同的列作为索引：

- 如果有主键，默认会使用主键作为聚簇索引的索引键；
- 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键；
- 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键；



为了实现非主键字段的快速搜索，就引出了二级索引（非聚簇索引/辅助索引），它也是利用了 B+ 树的数据结构，但是二级索引的叶子节点存放的是主键值，不是实际数据。

**如果某个查询语句使用了二级索引，但是查询的数据不是主键值，这时在二级索引找到主键值后，需要去聚簇索引中获得数据行，这个过程就叫作「回表」，也就是说要查两个 B+ 树才能查到数据。不过，当查询的数据是主键值时，因为只在二级索引就能查询到，不用再去聚簇索引查，这个过程就叫作「索引覆盖」，也就是只需要查一个 B+ 树就能找到数据。**



#### 为什么 MySQL 采用 B+ 树来作为索引？



MySQL 的数据是持久化的，意味着数据（索引+记录）是保存到磁盘上的，磁盘速度比内存速度慢很多。

磁盘读写的最小单位是**扇区**，扇区的大小只有 `512B` 大小，操作系统一次会读写多个扇区，所以**操作系统的最小读写单位是块（Block）。**

要设计一个适合 MySQL 索引的数据结构，至少满足以下要求：

- **能在尽可能少的磁盘的 I/O 操作中完成查询工作；**
- **要能高效地查询某一个记录，也要能高效地执行范围查找；**



二分查找 - 二分查找树（**左子树小于根节点，右子树大于根节点**） - 自平衡二叉树（**每个节点的左子树和右子树的高度差不能超过 1**） 



**当树的节点越多的时候，并且树的分叉数 M 越大的时候，M 叉树的高度会远小于二叉树的高度**。

B 树在数据查询中比平衡二叉树效率要高。但是 B 树的每个节点都包含数据（索引+记录），而**用户的记录数据的大小很有可能远远超过了索引数据**，这就需要花费更多的磁盘 I/O 操作次数来读到「有用的索引数据」。



**B+ 树与 B 树差异的点，主要是以下这几点：**

- 叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引；
- 所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表；
- 非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。
- 非叶子节点中有多少个子节点，就有多少个索引；



**性能区别：**

- **单点查询：B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少**。
- **插入和删除效率：B+ 树的插入和删除效率更高**。
- **范围查询：B+ 树所有叶子节点间还有一个链表进行连接，这种设计对范围查找非常有帮助**



**B 树**

![image-20240410155937049](.././assets/image-20240410155937049.png)

**B+ 树**


![image-20240410155955748](.././assets/image-20240410155955748.png)





**Innodb 里的 B+ 树：**

![image-20240410160237985](.././assets/image-20240410160237985.png)

但是 Innodb 使用的 B+ 树有一些特别的点，比如：

- B+ 树的叶子节点之间是用「双向链表」进行连接，这样的好处是既能向右遍历，也能向左遍历。
- B+ 树的节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 16 KB。



**MySQL 默认的存储引擎 InnoDB 采用的是 B+ 作为索引的数据结构，原因有：**

- B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少。
- B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；
- B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。



#### MySQL 单表不要超过 2000W 行，靠谱吗？



**表空间：**表数据实际上放在一个叫 表名.ibd 的文件中。数据表中，看起来是一条连着一条的，实际上在文件中被分为很多小份的数据页，每份都是16K。

**页的数据结构：**一开始只有六个部分，插入数据时，`Free Space` 空间给 `User Records`，`Free Space` 空间**用完则申请新的页。**每页16K。

![image-20240410170138371](.././assets/image-20240410170138371.png)



**索引的数据结构：**

索引的数据结构和刚刚描述的页几乎是一模一样的，而且大小也是 16K。索引页中记录的是页 (数据页，索引页) 的最小主键 id 和页号，以及在索引页中增加了层级的信息，从 0 开始往上算，所以页与页之间就有了上下层级的概念。

**非叶子节点（索引页）**，在它的内容区中有 id 和 页号地址两部分：

- id ：对应页中记录的最小记录 id 值；
- 页号：地址是指向对应页的指针；

而数据页与此几乎大同小异，区别在于数据页记录的是真实的行数据而不是页地址，而且 id 的也是顺序的。

同样一个 16K 的页，非叶子节点里的每条数据都指向新的页，而新的页有两种可能

- 如果是叶子节点，那么里面就是一行行的数据
- 如果是非叶子节点的话，那么就会继续指向新的页



**总结：**

- MySQL 的表数据是以页的形式存放的，页在磁盘中不一定是连续的。
- 页的空间是 16K, 并不是所有的空间都是用来存放数据的，会有一些固定的信息，如，页头，页尾，页码，校验码等等。
- 在 B+ 树中，叶子节点和非叶子节点的数据结构是一样的，区别在于，叶子节点存放的是实际的行数据，而非叶子节点存放的是主键和页号。
- 索引结构不会影响单表最大行数，2000W 也只是推荐值，超过了这个值可能会导致 B + 树层级更高，影响查询性能。



#### 索引失效有哪些？



MySQL 默认的存储引擎是 InnoDB，它采用 B+Tree 作为索引的数据结构。

MySQL 的 MyISAM 存储引擎支持多种索引数据结构，比如 B+ 树索引、R 树索引、Full-Text 索引。MyISAM 存储引擎在创建表时，创建的主键索引默认使用的是 B+ 树索引。

InnoDB 和 MyISAM 都支持 B+ 树索引，但是它们数据的存储结构实现方式不同。不同之处在于：

- InnoDB 存储引擎：B+ 树索引的叶子节点**保存数据本身；**
- MyISAM 存储引擎：B+ 树索引的叶子节点**保存数据的物理地址；**



**查询条件用上了索引列，并不意味着查询过程就一定都用上索引。以下是一些索引失效的例子：**

1. **对索引使用左或者左右模糊匹配：**`where name like "%xxx"` 和 `where name like "%xxx%"`索引失效，右模糊匹配 `xxx%` 索引是不会失效的。
2. **对索引使用函数：**索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了。（但先添加函数索引，走会走索引查了）`where length(name) = 6`
3. **对索引进行表达式计算：**`where id + 1 = 10 ` 不走索引，但是写成 `where id = 10 - 1` 就是走索引的。
4. **对索引隐式类型转换：**`where phone = 15757110192` 不走索引，因为 `phone` 是 `varchar` ，会先转换成数字（使用函数转换）再进行比较。`where id = "1"`就还是会走索引，因为函数转换的是 `"1"`，没有对索引使用函数（或者说对索引隐式类型转换）。
   1. **MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较**。
5. **联合索引非最左匹配：**多个普通字段组合在一起创建的索引就叫做联合索引，联合索引 (a, b, c) 和 (c, b, a) 在使用的时候会存在差别。
6. **WHERE 子句中的 OR：**条件中只要有一个不是索引列，就会索引失效。



#### MySQL 使用 like “%x” ，索引一定会失效吗？



**使用左模糊匹配（like "%xx"）并不一定会走全表扫描，关键还是看数据表中的字段。**

如果数据库表中的字段只有主键+二级索引，那么即使使用了左模糊匹配，也不会走全表扫描（type=all），而是走全扫描二级索引树(type=index)。

再说一个相似，我们都知道联合索引要遵循最左匹配才能走索引，但是如果数据库表中的字段都是索引的话，即使查询过程中，没有遵循最左匹配原则，也是走全扫描二级索引树(type=index)。



**为什么选择全扫描二级索引树，而不扫描聚簇索引树呢？**

二级索引树的记录东西很少，就只有「索引列+主键值」，而聚簇索引记录的东西会更多，比如聚簇索引中的叶子节点则记录了主键值、事务 id、用于事务和 MVCC 的回滚指针以及所有的剩余列。优化器选择它认为成本小的。



**为什么这个数据表加了非索引字段，执行同样的查询语句后，怎么变成走的是全表扫描呢？**

`select *` 的字段不能全部在二级索引树查询到，还需要回表。优化器认为这样成本太高，所以直接全表扫描。



#### count(*) 和 count(1) 有什么区别？哪个性能最好？



**结论：按照性能排序：count(*) = count(1) > count(主键字段) > count(字段) **

count() 是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是**统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个**。`select count(name) from t_order;`



**`count(*)` 其实等于 `count(0)`，所以和`count(1)`性能没什么差异。**

- 优化：如果有多个二级索引的时候，优化器会使用key_len 最小的二级索引进行扫描。
- 只有当没有二级索引的时候，才会采用主键索引来进行统计



**`count(1)` 1永远不为null，所以等同于表中的记录条数。**

- 如果表里只有主键索引，没有二级索引时。InnoDB 循环遍历聚簇索引（主键索引），将读取到的记录返回给 server 层，**但是不会读取记录中的任何字段的值。**相对于 `count(主键字段)` 无需读取记录，所以效率高一点。
- 如果表里有二级索引时，InnoDB 循环遍历的对象就二级索引了。



**`count(主键字段)`**

- 如果表里只有主键索引，没有二级索引时，那么，InnoDB 循环遍历聚簇索引，将读取到的记录返回给 server 层，然后**读取记录中的 id 值**，就会 id 值判断是否为 NULL，如果不为 NULL，就将 count 变量加 1。

- 如果表里有二级索引时，InnoDB 循环遍历的对象就不是聚簇索引，而是二级索引。

因为相同数量的二级索引记录可以比聚簇索引记录占用更少的存储空间，所以二级索引树比聚簇索引树小，这样遍历二级索引的 I/O 成本比遍历聚簇索引的 I/O 成本小，因此「优化器」优先选择的是二级索引。



**`count(字段)`采用全表扫描的方式来计数，所以它的执行效率是比较差的。**



**总结：**

1. count(1)、 count(*)、 count(主键字段)在执行的时候，如果表里存在二级索引，优化器就会选择二级索引进行扫描。

2. 如果要执行 count(1)、 count(*)、 count(主键字段) 时，尽量在数据表上建立二级索引，这样优化器会自动采用 key_len 最小的二级索引进行扫描，相比于扫描主键索引效率会高一些。

3. 不要使用 count(字段) 来统计记录个数，因为它的效率是最差的，会采用全表扫描的方式来统计。如果你非要统计表中该字段不为 NULL 的记录个数，**建议给这个字段建立一个二级索引。**



**为什么要通过遍历的方式来计数？**

**InnoDB 存储引擎是支持事务的**，同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的，所以无法像 MyISAM一样，只维护一个 row_count 变量。



**如何优化 count(*)?**

面对大表的记录统计，花费的时间比较久。

- **近似值：**可以使用 show table status 或者 explain 命令来表进行估算。
- **额外表保存计数值**





### 事务篇



#### 事务隔离级别是怎么实现的？



事务是由 MySQL 的引擎来实现的，我们常见的 InnoDB 引擎它是支持事务的。

事务看起来感觉简单，但是要实现**事务必须要遵守 4 个特性：**

- **原子性：**要么全部完成，要么全部不完成。undo log 回滚日志来保证的。
- **一致性：**操作前后，数据满足完整性约束。通过持久性+原子性+隔离性来保证；
- **隔离性：**每个事务都有一个完整的数据空间，对其他并发事务是隔离的。MVCC或锁机制来保证的。**（重点）**
- **持久性：**事务结束后，数据修改是永久的。 redo log 重做日志来保证的。



**并发事务会引发什么问题？**（引出隔离性）（三个现象的严重性排序从上到下）

- 脏读：**一个事务「读到」了另一个「未提交事务修改过的数据」**（回滚了）
- 不可重复读：在**一个事务内多次读取同一个数据，结果不一样**。
- 幻读：**在一个事务内多次查询某个符合查询条件的「记录数量」，数量不一样。**



SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低，这四个隔离级别如下：（隔离水平由低到高）

- **读未提交（read uncommitted）**，指一个事务还没提交时，它做的变更就能被其他事务看到；
- **读提交（read committed）**，指一个事务提交之后，它做的变更才能被其他事务看到；
- **可重复读（repeatable read）**，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，**MySQL InnoDB 引擎的默认隔离级别**；
- **串行化（serializable ）**；会对记录加上**读写锁**，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；



- 在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象；
- 在「读提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象；
- 在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象；
- 在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生。



**MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」**，但是它很大程度上避免幻读现象，解决的方案有两种：

- 针对**快照读**（普通 select 语句），是**通过 MVCC 方式解决了幻读**。
- 针对**当前读**（select ... for update 等语句），是**通过 next-key lock（记录锁+间隙锁）方式解决了幻读**。

在可重复读隔离级别中，普通的 select 语句就是基于 MVCC 实现的快照读，也就是不会加锁的。而 select .. for update 语句就不是快照读了，而是当前读了，也就是每次读都是拿到最新版本的数据，但是它会对读到的记录加上 next-key lock 锁。



**四种隔离级别具体是如何实现的呢？**

- 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；
- 对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；
- 对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 **Read View 来实现的，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View**。这两个隔离级别实现是通过「事务的 Read View 里的字段」和「记录中的两个隐藏列」的比对，来控制并发事务访问同一个记录时的行为，这就叫 MVCC（多版本并发控制）。



**执行「开始事务」命令，并不意味着启动了事务。**在 MySQL 有两种开启事务的命令，分别是：

- 第一种：begin/start transaction 命令。只有在执行这个命令后，执行了第一条 select 语句，才是事务真正启动的时机；
- 第二种：start transaction with consistent snapshot 命令。马上启动事务。



**MVCC (Multiversion Concurrency Control) 中文全程叫多版本并发控制**，是现代数据库（包括 MySQL、Oracle、PostgreSQL 等）引擎实现中常用的处理读写冲突的手段，目的在于提高数据库高并发场景下的吞吐性能。



**Read View 有四个重要的字段：(理解为数据快照)**

- creator_trx_id ：指的是**创建该 Read View 的事务的事务 id**。
- m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的**事务 id 列表**，注意是一个列表，**“活跃事务”指的就是，启动了但还没提交的事务**。
- min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 **id 最小的事务**，也就是 m_ids 的最小值。
- max_trx_id ：这个并不是 m_ids 的最大值，而是**创建 Read View 时当前数据库中应该给下一个事务的 id 值**，也就是全局事务中最大的事务 id 值 + 1；



对于使用 InnoDB 存储引擎的数据库表，它的**聚簇索引记录中都包含下面两个隐藏列：**

- **trx_id**，当一个事务对某条聚簇索引记录进行改动时，就会**把该事务的事务 id 记录在 trx_id 隐藏列里**；
- **roll_pointer**，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后**这个隐藏列是个指针，指向每一个旧版本记录**，于是就可以通过它找到修改前的记录。



在创建 Read View 后，我们可以将记录中的 trx_id 划分这三种情况：

![image-20240413143559159](.././assets/image-20240413143559159.png)



一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：

- 如果记录的 trx_id 值小于 Read View 中的 `min_trx_id` 值，表示这个版本的记录是在创建 Read View **前**已经提交的事务生成的，所以该版本的记录对当前事务**可见**。

- 如果记录的 trx_id 值大于等于 Read View 中的 `max_trx_id` 值，表示这个版本的记录是在创建 Read View **后**才启动的事务生成的，所以该版本的记录对当前事务**不可见**。

- 如果记录的 trx_id 值在 Read View 的`min_trx_id`和 `max_trx_id`之间，需要判断 trx_id 是否在 m_ids 列表中：

  - 如果记录的 trx_id **在** `m_ids` 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务**不可见**。
- 如果记录的 trx_id **不在** `m_ids`列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务**可见**。

**这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。**





**可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View**。

**读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View**。



#### MySQL 可重复读隔离级别，完全解决幻读了吗？



**幻读的定义：**当同一个查询在不同的时间产生不同的结果集时，事务中就会出现所谓的幻象问题。例如，如果 SELECT 执行了两次，但第二次返回了第一次没有返回的行，则该行是“幻像”行。



可重复读隔离级是由 MVCC（多版本并发控制）实现的，实现的方式是开始事务后（执行 begin 语句后），在执行第一个查询语句后，会创建一个 Read View，**后续的查询语句利用这个 Read View，通过这个 Read View 就可以在 undo log 版本链找到事务开始时的数据，所以事务过程中每次查询的数据都是一样的**，即使中途有其他事务插入了新纪录，是查询不出来这条数据的，所以就很好了避免幻读问题。



MySQL 里除了**普通查询是快照读，其他都是当前读**，比如 update、insert、delete，这些语句执行前都会查询最新版本的数据，然后再做进一步的操作。

**Innodb 引擎为了解决「可重复读」隔离级别使用「当前读」而造成的幻读问题，就引出了间隙锁**。

1. 事务A：`select name for t_stu where id > 2 for update` 执行了这条锁定读语句后，就在对表中的记录加上 id 范围为 (2, +∞] 的 next-key lock（next-key lock 临键锁，是间隙锁+记录锁的组合）。
2. 事务B：`insert into t_stu values(5, "小飞", 100);` 由于5>2，被锁住了，所以会插入一个意向锁，进入等待状态，事知道务A提交。



**可重复读隔离级别下虽然很大程度上避免了幻读，但是还是没有能完全解决幻读**。

**场景1：**在可重复读隔离级别下，事务 A 第一次执行普通的 select 语句时生成了一个 ReadView，之后事务 B 向表中新插入了一条 id = 5 的记录并提交。接着，事务 A 对 id = 5 这条记录进行了更新操作，在这个时刻，这条新记录的 trx_id 隐藏列的值就变成了事务 A 的事务 id，之后事务 A 再使用普通 select 语句去查询这条记录时就可以看到这条记录了，于是就发生了幻读。

因为这种特殊现象的存在，所以我们认为 **MySQL Innodb 中的 MVCC 并不能完全避免幻读现象**。



场景2：

- T1 时刻：事务 A 先执行「快照读语句」：select * from t_test where id > 100 得到了 3 条记录。
- T2 时刻：事务 B 往插入一个 id= 200 的记录并提交；
- T3 时刻：事务 A 再执行「当前读语句」 select * from t_test where id > 100 for update 就会得到 4 条记录，此时也发生了幻读现象。

**要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句**，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。



**总结：**

MySQL InnoDB 引擎的可重复读隔离级别（默认隔离级），根据不同的查询方式，分别提出了避免幻读的方案：

- 针对**快照读**（普通 select 语句），是通过 MVCC 方式解决了幻读。
- 针对**当前读**（select ... for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读。

我举例了两个发生幻读场景的例子。

第一个例子：对于快照读， MVCC 并不能完全避免幻读现象。因为当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读。

第二个例子：对于当前读，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。

所以，**MySQL 可重复读隔离级别并没有彻底解决幻读，只是很大程度上避免了幻读现象的发生。**

要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。



### 锁篇



（笔记写在科研记录本2.5）

#### MySQL有哪些锁？



在 MySQL 里，根据加锁的范围，可以分为**全局锁、表级锁和行锁**三类。



**全局锁：**

**全局锁是怎么用的？**

``` sql
flush tables with read lock
```

执行后数据库就处于**只读状态**了，这时其他线程执行以下操作，都会被阻塞：

- 对数据的增删改操作，比如 insert、delete、update等语句；
- 对表结构的更改操作，比如 alter table、drop table 等语句。

``` sql
unlock table
```

**全局锁应用场景是什么？**

全局锁主要应用于做**全库逻辑备份**，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。

**加全局锁又会带来什么缺点呢？**

备份期间，数据库只读，会造成业务停滞。

**既然备份数据库数据的时候，使用全局锁会影响业务，那有什么其他方式可以避免？**

如果数据库的引擎支持的事务支持**可重复读的隔离级别**，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。

备份数据库的工具是 mysqldump，在使用 mysqldump 时加上 `–single-transaction` 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎。



**表级锁 ：MySQL的表级别的锁包括表锁、元数据锁MDL、意向锁、AUTO-INC锁**



**表锁**

``` sql
// 加锁
//表级别的共享锁，也就是读锁；
lock tables t_student read;

//表级别的独占锁，也就是写锁；
lock tables t_stuent write;
```

表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。如果本线程对学生表加了「共享表锁」，那么本线程接下来如果要对学生表执行写操作的语句，是会被阻塞的，当然其他线程对学生表进行写操作时也会被阻塞，直到锁被释放。

``` sql
// 释放锁
// 会话结束后，也会释放所有表锁
unlock tables
```

尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能，**InnoDB 牛逼的地方在于实现了颗粒度更细的行级锁**。



**元数据锁(MDL)**

我们不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：

- 对一张表进行 CRUD 操作时，加的是 **MDL 读锁**；
- 对一张表做结构变更操作的时候，加的是 **MDL 写锁**；

**MDL 不需要显示调用，那它是在什么时候释放的?**

MDL 是在事务提交后才会释放，这意味着**事务执行期间，MDL 是一直持有的**。

**申请不到 MDL 写锁，后续申请读锁的查询操作也会被阻塞？**

申请 MDL 锁的操作会形成一个队列，队列中**写锁获取优先级高于读锁**，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。



**意向锁：**

- 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；
- 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；

**意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（*lock tables ... read*）和独占表锁（*lock tables ... write*）发生冲突。**

表锁和行锁是满足读读共享、读写互斥、写写互斥的。

**意向锁的目的是为了快速判断表里是否有记录被加锁**。



**AUTO-INC锁**

数据库自动给主键赋值递增的值，这主要是通过 **AUTO-INC 锁**实现的。

AUTO-INC 锁是特殊的表锁机制，锁**不是在一个事务提交后才释放，而是再执行完插入语句后就会立即释放**。

**在插入数据时，会加一个表级别的 AUTO-INC 锁**，然后为被 `AUTO_INCREMENT` 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。

**大量插入的时候影响性能（另一个事务的插入会被阻塞）：**所以提供了后面提供了一种**轻量级的锁**来实现自增。一样也是在插入数据的时候，会为被 `AUTO_INCREMENT` 修饰的字段加上轻量级锁，**然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁**。

InnoDB 存储引擎提供了个 **innodb_autoinc_lock_mode** 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。

- 当 innodb_autoinc_lock_mode = 0，就采用 AUTO-INC 锁，语句执行结束后才释放锁；
- 当 innodb_autoinc_lock_mode = 2，就采用轻量级锁，申请自增主键后就释放锁，并不需要等语句执行后才释放。
- 当 innodb_autoinc_lock_mode = 1：
  - 普通 insert 语句，自增锁在申请之后就马上释放；
  - 类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；

当 innodb_autoinc_lock_mode = 2 是性能最高的方式，但是当搭配 binlog 的日志格式是 statement 一起使用的时候，在「主从复制的场景」中会发生**数据不一致的问题**。

**当 innodb_autoinc_lock_mode = 2 时，并且 binlog_format = row，既能提升并发性，又不会出现数据一致性问题**。binlog 日志格式设置为 row，这样在 binlog 里面记录的是主库分配的自增值，到备库执行的时候，主库的自增值是什么，从库的自增值就是什么。



**行级锁**

**InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。**

如果要在查询时对记录加行锁，可以使用下面这两个方式，这种查询会加锁的语句称为**锁定读**。

``` sql
//对读取的记录加共享锁
select ... lock in share mode;

//对读取的记录加独占锁
select ... for update;
```

上面这两条语句必须在一个事务中，**因为当事务提交了，锁就会被释放**，所以在使用这两条语句的时候，要加上 begin、start transaction 或者 set autocommit = 0。

**共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥。**

行级锁的类型主要有三类：

- Record Lock，记录锁，也就是仅仅把一条记录锁上；**（记录锁无法防止插入，只能防止删除或者修改）**
- Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；
- Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。



**Record lock**

Record Lock 称为记录锁，锁住的是一条记录。而且记录锁是有 S 锁和 X 锁之分的：

- 当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）;
- 当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。

**Gap Lock**

Gap Lock 称为间隙锁，只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。

间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，**间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的**。

**Next-key Lock**

Next-Key Lock 称为临键锁，是 Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。next-key lock 即能保护该记录，又能阻止其他事务将新纪录插入到被保护记录前面的间隙中。

**next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的**。



**插入意向锁**

一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。

如果有的话，插入操作就会发生**阻塞**，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个**插入意向锁**，表明有事务想在某个区间插入新记录，但是现在处于等待状态。

（*PS：MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁*）

插入意向锁名字虽然有意向锁，但是它并**不是意向锁，它是一种特殊的间隙锁，属于行级别锁**。

如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。

**插入意向锁与间隙锁的另一个非常重要的差别是：**尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。



#### MySQL 是怎么加锁的？

InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。



**什么 SQL 语句会加行级锁？**

普通的 select 语句是不会对记录加锁的（除了串行化隔离级别），因为它属于快照读，是通过 MVCC（多版本并发控制）实现的。

如果要在查询时对记录加行级锁，可以使用下面这两个方式，这两种查询会加锁的语句称为**锁定读**。

```sql
//对读取的记录加共享锁(S型锁)
select ... lock in share mode;

//对读取的记录加独占锁(X型锁)
select ... for update;
```

上面这两条语句必须在一个事务中，**因为当事务提交了，锁就会被释放**，所以在使用这两条语句的时候，要加上 begin 或者 start transaction 开启事务的语句。

**除了上面这两条锁定读语句会加行级锁之外，update 和 delete 操作都会加行级锁，且锁的类型都是独占锁(X型锁)**。

```sql
//对操作的记录加独占锁(X型锁)
update table .... where id = 1;

//对操作的记录加独占锁(X型锁)
delete from table where id = 1;
```

共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥。



行级锁的类型主要有三类：

- Record Lock，记录锁，也就是仅仅把一条记录锁上；
- Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；
- Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。



**Record lock**

Record Lock 称为记录锁，锁住的是一条记录。而且记录锁是有 S 锁和 X 锁之分的：

- 当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）;
- 当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。

```sql
// 事务会对表中主键 id = 1 的这条记录加上 X 型的记录锁，如果这时候其他事务对这条记录进行删除或者更新操作，那么这些操作都会被阻塞。
mysql > begin;
mysql > select * from t_test where id = 1 for update;
```

**Gap Lock**

Gap Lock 称为间隙锁，只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。

间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，**间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的**。

**Next-key Lock**

Next-Key Lock 称为**临键锁**，是 Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。next-key lock 即能保护该记录，又能阻止其他事务将新纪录插入到被保护记录前面的间隙中。

**next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的**。



**插入意向锁**

一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。

如果有的话，插入操作就会发生**阻塞**，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个**插入意向锁**，表明有事务想在某个区间插入新记录，但是现在处于等待状态。

*（PS：MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁）*

插入意向锁名字虽然有意向锁，但是它并**不是意向锁，它是一种特殊的间隙锁，属于行级别锁**。

如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。

**插入意向锁与间隙锁的另一个非常重要的差别是：**尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。





**MySQL 是怎么加行级锁的？**



**加锁的对象是索引，加锁的基本单位是 next-key lock**，它是由记录锁和间隙锁组合而成的，**next-key lock 是前开后闭区间，而间隙锁是前开后开区间**。

**在能使用记录锁或者间隙锁就能避免幻读现象的场景下， next-key lock 就会退化成记录锁或间隙锁**。



**唯一索引等值查询（退化的原因就是仅靠xx就够用了）**

- 当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会**退化成「记录锁」**。
  - 可以通过 `select * from performance_schema.data_locks\G;` 查看事务执行 SQL 过程中加了什么锁。
  - 在唯一索引等值查询并且查询记录存在的场景下，仅靠记录锁也能避免幻读的问题。
- 当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会**退化成「间隙锁」**。
  - 在唯一索引等值查询并且查询记录不存在的场景下，仅靠间隙锁就能避免幻读的问题。



**唯一索引范围查询**

当唯一索引进行范围查询时，**会对每一个扫描到的索引加 next-key 锁，然后如果遇到下面这些情况，会退化成记录锁或者间隙锁**：

- 情况一：针对「大于等于」的范围查询，因为存在等值查询的条件，那么如果等值查询的记录是存在于表中，那么该记录的索引中的 next-key 锁会**退化成记录锁**。
- 情况二：针对「小于或者小于等于」的范围查询，要看条件值的记录是否存在于表中：
  - 当条件值的记录不在表中，那么不管是「小于」还是「小于等于」条件的范围查询，**扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁**，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。
  - 当条件值的记录在表中，如果是「小于」条件的范围查询，**扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁**，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁；如果「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引 next-key 锁不会退化成间隙锁。其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。



**非唯一索引等值查询**

当我们用非唯一索引进行等值查询的时候，**因为存在两个索引，一个是主键索引，一个是非唯一索引（二级索引），所以在加锁时，同时会对这两个索引都加锁，但是对主键索引加锁的时候，只有满足查询条件的记录才会对它们的主键索引加锁**。

针对非唯一索引等值查询时，查询的记录存不存在，加锁的规则也会不同：

- 当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是**非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁（为了避免幻读，插入二级记录相同，主键小的记录）同时，在符合查询条件的记录的主键索引上加记录锁**。
- 当查询的记录「不存在」时，**扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁**。
  - **当有一个事务持有二级索引的间隙锁 (22, 39) 时，插入 age = 22 或者 age = 39 记录的语句是否可以执行成功，关键还要考虑插入记录的主键值，因为「二级索引值（age列）+主键值（id列）」才可以确定插入的位置，确定了插入位置后，就要看插入的位置的下一条记录是否有间隙锁，如果有间隙锁，就会发生阻塞，如果没有间隙锁，则可以插入成功**。



**非唯一索引范围查询**

非唯一索引和主键索引的范围查询的加锁也有所不同，不同之处在于**非唯一索引范围查询，索引的 next-key lock 不会有退化为间隙锁和记录锁的情况**，也就是非唯一索引进行范围查询时，对二级索引记录加锁都是加 next-key 锁。



**没有加索引的查询**

**如果锁定读查询语句，没有使用索引列作为查询条件，或者查询语句没有走索引查询，导致扫描是全表扫描。那么，每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表，这时如果其他事务对该表进行增、删、改操作的时候，都会被阻塞**。（update 和 delete也一样）

**在线上在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了。**



**非唯一索引和主键索引的范围查询的加锁规则不同之处在于：**

- 唯一索引在满足一些条件的时候，索引的 next-key lock 退化为间隙锁或者记录锁。
- 非唯一索引范围查询，索引的 next-key lock 不会退化为间隙锁和记录锁。



#### update 没加索引会锁全表



**在 update 语句的 where 条件没有使用索引，就会全表扫描，于是就会对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于把整个表锁住了**。



那 update 语句的 where 带上索引就能避免全表记录加锁了吗？

**关键还得看这条语句在执行过程种，优化器最终选择的是索引扫描，还是全表扫描，如果走了全表扫描，就会对全表的记录加锁了**。



将 MySQL 里的 `sql_safe_updates` 参数设置为 1，开启安全更新模式。此时：

update 语句必须满足如下条件之一才能执行成功：

- 使用 where，并且 where 条件中必须有索引列；
- 使用 limit；
- 同时使用 where 和 limit，此时 where 条件中可以没有索引列；

delete 语句必须满足以下条件能执行成功：

- 同时使用 where 和 limit，此时 where 条件中可以没有索引列；

如果 where 条件带上了索引列，但是优化器最终扫描选择的是全表，而不是索引的话，我们可以使用 `force index([index_name])` 可以告诉优化器使用哪个索引，以此避免有几率锁全表带来的隐患。



`LIMIT` 是用于限制查询结果返回的行数的关键字。

`select * from t_user where id > 10 limit 10;`



#### MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读吗？



幻读：两次查询返回的记录数量不同 。

MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象，解决的方案有两种：

1. 快照读：MVCC 方式
2. 当前读：临键锁 next-key lock



当前读加锁后，删除操作会被阻塞。

在 MySQL 的可重复读隔离级别下，针对当前读的语句会对**索引**加记录锁+间隙锁，这样可以避免其他事务执行增、删、改时导致幻读的问题。

有一点要注意的是，在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了，这是挺严重的问题。



#### MySQL死锁了，怎么办？



死锁的发生：两个事务查询记录时候，都用了当前读。结果就锁住了。

**插入意向锁与间隙锁是冲突的，所以当其它事务持有该间隙的间隙锁时，需要等待其它事务释放间隙锁之后，才能获取到插入意向锁。而间隙锁与间隙锁之间是兼容的，所以所以两个事务中 `select ... for update` 语句并不会相互影响**。

**间隙锁的意义只在于阻止区间被插入**，因此是可以共存的。**一个事务获取的间隙锁不会阻止另一个事务获取同一个间隙范围的间隙锁**，共享和排他的间隙锁是没有区别的，他们相互不冲突，且功能相同，即两个事务可以同时持有包含共同间隙的间隙锁。

这里的共同间隙包括两种场景：

- 其一是两个间隙锁的间隙区间完全一样；
- 其二是一个间隙锁包含的间隙区间是另一个间隙锁包含间隙区间的子集。

但是有一点要注意，**next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的**。



Insert 语句在正常执行时是不会生成锁结构的，它是靠聚簇索引记录自带的 trx_id 隐藏列来作为**隐式锁**来保护记录的。

隐式锁就是在 Insert 过程中不加锁，只有在特殊情况下，才会将隐式锁转换为显示锁，这里我们列举两个场景。

- 如果记录之间加有间隙锁，为了避免幻读，此时是不能插入记录的；
  - 会添加 X 型插入意向锁

- 如果 Insert 的记录和已有记录存在唯一键冲突，此时也不能插入记录。
  - 如果主键索引重复，插入新记录的事务会给已存在的主键值重复的聚簇索引记录**添加 S 型记录锁**。
  - 如果唯一二级索引重复，插入新记录的事务都会给已存在的二级索引列值重复的二级索引记录**添加 S 型 next-key 锁**。
    - 两个事务都插入重复的唯一二级索引数据时，事务A添加成功，隐式锁；事务B阻塞，想要添加 S 型 next-key 锁，但 A 事务并未提交，所以锁等待，事务A隐式锁转为显式锁，类型为 X 型 记录锁。



**避免死锁**

死锁的四个必要条件：**互斥、占有且等待、不可强占用、循环等待**。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。

在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态：

- **设置事务等待锁的超时时间**。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 `innodb_lock_wait_timeout` 是用来设置超时时间的，默认值时 50 秒。

- **开启主动死锁检测**。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect` 设置为 on，表示开启这个逻辑，默认就开启。

  

#### 字节面试：加了什么锁，导致死锁的？

两个事务分别向对方持有的间隙锁范围内插入一条记录，而插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，满足了死锁的四个条件：**互斥、占有且等待、不可强占用、循环等待**，因此发生了死锁。



### 日志篇



#### MySQL 日志：undo log、redo log、bin log 有什么用？



更新语句的流程会涉及到 undo log（回滚日志）、redo log（重做日志） 、binlog （归档日志）这三种日志：

- **undo log（回滚日志）**：是 Innodb 存储引擎层生成的日志，实现了事务中的**原子性**，主要**用于事务回滚和 MVCC**。
- **redo log（重做日志）**：是 Innodb 存储引擎层生成的日志，实现了事务中的**持久性**，主要**用于掉电等故障恢复**；
- **binlog （归档日志）**：是 Server 层生成的日志，主要**用于数据备份和主从复制**；



**undo log**

我们在执行执行一条“增删改”语句的时候，虽然没有输入 begin 开启事务和 commit 提交事务，但是 MySQL 会**隐式开启事务**来执行“增删改”语句的，执行完就自动提交事务的，这样就保证了执行完“增删改”语句后，我们可以及时在数据库表看到“增删改”的结果了。

执行一条语句是否自动提交事务，是由 `autocommit` 参数决定的，默认是开启。所以，执行一条 update 语句也是会使用事务的。

如果MySQL崩溃，就需要用到 undo log 进行回滚。

**undo log 是一种用于撤销回退的日志。**在事务没提交之前，MySQL 会先**记录更新前的数据到 undo log 日志文件里面**，当事务回滚时，可以利用 undo log 来进行回滚。

- 在**插入**一条记录时，要把这条记录的主键值记下来，这样之后回滚时只需要把这个主键值对应的记录**删掉**就好了；
- 在**删除**一条记录时，要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录**插入**到表中就好了；
- 在**更新**一条记录时，要把被更新的列的旧值记下来，这样之后回滚时再把这些列**更新为旧值**就好了。

一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id：

- 通过 trx_id 可以知道该记录是被哪个事务修改的；
- 通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为**版本链**；

**undo log 还有一个作用，通过 ReadView + undo log 实现 MVCC（多版本并发控制）**。

- **「读提交」隔离级别是在每个 select 都会生成一个新的 Read View**，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。
- **「可重复读」隔离级别是启动事务时生成一个 Read View**，然后整个事务期间都在用这个 Read View，这样就保证了在事务期间读到的数据都是事务启动前的记录。

这两个隔离级别实现是通过**「事务的 Read View 里的字段」和「记录中的两个隐藏列（trx_id 和 roll_pointer）」**的比对，如果不满足可见行，就会顺着 undo log 版本链里找到满足其可见性的记录，从而控制并发事务访问同一个记录时的行为，这就叫 **MVCC（多版本并发控制）**。

**总结：undo log 两大作用：**

- **实现事务回滚，保障事务的原子性**。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。
- **实现 MVCC（多版本并发控制）关键因素之一**。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。



**很多人疑问 undo log 是如何刷盘（持久化到磁盘）的？**

undo log 和数据页的刷盘策略是一样的，都需要通过 redo log 保证持久化。

buffer pool 中有 undo 页，对 undo 页的修改也都会记录到 redo log。redo log 会每秒刷盘，提交事务时也会刷盘，数据页和 undo 页都是靠这个机制保证持久化的。



**Buffer Pool 缓冲池**

有了 Buffer Pool 后：

- 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。
- 当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。

InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，Buffer Pool 同样需要按「页」来划分。

在 MySQL 启动的时候，**InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的`16KB`的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页**。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。

Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等等。

**查询一条记录，就只需要缓冲一条记录吗？**

不是的。当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，将页加载到 Buffer Pool 后，再通过页里的「页目录」去定位到某条具体的记录。



**redo log**

Buffer Pool 是提高了读写效率没错，但是问题来了，Buffer Pool 是基于内存的，而内存总是不可靠，万一断电重启，还没来得及落盘的脏页数据就会丢失。

**redo log 是为了防止 Buffer Pool 中的脏页丢失而设计的**

为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，**这个时候更新就算完成了**。

后续，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 **WAL （Write-Ahead Logging）技术**。

**WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上**。

redo log 是物理日志，记录了某个数据页做了什么修改，比如**对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新**，每当执行一个事务就会产生这样的一条或者多条物理日志。

在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。

当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。

**被修改 Undo 页面，需要记录对应 redo log 吗？**

需要的。开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。

不过，**在内存修改该 Undo 页面后，需要记录对应的 redo log**。

**redo log 和 undo log 区别在哪？**

- redo log 记录了此次事务「**完成后**」的数据状态，记录的是更新**之后**的值；
- undo log 记录了此次事务「**开始前**」的数据状态，记录的是更新**之前**的值；

事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务。

有了 redo log，再通过 WAL 技术，InnoDB 就可以保证即使数据库发生异常重启，之前已提交的记录都不会丢失，这个能力称为 **crash-safe**（崩溃恢复）。可以看出来， **redo log 保证了事务四大特性中的持久性**。

**redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？**

写入 redo log 的方式使用了追加操作， 所以磁盘操作是**顺序写**，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是**随机写**。磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小。

**为什么需要 redo log ？**

- **实现事务的持久性，让 MySQL 有 crash-safe （崩溃恢复）的能力**，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；
- **将写操作从「随机写」变成了「顺序写」**，提升 MySQL 写入磁盘的性能。

**产生的 redo log 是直接写入磁盘的吗？**

不是的。redo log 也有自己的缓存 **redo log buffer**，每当产生一条 redo log 时，会先写入到 redo log buffer，后续再持久化到磁盘。

**缓存在 redo log buffer 里的 redo log 还是在内存中，它什么时候刷新到磁盘？**

主要有下面几个时机：

- MySQL 正常关闭时；

- 当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；

- **InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。**

- 每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制，下面会说）。

  - 当设置该**参数为 0 时**，表示每次事务提交时 ，还是**将 redo log 留在 redo log buffer 中** ，该模式下在事务提交时不会主动触发写入磁盘的操作。（可以容忍丢失一秒的数据，）

  - 当设置该**参数为 1 时**，表示每次事务提交时，都**将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘**，这样可以保证 MySQL 异常重启之后数据不会丢失。（强无敌，就是消耗IO）

  - 当设置该**参数为 2 时**，表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log **写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘**（MySQL崩了没事，系统别崩）
  - 数据安全性：参数 1 > 参数 2 > 参数 0；写入性能：参数 0 > 参数 2> 参数 1。所以，数据安全性和写入性能是熊掌不可得兼的，**要不追求数据安全性，牺牲性能；要不追求性能，牺牲数据安全性**。

**redo log 文件写满了怎么办？**

InnoDB 存储引擎有 1 个重做日志文件组( redo log Group），「重做日志文件组」由有 2 个 redo log 文件组成，这两个 redo 日志的文件名叫 ：`ib_logfile0` 和 `ib_logfile1` 。每个 redo log File 的大小是固定且一致的。重做日志文件组是以**循环写**的方式工作的，从头开始写，写到末尾就又回到开头，相当于一个环形。

redo log 是循环写的方式，相当于一个环形，**InnoDB 用 write pos 表示 redo log 当前记录写到的位置，用 checkpoint 表示当前要擦除的位置**，如下图：

![image-20240415101157592](.././assets/image-20240415101157592.png)

图中的：

- write pos 和 checkpoint 的移动都是顺时针方向；
- write pos ～ checkpoint 之间的部分（图中的红色部分），用来记录新的更新操作；
- check point ～ write pos 之间的部分（图中蓝色部分）：待落盘的脏数据页记录；

如果 write pos 追上了 checkpoint，就意味着 **redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞**（*因此所以针对并发量大的系统，适当设置 redo log 的文件大小非常重要*），此时**会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针）**，然后 MySQL 恢复正常运行，继续执行新的更新操作。

所以，一次 checkpoint 的过程就是脏页刷新到磁盘中变成干净页，然后标记 redo log 哪些记录可以被覆盖的过程。



**为什么需要bin log ？**

undo log 和 redo log 这两个日志都是 Innodb 存储引擎生成的。

MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。

**binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT 和 SHOW 操作。**

**为什么有了 binlog， 还要有 redo log？**

只依靠 binlog 是没有 crash-safe（崩溃恢复） 能力的，所以 InnoDB 使用 redo log 来实现 crash-safe 能力。



**redo log 和 binlog 有什么区别？**

这两个日志有四个区别。

*1、适用对象不同：*

- binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；
- redo log 是 Innodb 存储引擎实现的日志；

*2、文件格式不同：*

- binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：
  - STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于**记录了逻辑操作**，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；
  - ROW：**记录行数据最终被修改成什么样**了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；
  - MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；
- redo log 是**物理日志**，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；

*3、写入方式不同：*

- binlog 是**追加写**，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。
- redo log 是**循环写**，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。

*4、用途不同：*

- binlog 用于**备份恢复、主从复制**；
- redo log 用于掉电等**故障恢复**。

**如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？**

不可以使用 redo log 文件恢复，只能使用 binlog 文件恢复。因为 redo log 文件是循环写，只记录未被刷入磁盘的数据的物理日志。binlog 文件保存的是全量的日志，也就是保存了所有数据变更的情况。



**主从复制是怎么实现？**

MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。

这个过程一般是**异步**的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。

MySQL 集群的主从复制过程梳理成 3 个阶段：

- **写入 Binlog**：主库写 binlog 日志，提交事务，并更新本地存储数据。
- **同步 Binlog**：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志（relay log）中。
- **回放 Binlog**：回放 binlog，并更新存储引擎中的数据。

具体详细过程如下：

- MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。
- 从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。
- 从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。

在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。

>  从库是不是越多越好？

并不是，因为从库数量增加，从库连接上来的 I/O 线程也比较多，**主库也要创建同样多的 log dump 线程来处理复制的请求，对主库资源消耗比较高，同时还受限于主库的网络带宽**。一个主库一般跟 2～3 个从库。

> MySQL 主从复制还有哪些模型？

主要有三种：

- **同步复制**：MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。这种方式在实际项目中，**基本上没法用**，原因有两个：一是性能很差，因为要复制到所有节点才返回响应；二是可用性也很差，主库和所有从库任何一个数据库出问题，都会影响业务。
- **异步复制**（默认模型）：MySQL 主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。**这种模式一旦主库宕机，数据就会发生丢失。**
- **半同步复制**：MySQL 5.7 版本之后增加的一种复制方式，介于两者之间，事务线程不用等待所有的从库复制成功响应，只要一部分复制成功响应回来就行，比如一主二从的集群，只要数据成功复制到任意一个从库上，主库的事务线程就可以返回给客户端。这种**半同步复制的方式，兼顾了异步复制和同步复制的优点，即使出现主库宕机，至少还有一个从库有最新的数据，不存在数据丢失的风险**。



**bin log 什么时候刷盘？**

事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到 binlog 文件中。一个事务的 binlog 是不能被拆开的，因此无论这个事务有多大（比如有很多条语句），也要保证一次性写入。

> 什么时候 binlog cache会写到 binlog 文件？

**在事务提交的时候**，执行器把 binlog cache 里的完整事务写入到 binlog 文件中，并清空 binlog cache。实际也是先写到page cache里面，然后调用 `fsync` 才持久化到磁盘。

MySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率：

- sync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；（**默认，风险大**）
- sync_binlog = 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync；
- sync_binlog =N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。（**一般主动设置为100-1000**）





**为什么需要两个阶段提交？**

事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。redo log没写入则主库无法恢复，从库恢复了。binlog 没写入则主库恢复了，从库无法恢复。

**MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决，要么都成功，要么都不成功。两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」**，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。

为了保证这两个日志的一致性，MySQL 使用了**内部 XA 事务**，内部 XA 事务由 binlog 作为协调者，存储引擎是参与者。

事务的提交过程有两个阶段，就是**将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog**，具体如下：

- **prepare 阶段**：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1 的作用）；
- **commit 阶段**：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），接着调用引擎的提交事务接口，**将 redo log 状态设置为 commit**，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功；



**异常重启会出现什么现象？**

- redo log 已经写入磁盘， binlog 还没写入磁盘：**如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务**

- redo log 和 binlog 都已经写入磁盘，还没写入 commit 标识：**如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务**。

所以说，**两阶段提交是以 binlog 写成功为事务提交成功的标识**，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID。

> 处于 prepare 阶段的 redo log 加上完整 binlog，重启就提交事务，MySQL 为什么要这么设计?

binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。采用这个策略，主库和备库的数据就保证了一致性。

> 事务没提交的时候，redo log 会被持久化到磁盘吗？

会的。事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些缓存在 redo log buffer 里的 redo log 也会被「后台线程」每隔一秒一起持久化到磁盘。但如果MySQL崩溃了，重启后因为binlog 没有持久化到磁盘，会回滚的。



**两阶段提交有什么问题？**

- **磁盘 I/O 次数高**：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。
- **锁竞争激烈**：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。

> 为什么两阶段提交的磁盘 I/O 次数会很高？

如果 sync_binlog 和 当 innodb_flush_log_at_trx_commit 都设置为 1，那么在每个事务提交过程中， 都会**至少调用 2 次刷盘操作**，一次是 redo log 刷盘，一次是 binlog 落盘，所以这会成为性能瓶颈。

> 为什么锁竞争激烈？

早期MySQL：在一个事务获取到锁时才能进入 prepare 阶段，一直到 commit 阶段结束才能释放锁，下个事务才可以继续进行 prepare 操作。

**MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数，锁粒度减小了，这样就使得多个阶段可以并发执行，从而提升效率。**

> 有 binlog 组提交，那有 redo log 组提交吗？

MySQL 5.7之后有 redo log 组提交。



**MySQL 磁盘IO 很高，有什么优化的方法？**

- 设置组提交的两个参数： binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，延迟 binlog 刷盘的时机，从而减少 binlog 的刷盘次数。
- 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000），表示每次提交事务都 write，但累积 N 个事务后才 fsync，相当于延迟了 binlog 刷盘的时机。
- 将 innodb_flush_log_at_trx_commit 设置为 2。表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件。。



### 内存篇



#### 揭开 Buffer Pool 的面纱



**为什么要有 Buffer Pool？**

从磁盘里面读取数据性能差。为此，Innodb 存储引擎设计了一个**缓冲池（*Buffer Pool*）**，直接读取内存，来提高数据库的读写性能。

**有了缓冲池后：**

- 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。
- 当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。



**Buffer Pool 有多大？**

默认配置下 Buffer Pool 只有 `128MB` 。可以通过调整 `innodb_buffer_pool_size` 参数来设置 Buffer Pool 的大小，一般建议设置成可用物理内存的 60%~80%。



**Buffer Pool 缓存什么？**

在 MySQL 启动的时候，**InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的`16KB`的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页**。

Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 undo 页，插入缓存、自适应哈希索引、锁信息等等。

为了更好的管理这些在 Buffer Pool 中的缓存页，InnoDB 为每一个缓存页都创建了一个**控制块**，控制块信息包括「缓存页的表空间、页号、缓存页地址、链表节点」等等。

控制块也是占有内存空间的，它是放在 Buffer Pool 的最前面，接着才是缓存页。中间的被称为碎片页。

> 为什么会有碎片空间呢？

中间剩余的空间不够放一对控制块和缓存页。 Buffer Pool 大小设置的好的话，也可能不会产生碎片。

> 查询一条记录，就只需要缓冲一条记录吗？

不是的。当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，因为，**通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录。将页加载到 Buffer Pool 后，再通过页里的页目录去定位到某条具体的记录。**



**如何管理 Buffer Pool？**



**如何管理空闲页？**

为了能够快速找到空闲的缓存页，可以使用链表结构，将空闲缓存页的「控制块」作为链表的节点，这个链表称为 **Free 链表**（空闲链表）。有了 Free 链表后，每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。**Free 链表节点都对应一个空闲的缓存页。**



**如何管理脏页？**

更新数据的时候，不需要每次都要写入磁盘，而是将 Buffer Pool 对应的缓存页标记为**脏页**，然后再由后台线程将脏页写入到磁盘。

那为了能快速知道哪些缓存页是脏的，于是就设计出 **Flush 链表**，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 **Flush 链表的元素都是脏页。**



**如何提高缓存命中率？**

对于一些频繁访问的数据我们希望可以一直留在 Buffer Pool 中，而一些很少访问的数据希望可以在某些时机可以淘汰掉。**使用LRU（Least recently used）算法。**

- 当访问的页在 Buffer Pool 里，就直接把该页对应的 LRU 链表节点移动到链表的头部。
- 当访问的页不在 Buffer Pool 里，除了要把页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的节点。

Buffer Pool 里有三种页和链表来管理数据:

- **Free Page（空闲页）**，表示此页未被使用，位于 **Free 链表**；
- **Clean Page（干净页）**，表示此页已被使用，但是页面未发生修改，位于**LRU 链表**。
- **Dirty Page（脏页）**，表示此页「已被使用」且「已经被修改」，其数据和磁盘上的数据已经不一致。当脏页上的数据写入磁盘后，内存数据和磁盘数据一致，那么该页就变成了干净页。脏页同时存在于 **LRU 链表和 Flush 链表**。



简单的 LRU 算法并没有被 MySQL 使用，因为简单的 LRU 算法无法避免下面这两个问题：

- 预读失效；
- Buffer Pool 污染；

> 预读失效

MySQL 在加载数据页时，会提前把它相邻的数据页一并加载进来，目的是为了减少磁盘 IO。

但是可能这些**被提前加载进来的数据页，并没有被访问**，相当于这个预读是白做了，这个就是**预读失效**。

如果使用简单的 LRU 算法，就会把预读页放到 LRU 链表头部，而当 Buffer Pool空间不够的时候，还需要把末尾的页淘汰掉。

如果这些预读页一直不会被访问到，就会出现一个很奇怪的问题，不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是频繁访问的页，这样就大大降低了缓存命中率。

> 怎么解决预读失效而导致缓存命中率降低的问题？

**让预读的页停留在 Buffer Pool 里的时间要尽可能的短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在 Buffer Pool 里的时间尽可能长**。

MySQL 是这样做的，它改进了 LRU 算法，将 LRU 划分了 2 个区域：**old 区域 和 young 区域**。

young 区域在 LRU 链表的前半部分，old 区域则是在后半部分。**划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部**。

old 区域占整个 LRU 链表长度的比例可以通过 `innodb_old_blocks_pct` 参数来设置，默认是 37，代表整个 LRU 链表中 young 区域与 old 区域比例是 63:37。

> 什么是 Buffer Pool 污染？

当某一个 SQL 语句**扫描了大量的数据**时，在 Buffer Pool 空间比较有限的情况下，可能会将 **Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了**，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降，这个过程被称为 **Buffer Pool 污染**。

Buffer Pool 污染并不只是查询语句查询出了大量的数据才出现的问题，即使查询出来的结果集很小，也会造成 Buffer Pool 污染。(**当索引失效，在全表扫描的时候**)

> 怎么解决出现 Buffer Pool 污染而导致缓存命中率下降的问题？

**思路：提高进入到 young 区域的门槛，就能有效地保证 young 区域里的热点数据不会被替换掉。**

MySQL 是这样做的，进入到 young 区域条件增加了一个**停留在 old 区域的时间判断**。

具体是这样做的，在对某个处在 old 区域的缓存页进行第一次访问时，就在它对应的控制块中记录下来这个访问时间：

- 如果后续的访问时间与第一次访问的时间**在某个时间间隔内**，那么**该缓存页就不会被从 old 区域移动到 young 区域的头部**；
- 如果后续的访问时间与第一次访问的时间**不在某个时间间隔内**，那么**该缓存页移动到 young 区域的头部**；

这个间隔时间是由 `innodb_old_blocks_time` 控制的，默认是 1000 ms。

**只有同时满足「被访问」与「在 old 区域停留时间超过 1 秒」两个条件，才会被插入到 young 区域头部**，这样就解决了 Buffer Pool 污染的问题 。



**脏页什么时候会被刷入磁盘？**

脏页需要被刷入磁盘，保证缓存和磁盘数据一致，但是若每次修改数据都刷入磁盘，则性能会很差，因此一般都会在一定时机进行批量刷盘。

InnoDB 的更新操作采用的是 **WAL(Write Ahead Log) 策略**，即先写日志，再写入磁盘，通过 redo log 日志让 MySQL 拥有了崩溃恢复能力。

下面几种情况会**触发脏页的刷新：**

- 当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘；
- Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘；
- MySQL 认为空闲时，后台线程会定期将适量的脏页刷入到磁盘；
- MySQL 正常关闭之前，会把所有的脏页刷入到磁盘；



**总结：**

Innodb 存储引擎设计了一个 **缓冲池（*Buffer Pool*）**，来提高数据库的读写性能。

Buffer Pool 以页为单位缓冲数据，可以通过 `innodb_buffer_pool_size` 参数调整缓冲池的大小，默认是 128 M。

Innodb 通过三种链表来管理缓页：

- Free List （空闲页链表），管理空闲页；
- Flush List （脏页链表），管理脏页；
- LRU List，管理脏页+干净页，将最近且经常查询的数据缓存在其中，而不常查询的数据就淘汰出去。；

InnoDB 对 LRU 做了一些优化，我们熟悉的 LRU 算法通常是将最近查询的数据放到 LRU 链表的头部，而 InnoDB 做 2 点优化：

- 将 LRU 链表 分为 **young 和 old 两个区域**，加入缓冲池的页，优先插入 old 区域；页被访问时，才进入 young 区域，目的是为了解决预读失效的问题。
- 当 **「页被访问」且「 old 区域停留时间超过 `innodb_old_blocks_time` 阈值（默认为1秒）」** 时，才会将页插入到 young 区域，否则还是插入到 old 区域，目的是为了解决批量数据访问，大量热数据淘汰的问题。

可以通过调整 `innodb_old_blocks_pct` 参数，设置 young 区域和 old 区域比例。

在开启了慢 SQL 监控后，如果你发现「偶尔」会出现一些用时稍长的 SQL，这可因为脏页在刷新到磁盘时导致数据库性能抖动。如果在很短的时间出现这种现象，就需要调大 Buffer Pool 空间或 redo log 日志的大小。





### Others



**MySQL提供的内置函数：**

1. 字符串函数：
   - `CONCAT()`：连接两个或多个字符串。
   - `SUBSTRING()`：从字符串中提取子字符串。
   - `UPPER()`、`LOWER()`：将字符串转换为大写或小写。
   - `LENGTH()`：返回字符串的长度。
   - `TRIM()`：去除字符串首尾的空格。
   - `REPLACE()`：替换字符串中的子字符串。
2. 数值函数：
   - `ABS()`：返回一个数的绝对值。
   - `ROUND()`：四舍五入到指定的小数位数。
   - `CEIL()`、`FLOOR()`：向上或向下取整。
   - `RAND()`：返回一个随机数。
3. 日期和时间函数：
   - `NOW()`：返回当前日期和时间。
   - `DATE()`、`TIME()`、`YEAR()`、`MONTH()`、`DAY()`：从日期/时间中提取部分信息。
   - `DATE_FORMAT()`：格式化日期/时间。
   - `DATEDIFF()`、`TIMEDIFF()`：计算日期/时间之间的差异。
4. 逻辑函数：
   - `IF()`、`CASE WHEN THEN END`：执行条件逻辑。
5. 聚合函数：
   - `SUM()`、`AVG()`、`MAX()`、`MIN()`：计算数据集的总和、平均值、最大值和最小值。
6. 分组函数：
   - `GROUP_CONCAT()`：将组内的值连接为一个字符串。
7. 系统函数：
   - `DATABASE()`：返回当前数据库名称。
   - `USER()`：返回当前用户。
   - `VERSION()`：返回MySQL服务器版本。





## 图解 Redis



### 面试篇



Redis 是一种**基于内存的数据库**，对数据的读写操作都是在内存中完成，因此**读写速度非常快**，常用于**缓存，消息队列、分布式锁等场景**。除此之外，Redis 还支持**事务 、持久化、Lua 脚本、多种集群方案（主从复制模式、哨兵模式、切片机群模式）、发布/订阅模式，内存淘汰机制、过期删除机制**等等。

对数据类型的操作都是**原子性**的，因为执行命令由单线程负责的，不存在并发竞争的问题。



为什么用Redis作为MySQL的缓存？ 因为 **Redis 具备「高性能」和「高并发」两种特性**。

- 高性能：直接操作内存，所以速度相当快。（存在 Redis 和 MySQL 双写一致性问题）
- 高并发：直接访问 Redis 能够承受的请求是远远大于直接访问 MySQL 



Redis 提供了丰富的数据类型，常见的有五种数据类型：**String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）**。后面又支持了四种数据类型： **BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、GEO（3.2 版新增）、Stream（5.0 版新增）**。

- String 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。

  - 底层数据结构实现主要是 **SDS（简单动态字符串）**
  - **SDS 不仅可以保存文本数据，还可以保存二进制数据**。（使用 len 属性而不是空字符判断是否末尾）
  - **SDS 获取字符串长度的时间复杂度是 O(1)**。（用 len 属性记录了长度。）
  - **Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出**。（拼接前自动判断是否需要扩容）

- List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。

  - 底层数据结构是由**双向链表或压缩列表**实现的。（默认情况下元素小于512，元素值小于64字节用压缩列表，其余用双向链表）
  - 3.2 版本之后，就只能用 quicklist 实现。

- Hash 类型：缓存对象、购物车等。

  - 底层数据结构是由**压缩列表或哈希表**实现的（默认情况下元素小于512，元素值小于64字节用压缩列表，其余用哈希表）
  - 7.0 版本后，就只能用 listpack 实现。

- Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。

  - 底层数据结构是由**哈希表或整数集合**实现（默认情况下元素小于512个用整数集合，其余用哈希表）

- Zset 类型：排序场景，比如排行榜、电话和姓名排序等。

  - 底层数据结构是由**压缩列表或跳表**实现的。（默认情况下元素小于128，元素值小于64字节用压缩列表，其余用跳表）
  - 7.0 版本后，就只能用 listpack 实现。

  

**Redis 单线程指的是「接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端」这个过程是由一个线程（主线程）来完成的**，但是，**Redis 程序并不是单线程的**，Redis 在启动的时候，是会**启动后台线程**（BIO: Background I/O）的。

之所以 Redis 为**「关闭文件、AOF 刷盘、释放内存」**这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。关闭文件、AOF 刷盘、释放内存这三个任务都有各自的任务队列。



之所以 **Redis 采用单线程（网络 I/O 和执行命令）那么快，有如下几个原因：**

- 大部分操作都在内存中完成
- 避免了多线程之间的竞争
- I/O多路复用机制



**Redis 6.0 之前为什么使用单线程？**

**CPU 并不是制约 Redis 性能表现的瓶颈所在**

使用了单线程后，可维护性高，多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，**增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗**。

**Redis 6.0 之后为什么使用多线程？**

**随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上**。

为了提高网络 I/O 的并行度，Redis 6.0 **对于网络 I/O 采用多线程来处理**。但是对于命令的执行，Redis 仍然使用单线程来处理。

Redis 官方表示，**Redis 6.0 版本引入的多线程 I/O 特性对性能提升至少是一倍以上**。



**Redis 共有三种数据持久化的方式：**

- **AOF 日志 (Append-Only File)**：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；
- **RDB (Redis DataBase)快照**：将某一时刻的内存数据，以二进制的方式写入磁盘；
- **混合持久化方式**：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；



**AOF 日志是如何实现的？**

Redis 在**执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件**里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。

> 为什么先执行命令，再把数据写入日志呢？

好处：**避免额外的检查开销、不会阻塞当前写操作命令的执行**

风险：**数据可能会丢失、可能阻塞其他操作**

> AOF 写回策略有几种？

实际上也不是直接写到磁盘中的，先到 page cache，然后写入磁盘。 

写入的时机：在 Redis.conf 配置文件中的 appendfsync 配置项可以有以下 3 种参数。

- **Always**，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；
- **Everysec**，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后**每隔一秒**将缓冲区里的内容写回到硬盘；
- **No**，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。

> AOF 日志过大，会触发什么机制？

**AOF 重写机制**，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。

AOF 重写机制是在重写时，**读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」**，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。(**只保留最后的结果，历史命令不保留了**)

> 重写 AOF 日志的过程是怎样的？

**重写 AOF 过程是由后台子进程 *bgrewriteaof (background rewrite aof)* 来完成的**

但是在重写过程中，主进程依然可以正常处理命令，可能会出现数据不一致。

为此，Redis 设置了一个 **AOF 重写缓冲区**，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会**同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」**。

当子进程完成 AOF 重写工作（**扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志**）后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。

主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：

- 将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；
- 新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。

信号函数执行完后，主进程就可以继续像往常一样处理命令了。



**RDB 快照是如何实现的？**

RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。

在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。

> RDB 做快照时会阻塞线程吗？

Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：

- 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，**会阻塞主线程**；
- 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以**避免主线程的阻塞**；

Redis 的快照是**全量快照**，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。所以执行快照是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。

> RDB 在执行快照的时候，数据能修改吗？

可以的，执行 bgsave 过程中，Redis 依然**可以继续处理操作命令**的，也就是数据是能被修改的，关键的技术就在于**写时复制技术（Copy-On-Write, COW）。**



**为什么会有混合持久化？**

为了集成了两者的优点， Redis 4.0 提出了**混合使用 AOF 日志和内存快照**，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。

混合持久化工作在 **AOF 日志重写过程**，当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。

也就是说，使用了混合持久化，AOF 文件的**前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据**。

**混合持久化优点：**

- 混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。

**混合持久化缺点：**

- AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；
- 兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。



**Redis  集群**



**Redis 如何实现服务高可用？**

要想设计一个高可用的 Redis 服务，一定要从 Redis 的多服务节点来考虑，比如 Redis 的主从复制、哨兵模式、切片集群。

> 主从复制

主从复制是 Redis 高可用服务的最基础的保证，实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是「读写分离」的方式。

主从服务器之间的命令复制是**异步**进行的。无法实现强一致性保证（主从数据时时刻刻保持一致），数据不一致是难以避免的。

> 哨兵模式

当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复。

为了解决这个问题，Redis 增加了哨兵模式（**Redis Sentinel**），因为哨兵模式做到了可以监控主从服务器，并且提供**主从节点故障转移的功能。**

> 切片集群模式

当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 **Redis 切片集群**（Redis Cluster ）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。



**集群脑裂导致数据丢失怎么办？**

> 什么是脑裂？

由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。

> 解决方案

当主节点发现**从节点下线或者通信超时的总数量小于阈值**时，那么禁止主节点进行写数据，直接把错误返回给客户端。

**原主库会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了**。

**等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。**



**Redis 过期删除与内存淘汰**



**Redis 使用的过期删除策略是什么？**

每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个**过期字典**（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。

当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：

- 如果不在，则正常读取键值；
- 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。

Redis 使用的过期删除策略是「**惰性删除+定期删除**」这两种策略配和使用。

> 惰性删除

**不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。**

优点：资源消耗少。

缺点：占用内存。

> 定期删除

**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。**

优点：减少内存占用。

缺点：难以确定删除操作的执行时长和频率。





**Redis 持久化时，对过期键会如何处理？**

Redis 持久化文件有两种格式：RDB（Redis Database）和 AOF（Append Only File）

RDB 文件分为两个阶段，RDB 文件生成阶段和加载阶段。

- **RDB 文件生成阶段**：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，**过期的键「不会」被保存到新的 RDB 文件中**，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响。

- RDB 加载阶段

  ：RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况：

  - **如果 Redis 是「主服务器」运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中**。所以过期键不会对载入 RDB 文件的主服务器造成影响；
  - **如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中**。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响。

AOF 文件分为两个阶段，AOF 文件写入阶段和 AOF 重写阶段。

- **AOF 文件写入阶段**：当 Redis 以 AOF 模式持久化时，**如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值**。
- **AOF 重写阶段**：执行 AOF 重写时，会对 Redis 中的键值对进行检查，**已过期的键不会被保存到重写后的 AOF 文件中**，因此不会对 AOF 重写造成任何影响。



**Redis 主从模式中，对过期键会如何处理？**

**从库不会进行过期扫描，从库对过期的处理是被动的**。依然可以从从库中获取过期key对应的值。

从库的过期键处理依靠主服务器控制，**主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库**，从库通过执行这条 del 指令来删除过期的 key。



**Redis 内存满了，会发生什么？**

触发**内存淘汰机制**，共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。

1. 不进行数据淘汰的策略
   1. noeviction：超过最大内存，不淘汰，直接不提供服务，返回错误。
2. 进行数据淘汰的策略
   1. 在设置了过期时间的数据中进行淘汰
      1. **volatile-random**：随机淘汰设置了过期时间的任意键值；
      2. **volatile-ttl**：优先淘汰更早过期的键值。
      3. **volatile-lru**（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；
      4. **volatile-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；
   2. 在所有数据范围内进行淘汰
      1. **allkeys-random**：随机淘汰任意键值;
      2. **allkeys-lru**：淘汰整个键值中最久未使用的键值；
      3. **allkeys-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。



**LRU 算法和 LFU算法有什么区别？**

**LRU** 全称是 Least Recently Used 翻译为**最近最少使用**，会选择淘汰最近最少使用的数据。

Redis 实现的是一种**近似 LRU 算法**，目的是为了更好的节约内存，它的**实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间**。

当 Redis 进行内存淘汰时，会使用**随机采样的方式来淘汰数据**，它是随机取 5 个值（此值可配置），然后**淘汰最久没有使用的那个**。

**无法解决缓存污染问题**，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。

LFU 全称是 Least Frequently Used 翻译为**频率最少使用**，LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。

LFU 算法相比于 LRU 算法的实现，多记录了**「数据的访问频次」**的信息。

**在 LRU 算法中**，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。

**在 LFU 算法中**，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，用来记录 key 的访问时间戳；低 8bit 存储 logc(Logistic Counter)，用来记录 key 的访问频次。



**Redis 缓存设计**

**如何避免缓存雪崩、缓存击穿、缓存穿透？**

> 如何避免缓存雪崩？

**缓存雪崩：缓存大面积过期，大量请求打到数据库中**

两种解决方案：**将缓存失效时间随机打散、设置缓存不过期**

> 如何避免缓存击穿？

**缓存击穿：某个热点数据过期，大量请求打到数据库**。（可以认为缓存击穿是缓存雪崩的一个**子集**）

两种解决方案：**互斥锁方案（确保只有一个读请求到数据库）、不给热点数据设置过期时间**

> 如何避免缓存穿透？

**缓存穿透：既不在缓存中，也不在数据库中**

三种解决方案：**非法请求的限制、设置空值或者默认值、使用布隆过滤器快速判断是否存在**





**如何设计一个缓存策略，可以动态缓存热点数据？**

热点数据动态缓存的策略总体思路：**通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据**。



**常见的缓存更新策略**

- Cache Aside（旁路缓存）策略；
- Read/Write Through（读穿 / 写穿）策略；
- Write Back（写回）策略；

实际开发中，Redis 和 MySQL 的更新策略用的是 Cache Aside，另外两种策略应用不了。



> Cache Aside（旁路缓存）策略

Cache Aside（旁路缓存）策略是最常用的，应用程序直接与「数据库、缓存」交互，并负责对缓存的维护，该策略又可以细分为「读策略」和「写策略」。

**写策略的步骤：**

- 先更新数据库中的数据，再删除缓存中的数据。（**缓存的写入通常要远远快于数据库的写入，所以很难出现数据不一致**）

**读策略的步骤：**

- 如果读取的数据命中了缓存，则直接返回数据；
- 如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。

注意，写策略的步骤的顺序不能倒过来，即**不能先删除缓存再更新数据库**，原因是在「读+写」并发的时候，会出现缓存和数据库的数据不一致性的问题。

**Cache Aside 策略适合读多写少的场景，不适合写多的场景**，因为当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。



> Read/Write Through（读穿 / 写穿）策略

Read/Write Through（读穿 / 写穿）策略原则是应用程序只和缓存交互，不再和数据库交互，而是由缓存和数据库交互，相当于更新数据库的操作由缓存自己代理了。

***1、Read Through 策略***

先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库查询数据，并将结果写入到缓存组件，最后缓存组件将数据返回给应用。

***2、Write Through 策略***

当有数据更新的时候，先查询要写入的数据在缓存中是否已经存在：

- 如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成。
- 如果缓存中数据不存在，直接更新数据库，然后返回；



> Write Back（写回）策略

Write Back（写回）策略在更新数据的时候，只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行。

**但Redis 并没有异步更新数据库的功能。**

**Write Back 策略特别适合写多的场景，但是带来的问题是，数据不是强一致性的，而且会有数据丢失的风险**



**Redis 实战**



**Redis 如何实现延迟队列？**

延迟队列是指把当前要做的事情，往后推迟一段时间再做。

在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。



**Redis 的大 Key 如何处理？**

> 什么是 Redis 大 key？

大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。

一般而言，下面这两种情况被称为大 key：

- String 类型的值大于 10 KB；
- Hash、List、Set、ZSet 类型的元素的个数超过 5000个；

> 大 key 会造成什么问题？

- **客户端超时阻塞**。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。
- **引发网络阻塞**。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。
- **阻塞工作线程**。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。
- **内存分布不均**。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。

> 如何找到大 key ？

***1、redis-cli --bigkeys 查找大key***

***2、使用 SCAN 命令查找大 key***

***3、使用 RdbTools 工具查找大 key***

> 如何删除大 key？

删除操作的本质是要释放键值对占用的内存空间。

如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞。

因此，删除大 key 这一个动作，我们要小心。具体要怎么做呢？这里给出两种方法：

- 分批次删除
- 异步删除（Redis 4.0版本以上）



**Redis 管道有什么用？**

管道技术（Pipeline）是客户端提供的一种批处理技术，用于**一次处理多个 Redis 命令**，从而提高整个交互的性能。

**管道技术可以解决多个命令执行时的网络等待**

管道技术本质上是客户端提供的功能，而非 Redis 服务器端的功能。



**Redis 事务支持回滚吗？**

MySQL 在执行事务时，会提供回滚机制，当事务执行发生错误时，事务中的所有操作都会撤销，已经修改的数据也会被恢复到事务执行前的状态。

**Redis 中并没有提供回滚机制**，虽然 Redis 提供了 DISCARD 命令，但是这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。

**Redis 并不一定保证原子性**（原子性：事务中的命令要不全部成功，要不全部失败）。



**如何用 Redis 实现分布式锁？**

分布式锁是用于分布式环境下并发控制的一种机制，用于控制某个资源在同一时刻只能被一个应用所使用。

基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件：

- NX 实现加锁。
- EX/PX 设置过期时间，防止锁无法释放。
- 设置唯一标识，用于标识客户端。

满足三个条件的分布式命令如下：

``` sql
SET lock_key unique_value NX PX 10000 
```

解锁的过程就是将 lock_key 键删除（del lock_key），但**要保证执行操作的客户端就是加锁的客户端**。


释放锁时，先比较 unique_value 是否相等，相等才进行解锁。由于有两个操作，需要**使用Lua脚本来保证解锁的原子性**。

**通过使用 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁**

> 基于 Redis 实现分布式锁有什么优缺点？

基于 Redis 实现分布式锁的**优点**：

1. 性能高效（这是选择缓存实现分布式锁最核心的出发点）。
2. 实现方便。很多研发工程师选择使用 Redis 来实现分布式锁，很大成分上是因为 Redis 提供了 setnx 方法，实现分布式锁很方便。
3. 避免单点故障（因为 Redis 是跨集群部署的，自然就避免了单点故障）。

基于 Redis 实现分布式锁的**缺点**：

- 超时时间不好设置

  。如果锁的超时时间设置过长，会影响性能，如果设置的超时时间过短会保护不到共享资源。

  - **那么如何合理设置超时时间呢？** 我们可以基于续约的方式设置超时时间：先给锁设置一个超时时间，然后启动一个守护线程，让守护线程在一段时间后，重新设置这个锁的超时时间。实现方式就是：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可，不过这种方式实现起来相对复杂。

- **Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性**。如果在 Redis 主节点获取到锁后，在没有同步到其他节点时，Redis 主节点宕机了，此时新的 Redis 主节点依然可以获取锁，所以多个应用服务就可以同时获取到锁。

> Redis 如何解决集群情况下分布式锁的可靠性？

为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock（红锁）。

Redlock 算法的基本思路，**是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败**。

**加锁成功要同时满足两个条件如果有超过半数的 Redis 节点成功的获取到了锁，并且总耗时没有超过锁的有效时间，那么就是加锁成功**

加锁失败后，客户端向**所有 Redis 节点发起释放锁的操作**，释放锁的操作和在单节点上释放锁的操作一样，只要执行释放锁的 Lua 脚本就可以了。





### 数据类型篇



#### Redis 常见数据类型和应用场景



**String**

String 是最基本的 key-value 结构，key 是唯一标识，value 是具体的值，value其实不仅是字符串， 也可以是数字（整数或浮点数），value 最多可以容纳的数据长度是 `512M`。

String 类型的**底层的数据结构实现主要是 int 和 SDS（简单动态字符串）。**

- **SDS 不仅可以保存文本数据，还可以保存二进制数据**。（ `SDS` 使用 `len` 属性的值而不是空字符来判断字符串是否结束）
- **SDS 获取字符串长度的时间复杂度是 O(1)**。（SDS 结构里用 `len` 属性记录了字符串长度，所以复杂度为 `O(1)`）
- **Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出**。（拼接字符串之前会检查，空间不够自动扩容）

字符串对象的内部编码（encoding）有 3 种 ：**int、embstr、raw **。

看到`embstr`和`raw`编码都会使用`SDS`来保存值，但不同之处在于`embstr`会通过一次内存分配函数来分配一块连续的内存空间来保存`redisObject`和`SDS`，而`raw`编码会通过调用两次内存分配函数来分别分配两块空间来保存`redisObject`和`SDS`。

`embstr`内存分配只需一次，释放对象也只需调用一次内存释放函数，内存连续有利于提升性能。但**embstr编码的字符串对象实际上是只读的**。

**应用场景：**

1. **缓存对象**
   1. 直接缓存整个对象的 JSON，命令例子： `SET user:1 '{"name":"xiaolin", "age":18}'`。
   2. 采用将 key 进行分离为 user:ID:属性，采用 MSET 存储，用 MGET 获取各属性值，命令例子： `MSET user:1:name xiaolin user:1:age 18 user:2:name xiaomei user:2:age 20`。
2. **常规计数：**因为 Redis 处理命令是单线程，所以执行命令的过程是原子的。因此 String 数据类型适合计数场景，比如计算访问次数、点赞、转发、库存数量等等。
3. **分布式锁：**SET 命令有个 NX 参数可以实现「key不存在才插入」，可以用它来实现分布式锁
4. **共享Session信息：**分布式系统使用同一个 Redis 存储 Session





**List**

List 列表是简单的字符串列表，**按照插入顺序排序**，可以从头部或尾部向 List 列表添加元素。

列表的最大长度为 `2^32 - 1`，也即每个列表支持超过 `40 亿`个元素。（4个字节）

List 类型的底层数据结构是由**双向链表或压缩列表**实现的。（默认情况下元素个数小于512个，元素值都小于64字节用压缩列表，否者双向链表）

**在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表**。

**应用场景：**

1. **消息队列：**（List和Stream都可以实现）
   1. 消息队列在存取消息时，必须要满足三个需求，分别是**消息保序、处理重复的消息和保证消息可靠性**。
   2. 消息保序：生成者 LPUSH , 消费者 RPOP。为什么不让消费者一直调用命令检查是否有消息品，Redis提供了 BRPOP 命令。**BRPOP命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据**。
   3. 处理重复信息：**List 并不会为每个消息生成 ID 号，所以我们需要自行为每个消息生成一个全局唯一ID**`LPUSH mq "111000102:stock:99"` 这样就将一条全局 ID 为 111000102、库存量为 99 的消息插入了消息队列。
   4. 保证消息可靠性：为了留存消息，List 类型提供了 `BRPOPLPUSH` 命令，这个命令的**作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存**。
   5. 总结：
      1. 消息保序：使用 LPUSH + RPOP；
      2. 阻塞读取：使用 BRPOP；
      3. 重复消息处理：生产者自行实现全局唯一 ID；
      4. 消息的可靠性：使用 BRPOPLPUSH
   6. **List 不支持多个消费者消费同一条消息，List 类型并不支持消费组的实现**。（Stream可以）



**Hash**

Hash 是一个键值对（key - value）集合，其中 value 的形式如： `value=[{field1，value1}，...{fieldN，valueN}]`。Hash 特别适合用于存储对象。

**Hash 与 String 对象的区别：**

- String: uid:1:name --> tom; uid:1:age --> 23
- Hash: uid:1 --> [{name, tom},{age, 23}]

Hash 类型的底层数据结构是由**压缩列表或哈希表**实现的，7.0 后listpack。

**应用场景：**

1. **缓存对象**
   1. 一般对象用 String + Json 存储，对象中**某些频繁变化的属性**可以考虑抽出来用 Hash 类型存储。
2. 购物车
   1. 以用户 id 为 key，商品 id 为 field，商品数量为 value



**Set**

Set 类型是一个**无序并唯一的键值集合**，它的存储顺序不会按照插入的先后顺序进行存储。

一个集合最多可以存储 `2^32-1` 个元素。概念和数学中个的集合基本类似，可以交集，并集，差集等等，所以 Set 类型除了支持集合内的增删改查，同时还支持多个集合取交集、并集、差集。（4个字节）

Set 类型的底层数据结构是由**哈希表或整数集合**实现的。（元素都是整数且个数小于512个，使用整数集合，否则哈希表。）

**应用场景：**

Set 类型比较适合用来数据去重和保障数据的唯一性，还可以用来统计多个集合的交集、错集和并集等，当我们存储的数据是无序并且需要去重的情况下，比较适合使用集合类型进行存储。

**Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞**。

1. **点赞**：Set 类型可以保证一个用户只能点一个赞
2. **共同关注：**Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号等。
3. **抽奖活动：**存储某活动中中奖的用户名 ，Set 类型因为有去重功能，可以保证同一个用户不会中奖两次。



**Zset**

Zset 类型（有序集合类型）相比于 Set 类型多了一个**排序属性 score（分值）**，对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序集合的元素值，一个是排序值。

有序集合保留了集合不能有重复成员的特性（分值可以重复），但不同的是，有序集合中的元素可以排序。

Zset 类型的底层数据结构是由**压缩列表或跳表** skiplist 实现的。（元素个数小于128个，每个元素值小于64字节，使用压缩列表，否则跳表）

**在 Redis 7.0 中，压缩列表 ziplist数据结构已经废弃了，交由 listpack 数据结构来实现了。**

**应用场景：**

1. **排行榜**：有序集合比较典型的使用场景就是排行榜。
2. **电话、姓名排序：不要在分数不一致的 SortSet 集合中去使用 ZRANGEBYLEX和 ZREVRANGEBYLEX 指令，因为获取的结果会不准确。**



**BitMap**

Bitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行`0|1`的设置，表示某个元素的值或者状态，时间复杂度为O(1)。

由于 bit 是计算机中最小的单位，使用它进行储存将非常节省空间，特别适合一些数据量大且使用**二值统计的场景**。

Bitmap 本身是**用 String 类型作为底层数据结构实现**的一种统计二值状态的数据类型。**可以把 Bitmap 看作是一个 bit 数组。**

**应用场景：（适合二值状态统计的场景）**

1. **签到统计**
2. **判断用户是否登录态**
3. **连续签到用户总数**



**HyperLogLog**

HyperLogLog **提供不精确的去重计数**。HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的内存空间总是固定的、并且是很小的。HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。

在 Redis 里面，**每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 `2^64` 个不同元素的基数**，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。

**应用场景：**

1. **百万级网页UV计数**（UV：Unique visitor）



**GEO**

主要用于存储地理位置信息，并对存储的信息进行操作。

GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。

可以把经纬度保存到 Sorted Set 中，利用 Sorted Set 提供的“按权重进行有序范围查找”的特性，实现 LBS 服务中频繁使用的“搜索附近”的需求。

**应用场景：**

1. **滴滴打车**

``` sql
# 车辆id=33，所在位置：经纬度信息
GEOADD cars:locations 116.034579 39.030452 33
# 用户所在位置：经纬度信息。返回以此为中心5km内前十个车辆信息，从进到远（升序）
GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10
```



**Stream**

专门为消息队列设计的数据类型。它支持消息的持久化、支持自动生成全局唯一 ID、支持 ack 确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠。

应用场景：

1. 消息队列
   1. **想要实现阻塞读（当没有数据时，阻塞住），可以调用 XRAED 时设定 BLOCK 配置项**，实现类似于 List 中 BRPOP 的阻塞读取操作。
   2. 特有功能（List 不支持的）
      1. Stream 可以以使用 **XGROUP 创建消费组**。**消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了，即同一个消费组里的消费者不能消费同一条消息**。**不同消费组的消费者可以消费同一条消息（但是有前提条件，创建消息组的时候，不同消费组指定了相同位置开始读取消息）**。
      2. Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”。（**保证宕机重启后仍能继续处理未完成消息**）**在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息**。
   3. 总结
      1. 消息保序：XADD/XREAD
      2. 阻塞读取：XREAD block
      3. 重复消息处理：Stream 在使用 XADD 命令，会自动生成全局唯一 ID；
      4. 消息可靠性：内部使用 PENDING List 自动保存消息，使用 XPENDING 命令查看消费组已经读取但是未被确认的消息，消费者使用 XACK 确认消息；
      5. 支持消费组形式消费数据

> Redis 基于 Stream 消息队列与专业的消息队列有哪些差距？

***Redis Stream 消息会丢失吗？***

消息队列，其实就分为三大块：**生产者、队列中间件、消费者**。要保证三个环节都不丢失数据。

生产者和消费者都不会丢，中间件会丢：

- AOF 持久化配置为每秒写盘，但这个写盘过程是异步的，Redis 宕机时会存在数据丢失的可能
- 主从复制也是异步的，主从切换时，也存在丢失数据的可能。

像 RabbitMQ 或 Kafka 这类专业的队列中间件，在使用时是部署一个集群，生产者在发布消息时，队列中间件通常会写「多个节点」，也就是有多个副本，这样一来，即便其中一个节点挂了，也能保证集群的数据不丢失。

***Redis Stream 消息可堆积吗？***

Redis 的数据都**存储在内存中**，这就意味着一旦发生消息积压，则会导致 Redis 的内存持续增长，如果超过机器内存上限，就会面临被 OOM 的风险。所以得指定上限，超过上限，就丢失消息。

但 Kafka、RabbitMQ 专业的消息队列它们的数据都是**存储在磁盘上**，当消息积压时，无非就是多占用一些磁盘空间。



> Redis 发布/订阅机制为什么不可以作为消息队列？

1. 不具备「数据持久化」的能力，
2. 订阅者离线重连之后不能消费之前的历史消息，
3. 消息积压时，消费端会被强行断开。

发布/订阅机制只适合即时通讯的场景，比如**构建哨兵集群**的场景采用了发布/订阅机制。



**总结：**

Redis 五种数据类型的应用场景：

- String 类型的应用场景：缓存对象、常规计数、分布式锁、共享session信息等。
- List 类型的应用场景：消息队列（有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。
- Hash 类型：缓存对象、购物车等。
- Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。
- Zset 类型：排序场景，比如排行榜、电话和姓名排序等。

Redis 后续版本又支持四种数据类型，它们的应用场景如下：

- BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；
- HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；
- GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；
- Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。

针对 Redis 是否适合做消息队列，关键看你的业务场景：

- 如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。
- 如果你的业务有海量消息，消息积压的概率比较大，并且不能接受数据丢失，那么还是用专业的消息队列中间件吧。



#### Redis 数据结构

> Redis为什么那么快？

1. 所有的操作都在内存上
2. 实现的数据结构，使得我们对数据进行增删查改操作时，Redis 能高效的处理。

**Redis 数据结构并不是指 String（字符串）对象、List（列表）对象、Hash（哈希）对象、Set（集合）对象和 Zset（有序集合）对象，因为这些是 Redis 键值对中值的数据类型，也就是数据的保存形式，这些对象的底层实现的方式就用到了数据结构**。

![image-20240416111319240](.././assets/image-20240416111319240.png)

**新旧版本的数据结构，共有 9 种数据结构：SDS、双向链表、压缩列表、哈希表、跳表、整数集合、quicklist、listpack。**



**键值对数据库是怎么实现的？**

Redis 的键值对中的 key 就是字符串对象，而 **value 可以是字符串对象，也可以是集合数据类型的对象**，比如 List 对象、Hash 对象、Set 对象和 Zset 对象。

Redis 是**使用了一个「哈希表」保存所有键值对**，哈希表的最大好处就是让我们可以用 O(1) 的时间复杂度来快速查找到键值对。**哈希表其实就是一个数组，数组中的元素叫做哈希桶。**

**哈希桶**存放的是指向键值对数据的指针（dictEntry*），这样通过指针就能找到键值对数据，然后因为键值对的值可以保存字符串对象和集合数据类型的对象，所以键值对的数据结构中并不是直接保存值本身，而是保存了 void * key 和 void * value 指针，分别指向了实际的键对象和值对象，这样一来，即使值是集合数据，也可以通过 void * value 指针找到。

![image-20240416112227177](.././assets/image-20240416112227177.png)



**SDS**

C 语言的字符串不足之处以及可以改进的地方：

- 获取字符串长度的时间复杂度为 O（N）；
- 字符串的结尾是以 “\0” 字符标识，字符串里面不能包含有 “\0” 字符，因此不能保存二进制数据；
- 字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止；

Redis 实现的 SDS 的结构就把上面这些问题解决了.

Redis 的 SDS 结构在原本字符数组之上，增加了三个元数据：len(记录字符串长度)、alloc(计算所需空间)、flags(表示不同类型)，用来解决 C 语言字符串的缺陷。还有一个 buf[]，用来实际保存数据。

**alloc**

- 如果所需的 sds 长度**小于 1 MB**，那么最后的扩容是按照**翻倍扩容**来执行的，即 2 倍的newlen
- 如果所需的 sds 长度**超过 1 MB**，那么最后的扩容长度应该是 newlen **+ 1MB**。

**扩容时多给容量，有效的减少内存分配次数**。

**flags**

包括5 种类型，主要**区别就在于，它们数据结构中的 len 和 alloc 成员变量的数据类型不同**。

**为了能灵活保存不同大小的字符串，从而有效节省内存空间**。



**链表**

Redis 的 List 对象的底层实现之一就是链表。C 语言本身没有链表这个数据结构的，所以 Redis 自己设计了一个链表数据结构。（双向链表）

Redis 在 listNode 结构体基础上又封装了 list 这个数据结构，这样操作起来会更方便。

Redis 的链表实现优点如下：

- listNode 链表节点的结构里带有 prev 和 next 指针，**获取某个节点的前置节点或后置节点的时间复杂度只需O(1)，而且这两个指针都可以指向 NULL，所以链表是无环链表**；
- list 结构因为提供了表头指针 head 和表尾节点 tail，所以**获取链表的表头节点和表尾节点的时间复杂度只需O(1)**；
- list 结构因为提供了链表节点数量 len，所以**获取链表中的节点数量的时间复杂度只需O(1)**；
- listNode 链表节使用 void* 指针保存节点值，并且可以通过 list 结构的 dup、free、match 函数指针为节点设置该节点类型特定的函数，因此**链表节点可以保存各种不同类型的值**；

链表的缺陷也是有的：

- 链表每个节点之间的内存都是不连续的，意味着**无法很好利用 CPU 缓存**。能很好利用 CPU 缓存的数据结构就是数组，因为数组的内存是连续的，这样就可以充分利用 CPU 缓存来加速访问。
- 还有一点，保存一个链表节点的值都需要一个链表节点结构头的分配，**内存开销较大**。



**压缩列表**

压缩列表的最大特点，就是它被设计成一种内存紧凑型的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销。

但是，压缩列表的缺陷也是有的：

- 不能保存过多的元素，否则查询效率就会降低；
- 新增或修改某个元素时，压缩列表占用的内存空间需要重新分配，甚至可能引发连锁更新的问题。

压缩列表是 Redis 为了节约内存而开发的，它是**由连续内存块组成的顺序型数据结构**，有点类似于数组。

**根据数据大小和类型进行不同的空间大小分配的设计思想，正是 Redis 为了节省内存而采用的**。

**压缩列表新增某个元素或修改某个元素时，如果空间不不够，压缩列表占用的内存空间就需要重新分配。而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降**。前一个大，后面prevlen变大，整体变大，后续prevlen变大，整体变大，开始连锁反应。

因此，**压缩列表只会用于保存的节点数量不多的场景**，只要节点数量足够小，即使发生连锁更新，也是能接受的。



**哈希表** （字典）

哈希表中的每一个 key 都是独一无二的，程序可以根据 key 查找到与之关联的 value，或者通过 key 来更新 value，又或者根据 key 来删除整个 key-value等等。

Redis 的 Hash 对象的底层实现之一是压缩列表，另外一个底层实现就是哈希表。

哈希表优点在于，它**能以 O(1) 的复杂度快速查询数据**。

**Redis 采用了「链式哈希」来解决哈希冲突**，在不扩容哈希表的前提下，将具有相同哈希值的数据串起来，形成链接起，以便这些数据在表中仍然可以被查询到。

链式哈希局限性也很明显，随着链表长度的增加，在查询这一位置上的数据的耗时就会增加，毕竟链表的查询的时间复杂度是 O(n)。

要想解决这一问题，就需要进行 rehash，也就是对哈希表的大小进行扩展。

**rehash：**将「哈希表 1 」的数据迁移到「哈希表 2」 中

**存在的问题：如果「哈希表 1 」的数据量非常大，那么在迁移至「哈希表 2 」的时候，因为会涉及大量的数据拷贝，此时可能会对 Redis 造成阻塞，无法服务其他请求**。

**渐进式 rehash**，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。

在渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。新增一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作。

**触发 rehash 操作的条件，主要有两个：**

- **当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。**
- **当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。**

（***负载因子 = 哈希表已保存节点数量 / 哈希表大小***）



**整数集合**

整数集合是 Set 对象的底层实现之一。当一个 Set 对象只包含整数值元素，并且元素数量不大时，就会使用整数集这个数据结构作为底层实现。

整数集合会有一个升级规则，就是当我们将一个新元素加入到整数集合里面，如果新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级，也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里，当然升级的过程中，也要维持整数集合的有序性。

整数集合升级的过程不会重新分配一个新类型的数组，而是在原本的数组上扩展空间，然后在将每个元素按间隔类型大小分割，如果 encoding 属性值为 INTSET_ENC_INT16，则每个元素的间隔就是 16 位。

整数集合升级的好处是**节省内存资源**。

**但不支持降级操作**



**跳表**

链表的基础上，建立了多级索引。有点类似于二分法。

Redis 只有 Zset 对象的底层实现用到了跳表，跳表的优势是能支持平均 O(logN) 复杂度的节点查找。

zset 结构体里有两个数据结构：一个是跳表，一个是哈希表。这样的好处是既能进行高效的**范围查询**，也能进行高效单点查询。

Zset 对象在使用跳表作为数据结构的时候，是使用由「哈希表+跳表」组成的 struct zset，但是我们讨论的时候，都会说跳表是 Zset 对象的底层数据结构，而不会提及哈希表，是因为 struct zset 中的哈希表只是用于以常数复杂度获取元素权重，大部分操作都是跳表实现的。

**跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表**，这样的好处是能快读定位数据。

跳表是一个带有层级关系的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的 **zskiplistLevel 结构体类型的 level 数组**。

查找一个跳表节点的过程时，跳表会从头节点的最高层开始，逐一遍历每一层。在遍历某一层的跳表节点时，会用跳表节点中的 SDS 类型的元素和元素的权重来进行判断，共有两个判断条件：

- 如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。
- 如果当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。

跳表的相邻两层的节点数量的比例会影响跳表的查询性能。

**跳表的相邻两层的节点数量最理想的比例是 2:1，查找复杂度可以降低到 O(logN)**。

> 那怎样才能维持相邻两层的节点数量的比例为 2 : 1 呢？

Redis 则采用一种巧妙的方法是，**跳表在创建节点的时候，随机生成每个节点的层数**，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。具体的做法是，**跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数**。

> 为什么 Zset 的实现用跳表而不用平衡树（如 AVL树、红黑树等）？

- **从内存占用上来比较，跳表比平衡树更灵活一些**。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。
- **在做范围查找的时候，跳表比平衡树操作要简单**。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。
- **从算法实现难度上来比较，跳表比平衡树要简单得多**。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速。



**quicklist**

在 Redis 3.0 之前，List 对象的底层数据结构是双向链表或者压缩列表。在 Redis 3.2 的时候，List 对象的底层改由 quicklist 数据结构实现。其实 **quicklist 就是「双向链表 + 压缩列表」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。**

面对压缩列表的不足，quicklist 解决办法，**通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。**

quicklist 的结构体跟链表的结构体类似，都包含了表头和表尾，区别在于 quicklist 的节点是 quicklistNode。quicklistNode 结构体里包含了前一个节点和下一个节点指针，这样每个 quicklistNode 形成了一个双向链表。但是链表节点的元素不再是单纯保存元素值，而是保存了一个压缩列表，所以 quicklistNode 结构体里有个指向压缩列表的指针 *zl。

![image-20240416131256637](.././assets/image-20240416131256637.png)

在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点。而是会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构。

quicklist 会控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来规避潜在的连锁更新的风险，但是这并没有完全解决连锁更新的问题。



**listpack**

quicklist 虽然通过控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。**要想彻底解决这个问题，需要设计一个新的数据结构。**

Redis 在 5.0 新设计一个数据结构叫 listpack，目的是替代压缩列表，它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。

listpack 采用了压缩列表的很多优秀的设计，比如还是用一块连续的内存空间来紧凑地保存数据，并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据。

**listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题**。



> 压缩列表的entry为什么要保存prevlen呢？listpack改成len之后不会影响功能吗？

压缩列表的 entry 保存 prevlen 是为了实现节点从后往前遍历，知道前一个节点的长度，就可以计算前一个节点的偏移量。

listpack 一样可以支持从后往前遍历的。从当前列表项起始位置的指针开始，向左逐个字节解析，得到前一项的 entry-len 值。



### 持久化篇



#### AOF 持久化是怎么实现的？

Redis 里的 **AOF(*Append Only File*)** 持久化功能，**注意只会记录写操作命令，读操作命令是不会被记录的**。默认不开启。

AOF 日志文件其实就是普通的文本，我们可以通过 `cat` 命令查看里面的内容。

Redis 是先执行写操作命令后，才将该命令记录到 AOF 日志里，这样做有两个好处：

1. **避免额外的检查开销：**语句因为语法问题失败。
2. **不会阻塞当前写操作命令的执行：**写操作执行完，然后记录到AOF日志。

**风险：**

1. **丢失的风险：**操作完成，但是还没写到日志中就宕机了。
2. **可能会给「下一个」命令带来阻塞风险：**写入到日志的这个操作也是在主进程完成的（执行命令也是在主进程）



**3 种写回策略：**

1. Redis 执行完写操作命令后，会将命令追加到 `server.aof_buf` 缓冲区；
2. 然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 **page cache**，等待内核将数据写入硬盘；
3. **具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。**

Redis 提供了 3 种写回硬盘的策略，控制的就是上面说的第三步的过程。在 `redis.conf` 配置文件中的 `appendfsync` 配置项可以有以下 3 种参数可填：

1. **Always**，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；
2. **Everysec**，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后**每隔一秒**将缓冲区里的内容写回到硬盘；
3. **No**，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再**由操作系统决定**何时将缓冲区内容写回硬盘。

这 3 种写回策略都无法能完美解决「主进程阻塞」和「减少数据丢失」的问题，因为两个问题是对立的，偏向于一边的话，就会要牺牲另外一边，所以要根据业务选择。

深入到源码后，你就会发现这三种策略只是在控制 `fsync()` 函数的调用时机。



**AOF 重写机制**

Redis 为了避免 AOF 文件越写越大，提供了 **AOF 重写机制**，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。

AOF 重写机制是在重写时，**读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」**，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。（**相当于新的AOF文件中去重了，只记录最终的结果**）

**根据「键值对」当前的最新状态，然后用一条命令去记录键值对**

**如果 AOF 重写过程中失败了，现有的 AOF 文件就会造成污染**。所以要先写到新的AOF文件中。



**AOF 后台重写**

重写的操作不能放在主进程里，**是由后台子进程 *bgrewriteaof* 来完成的**

主进程在通过 `fork` 系统调用生成 bgrewriteaof 子进程时，操作系统会把主进程的「**页表**」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。这样一来，子进程就共享了父进程的物理内存数据了，这样能够**节约物理内存资源**，页表对应的页表项的属性会标记该物理内存的权限为**只读**。

当父进程或者子进程在向这个内存发起写操作时，CPU 就会触发**写保护中断**，这个写保护中断是由于违反权限导致的，然后操作系统会在「写保护中断处理函数」里进行**物理内存的复制**，并重新设置其内存映射关系，将父子进程的内存读写权限设置为**可读写**，最后才会对内存进行写操作，这个过程被称为「**写时复制(*Copy On Write*)**」。

写时复制顾名思义，**在发生写操作的时候，操作系统才会去复制物理内存**，这样是为了防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。

**有两个阶段会导致阻塞父进程：**

- 创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；
- 创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长；

如果此时**主进程修改了已经存在 key-value，就会发生写时复制，注意这里只会复制主进程修改的物理内存数据，没修改物理内存还是与子进程共享的**。

重写 AOF 日志过程中，如果主进程修改了已经存在 key-value，此时这个 **key-value 数据在子进程的内存数据就跟主进程的内存数据不一致**了。

为了解决这种数据不一致问题，Redis 设置了一个 **AOF 重写缓冲区**，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。

在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会**同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」**。

![image-20240416141722730](.././assets/image-20240416141722730.png)

在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:

- 执行客户端发来的命令；
- 将执行后的写命令追加到 「AOF 缓冲区」；
- 将执行后的写命令追加到 「AOF 重写缓冲区」；

当子进程完成 AOF 重写工作（*扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志*）后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。

主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：

- 将 **AOF 重写缓冲区**中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；
- 新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。

信号函数执行完后，主进程就可以继续像往常一样处理命令了。

在整个 AOF 后台重写过程中，除了发生**写时复制会对主进程造成阻塞，还有信号处理函数执行时也会对主进程造成阻塞**，在其他时候，AOF 后台重写都不会阻塞主进程。



#### RDB 快照是怎么实现的？

- AOF 文件的内容是操作命令；
- RDB 文件的内容是二进制数据。

RDB 快照就是记录**某一个瞬间的内存数据，记录的是实际数据**，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。

因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。

Redis 提供了两个命令来生成 RDB 文件，分别是 `save` 和 `bgsave`，他们的区别就在于是否在「主线程」里执行：

- 执行了 `save` 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，**会阻塞主线程**；
- 执行了 `bgsave` 命令，会创建一个子进程来生成 RDB 文件，这样可以**避免主线程的阻塞**；

RDB 文件的加载工作是在服务器启动时自动执行的，Redis 并没有提供专门用于加载 RDB 文件的命令。

Redis 还可以通过配置文件的选项来实现每隔一段时间自动执行一次 bgsave 命令，默认会提供以下配置：

``` sql
# 300 秒之内，对数据库进行了至少 10 次修改
save 300 10
```

别看选项名叫 save，实际上执行的是 bgsave 命令，也就是会创建子进程来生成 RDB 快照文件。

Redis 的快照是**全量快照**，记录所有数据，是一个比较重的操作。

通常可能设置至少 5 分钟才保存一次快照，这时如果 Redis 出现宕机等情况，则意味着最多可能丢失 5 分钟数据。这也是 RDB 的缺点，不能太频繁，否则会影响 Redis 的性能。但不能频繁意味着宕机是丢失的数据更多。

执行 bgsave 过程中，Redis 依然**可以继续处理操作命令**，也就是数据是能被修改的。

关键的技术就在于**写时复制技术（Copy-On-Write, COW）。**

如果主线程（父进程）要**修改共享数据里的某一块数据**（比如键值对 `A`）时，就会发生写时复制，于是这块数据的**物理内存就会被复制一份（键值对 `A'`）**，然后**主线程在这个数据副本（键值对 `A'`）进行修改操作**。与此同时，**bgsave 子进程可以继续把原来的数据（键值对 `A`）写入到 RDB 文件**。

即**发生了写时复制后，RDB 快照保存的是原本的内存数据**

极端情况下，**如果所有的共享内存都被修改，则此时的内存占用是原先的 2 倍。**所以要留意 RDB 时的内存变化。



**RDB 和 AOF 合体**

**混合使用 AOF 日志和内存快照**，也叫混合持久化。

``` sql
# 在 Redis 配置文件将下面这个配置项设置成 yes
aof-use-rdb-preamble yes
```

AOF 文件的**前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据**。

这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样**加载的时候速度会很快**。

加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得**数据更少的丢失**。



#### Redis 大 Key 对持久化有什么影响？

>  持久化大 Key 的时候，对 AOF 日志会影响什么？

**当使用 Always 策略的时候，如果写入是一个大 Key，主线程在执行 fsync()  函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的**。

当使用 Everysec 策略的时候，由于是异步执行 fsync() 函数，所以大 Key 持久化的过程（数据同步磁盘）不会影响主线程。

当使用 No 策略的时候，由于永不执行 fsync() 函数，所以大 Key 持久化的过程不会影响主线程。

> 大 Key 对 AOF 重写和 RDB 的影响

当 AOF 日志写入了很多的大 Key，AOF 日志文件的大小会很大，那么很快就会触发 **AOF 重写机制**。

AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 `fork()` 函数创建一个子进程来处理任务。

在通过 `fork()` 函数创建子进程的时候，虽然不会复制父进程的物理内存，但是**内核会把父进程的页表复制一份给子进程，如果页表很大，那么这个复制过程是会很耗时的，那么在执行 fork 函数的时候就会发生阻塞现象**。fork函数是主线程调用的，所以会阻塞主线程。

> 那什么时候会发生物理内存的复制呢？

「**写时复制(Copy On Write)**」

如果创建完子进程后，**父进程对共享内存中的大 Key 进行了修改，那么内核就会发生写时复制，会把物理内存复制一份，由于大 Key 占用的物理内存是比较大的，那么在复制物理内存这一过程中，也是比较耗时的，于是父进程（主线程）就会发生阻塞**。

额外知识点：如果 **Linux 开启了内存大页，会影响 Redis 的性能的**。所以要关闭内存大页。



**总结：**

当 AOF 写回策略配置了 Always 策略，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的。

AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 `fork()` 函数创建一个子进程来处理任务。会有两个阶段会导致阻塞父进程（主线程）：

- **创建子进程的途中**，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；
- 创建完子进程后，如果**父进程修改了共享数据中的大 Key，就会发生写时复制**，这期间会拷贝物理内存，由于大 Key 占用的物理内存会很大，那么在复制物理内存这一过程，就会比较耗时，所以有可能会阻塞父进程。

大 key 除了会影响持久化之外，还会有以下的影响。

- 客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。
- 引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。
- 阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。
- 内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。

如何避免大 Key 呢？

最好在设计阶段，就把大 key 拆分成一个一个小 key。或者，定时检查 Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，而是用 unlink 命令（Redis 4.0+）删除大 key，因为该命令的删除过程是异步的，不会阻塞主线程。



### 功能篇



#### Redis 过期删除策略和内存淘汰策略有什么区别？

> 设置过期时间的相关命令

``` bash
# 设置键值对 jim:25,100后过期
set jim 25 ex 100
# 查看 jim 的存活时间 time to live
ttl jim
# 永不过期，此时查看ttl返回 -1
persist jim
```

> 如何判定 key 是否过期？

**「过期字典」保存了数据库中所有 key 的过期时间。**

过期字典数据结构结构如下：

- 过期字典的 key 是一个指针，指向某个键对象；
- 过期字典的 value 是一个 long long 类型的整数，这个整数保存了 key 的过期时间；

当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：

- 如果不在，则正常读取键值；
- 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。

> 过期删除策略有哪些？

- 定时删除：**在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。**
  - 优点：可以保证过期 key 会被尽快删除，也就是内存可以被尽快地释放。因此，定时删除对内存是最友好的。
  - 缺点：在过期 key 比较多的情况下，删除过期 key 可能会占用相当一部分 CPU 时间，在内存不紧张但 CPU 时间紧张的情况下，将 CPU 时间用于删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。所以，定时删除策略对 CPU 不友好。
- 惰性删除：**不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。**
  - 优点：因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。
  - 缺点：如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好。
- 定期删除：**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。**（折中）
  - 优点：通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。
  - 缺点：
    - 内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。
    - 难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。

> Redis 过期删除策略是什么？

**Redis 选择「惰性删除+定期删除」这两种策略配和使用**，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。

Redis 的惰性删除策略由 db.c 文件中的 `expireIfNeeded` 函数实现。判断是否过期，过期则可以选择异步删除或同步删除，删除后返回null，不过期返回正常键值对给客户端。

Redis 的定期删除策略，默认每秒进行 10 次过期检查一次数据库，其中随机抽查的数量为20（写死了），如果20个中有5个以上（25%）过期则继续抽查。

**定期删除是一个循环的流程**，为了不一直循环，设置默认上限定期删除25ms内。



**内存淘汰策略**

当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行。

在配置文件 redis.conf 中，可以通过参数 `maxmemory <bytes>` 来设定最大运行内存，只有在 Redis 的运行内存达到了我们设置的最大运行内存，才会触发内存淘汰策略。 （64位操作系统，默认0，即无限制，32位系统默认3G）

触发**内存淘汰机制**，共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。

1. 不进行数据淘汰的策略
   1. noeviction：超过最大内存，不淘汰，直接不提供服务，返回错误。禁止写入，但仍可以查询删除。（**默认的内存淘汰策略**）
2. 进行数据淘汰的策略
   1. 在设置了过期时间的数据中进行淘汰
      1. **volatile-random**：随机淘汰设置了过期时间的任意键值；
      2. **volatile-ttl**：优先淘汰更早过期的键值。
      3. **volatile-lru**（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；
      4. **volatile-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；
   2. 在所有数据范围内进行淘汰
      1. **allkeys-random**：随机淘汰任意键值;
      2. **allkeys-lru**：淘汰整个键值中最久未使用的键值；
      3. **allkeys-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。

> 如何查看当前 Redis 使用的内存淘汰策略？

使用 `config get maxmemory-policy` 命令



> 什么是 LRU 算法？

**LRU** 全称是 Least Recently Used 翻译为**最近最少使用**，会选择淘汰最近最少使用的数据。

Redis 并没有使用这样的方式实现 LRU 算法，因为传统的 LRU 算法存在两个问题：（**空间开销和性能开销**）

- 需要用链表管理所有的缓存数据，这会带来额外的空间开销；
- 当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。

> Redis 是如何实现 LRU 算法的？

Redis 实现的是一种**近似 LRU 算法**，目的是为了更好的节约内存，它的**实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间**。

当 Redis 进行内存淘汰时，会使用**随机采样的方式来淘汰数据**，它是随机取 5 个值（此值可配置），然后**淘汰最久没有使用的那个**。

但是 LRU 算法有一个问题，**无法解决缓存污染问题**，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。

因此，在 Redis 4.0 之后引入了 LFU 算法来解决这个问题。

> 什么是 LFU 算法

LFU 全称是 Least Frequently Used 翻译为**最近最不常用**，LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。

> Redis 是如何实现 LFU 算法的？

LFU 算法相比于 LRU 算法的实现，多记录了「数据的访问频次」的信息。

**在 LRU 算法中**，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。

**在 LFU 算法中**，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，低 8bit 存储 logc(Logistic Counter)。

**访问频率**不只是访问次数。访问频率需要考虑 key 的访问是多长时间段内发生的。key 的先前访问距离当前时间越长，那么这个 key 的访问频率相应地也就会降低，这样被淘汰的概率也会更大。



### 高可用篇



#### 主从复制是怎么实现的？



AOP 和 RDB 保证了但服务器情况下不会丢失数据（或者说丢失少量数据），但无法避免单点故障的影响。

因此需要多服务器。Redis 提供了 **主从复制模式**来保持服务器之间的数据一致性。

这个模式可以保证多台服务器的数据一致性，且主从服务器之间采用的是**「读写分离」**的方式。

**主服务器可以进行读写操作**，当发生写操作时自动将写操作**同步**给从服务器，而**从服务器一般是只读**，并接受主服务器同步过来写操作命令，然后执行这条命令。



**第一次同步**

使用 `replicaof`命令形成主服务器和从服务器的关系。

``` bash
# 服务器 B 执行这条命令后就成为了 A 的从服务器
replicaof <服务器 A 的 IP 地址> <服务器 A 的 Redis 端口号>
```

主从服务器间的第一次同步的过程可分为三个阶段：

- 第一阶段是建立链接、协商同步；
  - 从服务器就会给主服务器发送 `psync` 命令，包含两个参数，分别是**主服务器的 runID**（第一次同时不知道，设置为 ？） 和**复制进度 offset**（第一次同步，其值为 -1 ）。
  - 主服务器收到 psync 命令后，会用 `FULLRESYNC` 作为响应命令返回给对方，包含两个参数，主服务器的 runID 和主服务器目前的复制进度 offset。FULLRESYNC 响应命令的意图是采用**全量复制**的方式。
- 第二阶段是主服务器同步数据给从服务器；（RDB）
  - 主服务器会执行 bgsave 命令来生成 RDB 文件（bgsave 子线程，异步，不会阻塞），然后把文件发送给从服务器。
    - 为了保证主从服务器的数据一致性，**主服务器在下面这三个时间间隙中将收到的写操作命令，写入到 replication buffer 缓冲区里**：主服务器生成 RDB 文件期间；主服务器发送 RDB 文件给从服务器期间；「从服务器」加载 RDB 文件期间；
  - 从服务器收到 RDB 文件后，会先清空当前的数据，然后载入 RDB 文件。
- 第三阶段是主服务器发送新写操作命令给从服务器。
  - 从服务器收到 RDB 文件后，丢弃所有旧数据，**将 RDB 数据载入到内存**。完成 RDB 的载入后，会回复一个确认消息给主服务器。接着，主服务器将 replication buffer 缓冲区里所记录的写操作命令发送给从服务器，**从服务器执行来自主服务器 replication buffer 缓冲区里发来的命令**，这时主从服务器的数据就一致了。



**命令传播**

主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。

后续主服务器可以通过这个连接继续将**写操作命令**传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。

而且这个连接是长连接的，目的是避免频繁的 TCP 连接和断开带来的性能开销。

上面的这个过程被称为**基于长连接的命令传播**，通过这种方式来**保证第一次同步后的主从服务器的数据一致性。**



**分摊主服务器的压力**

主从服务器在第一次数据同步的过程中，主服务器会做两件耗时的操作：生成 RDB 文件和传输 RDB 文件。

主服务器是可以有多个从服务器的，如果从服务器数量非常多，而且都与主服务器进行全量同步的话，就会带来两个问题：

- 由于是通过 bgsave 命令来生成 RDB 文件的，那么主服务器就会忙于使用 fork() 创建子进程，如果主服务器的内存数据非大，在执行 fork() 函数时是会阻塞主线程的，从而使得 Redis 无法正常处理请求；
- 传输 RDB 文件会占用主服务器的网络带宽，会对主服务器响应命令请求产生影响。

主服务器管理从服务器变成，主服务器管理部分从服务器，部分从服务器管理下属从服务器。（让一部分从服务器成为管理者）

通过这种方式，**主服务器生成 RDB 和传输 RDB 的压力可以分摊到充当经理角色的从服务器**。



**增量复制**

如果主从服务器间的网络连接断开了，那么就无法进行命令传播了，这时从服务器的数据就没办法和主服务器保持一致了，客户端就可能从「从服务器」读到旧的数据。

网络断开又恢复后，从主从服务器会采用**增量复制**的方式继续同步，也就是只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器。主要有三个步骤：

- 从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1；
- 主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据；
- 然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。

**主服务器怎么知道要将哪些增量数据发送给从服务器呢？**

- **repl_backlog_buffer**，是一个「**环形**」缓冲区，用于主从服务器断连后，从中找到差异的数据；
- **replication offset**，标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 master_repl_offset 来记录自己「*写*」到的位置，从服务器使用 slave_repl_offset 来记录自己「*读*」到的位置。

在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。

网络断开后，当从服务器重新连上主服务器时，从服务器会通过 psync 命令将自己的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作：

- 如果判断出从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用**增量同步**的方式；
- 相反，如果判断出从服务器要读取的数据已经不存在 repl_backlog_buffer（**环形，当主服务器写入速度远超从服务器读取速度时，会被覆盖，所以应该调整其大小，尽可能大一点，不免全量同步**） 缓冲区里，那么主服务器将采用**全量同步**的方式。

repl_backlog_buffer 最小大小的计算方式 = second * write_size_per_second。即重连平均之间乘上主服务器平均每秒写入数据量。一般设置最小大小的两倍。



主从复制共有三种模式：**全量复制、基于长连接的命令传播、增量复制**。第一次同步，全量复制。后续命令传播。如果网络断开，根据 repl_backlog_buffer 缓冲区判断是全量同步还是增量同步。



> Redis 主从节点是长连接还是短连接？

长连接。

> 怎么判断 Redis 某个节点是否正常工作？

通过互相的 ping-pong 心态检测机制，如果有一半以上的节点去 ping 一个节点的时候没有 pong 回应，集群就会认为这个节点挂掉了，会断开与这个节点的连接。

Redis **主从节点**发送的心态间隔是不一样的，而且作用也有一点区别：

- Redis 主节点默认每隔 10 秒对从节点发送 ping 命令，判断从节点的存活性和连接状态，可通过参数repl-ping-slave-period控制发送频率。
- Redis 从节点每隔 1 秒发送 replconf ack{offset} 命令，给主节点上报自身当前的复制偏移量，目的是为了：
  - 实时监测主从节点网络状态；
  - 上报自身复制偏移量， 检查复制数据是否丢失， 如果从节点数据丢失， 再从主节点的复制缓冲区中拉取丢失数据。

> 主从复制架构中，过期key如何处理？

主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间**主节点模拟一条del命令发送给从节点**，从节点收到该命令后，就进行删除key的操作。

> Redis 是同步复制还是一步复制？

Redis 主节点每次收到写命令之后，先写到内部的缓冲区 replication buffer，然后异步发送给从节点。

> 主从复制中两个buffer (replication buffer, repl backlog buffer)区别？

- 出现的阶段不一样：
  - repl backlog buffer 是在增量复制阶段出现，**一个主节点只分配一个 repl backlog buffer**；
  - replication buffer 是在全量复制阶段和增量复制阶段都会出现，**主节点会给每个新连接的从节点，分配一个 replication buffer**；
- 这两个 Buffer 都有大小限制的，当缓冲区满了之后，发生的事情不一样：
  - 当 repl backlog buffer 满了，因为是环形结构，会直接**覆盖起始位置数据**;
  - 当 replication buffer 满了，会导致连接断开，删除缓存，从节点重新连接，**重新开始全量复制**.

> 为什么会出现主从数据不一致？

**因为主从节点间的命令复制是异步进行的**.

> 如何如何应对主从数据不一致？

第一种方法，尽量保证主从节点间的网络连接状况良好，避免主从节点在不同的机房。

第二种方法，可以开发一个外部程序来监控主从节点间的复制进度



**主从切换过程中，产生数据丢失的情况有两种：**

- 异步复制同步丢失：主节点还没来得及同步给从节点时发生了断电，那么主节点内存中的数据会丢失。
  - 减少丢失方案：配置 min-slaves-max-lag 参数。一旦所有的从节点数据复制和同步的延迟都超过了 min-slaves-max-lag 定义的值，那么主节点就会拒绝接收任何请求。
- 集群产生脑裂数据丢失：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。
  - 减少丢失方案：当主节点发现「从节点下线的数量太多」，或者「网络延迟太大」的时候，那么主节点会禁止写操作，直接把错误返回给客户端。配置 min-slaves-to-write 和 min-slaves-max-lag 参数，保证从节点个数以及消息延迟时间。



> 主从如何做到故障自动切换？

Redis 的哨兵机制，哨兵在发现主节点出现故障时，由哨兵自动完成故障发现和故障转移，并通知给应用方，从而实现高可用性。





#### 为什么要有哨兵？

在 Redis 的主从架构中，由于主从模式是读写分离的，如果主节点（master）挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点（slave）进行数据同步了。

这时如果要恢复服务的话，需要人工介入，选择一个「从节点」切换为「主节点」，然后让其他从节点指向新的主节点，同时还需要通知上游那些连接 Redis 主节点的客户端，将其配置中的主节点 IP 地址更新为「新主节点」的 IP 地址。

Redis 在 2.8 版本以后提供的**哨兵（*Sentinel*）机制**，它的作用是实现**主从节点故障转移**。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。



哨兵其实是一个运行在特殊模式下的 Redis 进程，所以它也是一个节点。从“哨兵”这个名字也可以看得出来，它相当于是“观察者节点”，观察的对象是主从节点。但不仅仅是观察，还要处理。哨兵节点主要负责三件事情：**监控、选主、通知**。

> 如何判断主节点真的故障了？

哨兵会**每隔 1 秒**给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「**主观下线**」。这个「规定的时间」是配置项 `down-after-milliseconds` 参数设定的，单位是毫秒。

「**主观下线**」是因为可能主服务器压力大或者网络拥堵，避免误判，所以定义为 主观下线。

**需要哨兵集群**（*最少需要三台机器来部署哨兵集群*），**通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况**。

「**客观下线**」当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。赞成主服务器下线的超过 quorum 则定义为 客观下线。

> 由那个哨兵进行主从故障转移？

**哨兵是以哨兵集群的方式存在的**，需要在哨兵集群中选出一个 leader，让 leader 来执行主从切换。

Leader 候选者是所有赞成主服务器下线的哨兵。

> 候选者如何选举成为 Leader ？ 

满足两个条件：

- 第一，拿到半数以上的赞成票；
- 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。

每位候选者都会先给自己投一票，然后向其他哨兵发起投票请求。如果投票者先收到「候选者 A」的投票请求，就会先投票给它，如果投票者用完投票机会后，收到「候选者 B」的投票请求后，就会拒绝投票。这时，候选者 A 先满足了上面的那两个条件，所以「候选者 A」就会被选举为 Leader。

> 为什么哨兵节点至少要有 3 个？

2个的话出现问题，候选者无法拿到半数以上的赞成票，成为Leader。

> Redis 1 主 4 从，5 个哨兵，quorum 设置为 3，如果 2 个哨兵故障，当主节点宕机时，哨兵能否判断主节点“客观下线”？主从能否自动切换？

- **哨兵集群可以判定主节点“客观下线”**。(3 >= 2)
- **哨兵集群可以完成主从切换**。(3 > 2.5, 3 >= 3)

**quorum 的值建议设置为哨兵个数的二分之一加 1**，例如 3 个哨兵就设置 2，5 个哨兵设置为 3，而且**哨兵节点的数量应该是奇数**。这样设置可以防止上面两样情况不一致，做无用功。





**主从故障转移的过程是怎么样的？**

包含以下四个步骤：

- 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。
  - 过滤掉已经离线的从节点。
  - 过滤掉历史网络连接状态不好的从节点。
  - 第一轮考察：哨兵首先会根据从节点的优先级来进行排序，优先级越小排名越靠前，（优先级是可以配置的）
  - 第二轮考察：如果优先级相同，则查看复制的下标，哪个从「主节点」接收的复制数据多，哪个就靠前。（命令传播）
  - 第三轮考察：如果优先级和下标都相同，就选择从节点 ID 较小的那个。
  - 发送 `SLAVEOF no one` 命令，让从节点升级为新主节点。
  - 哨兵 leader 会以每秒一次的频率向被升级的从节点发送 `INFO` 命令，查询角色信息。
- 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；
  - 哨兵 leader 向所有从节点（server3 和 server4）发送 `SLAVEOF` ，让它们成为新主节点的从节点。
- 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；
  - **主从切换完成后，哨兵就会向 `+switch-master` 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了**。
- 第四步：继续监视旧主节点，当这个旧主节点重新上线时，哨兵集群就会向它发送 `SLAVEOF` 命令，将它设置为新主节点的从节点；



**哨兵集群是如何组成的？**

**哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的**。

主节点上有一个名为`__sentinel__:hello`的频道，不同哨兵就是通过它来相互发现，实现互相通信的。

> 哨兵集群会对「从节点」的运行状态进行监控，那哨兵集群如何知道「从节点」的信息？

哨兵 B 给主节点发送 `INFO` 命令，主节点接受到这个命令后，就会**把从节点列表返回给哨兵**。接着，哨兵就可以根据从节点列表中的连接信息，和每个从节点建立连接，并在这个连接上持续地对从节点进行监控。





### 缓存篇



#### 什么是缓存雪崩、击穿、穿透？



##### 缓存雪崩

**定义：大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机**

**应对方法（for 大量数据同时过期）：**

- 均匀设置过期时间：**给数据的过期时间加上一个随机数**
- 互斥锁：**如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存（数据库读取后更新缓存）**，最好**设置超时时间，防止不释放锁。**
- 后台更新缓存：**让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新**。

**应对方法（for Redis 故障宕机）：**

- 服务熔断或请求限流机制：**暂停业务应用对缓存服务的访问，直接返回错误**；**只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务**
- 构建 Redis 缓存高可靠集群：**主从节点的方式构建 Redis 缓存高可靠集群**。



##### 缓存击穿

**某个热点数据过期**

可以认为缓存击穿是缓存雪崩的一个子集。

**应对方案：**

- **互斥锁方案**，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。
- **不给热点数据设置过期时间**，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；



##### 缓存穿透

**既不在缓存中，也不在数据库中**

**应对方案：**

- 非法请求的限制；
- 缓存空值或者默认值；
- 使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在；

布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。

N 个哈希函数分别对 X 进行映射，将对应位置的值都设置为1。**存在哈希冲突的可能性**

**查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据**。



#### 数据库和缓存如何保证一致性？



**无论是「先更新数据库，再更新缓存」，还是「先更新缓存，再更新数据库」，这两个方案都存在并发问题，当两个请求并发更新同一条数据的时候，可能会出现缓存和数据库中的数据不一致的现象**。（ABBA）

写策略：更新数据库缓存；删除缓存数据。

读策略：缓存未命中；读取数据库；回写缓存。

**先删除缓存，再更新数据库，在「读 + 写」并发的时候，还是会出现缓存和数据库的数据不一致的问题**。(ABBBA，写A读B)

**「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的**。（BBAAB会不一致，但是很少发生，**因为缓存的写入通常要远远快于数据库的写入**），给缓存数据加上了「**过期时间**」，就算在这期间存在缓存数据不一致，有过期时间来兜底，这样也能达到最终一致。

这种方案缓存的数据都会被删除，会对缓存的命中率带来影响。**如果我们的业务对缓存命中率有很高的要求，我们可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况**。数据不一致有两种解决方案：

1. 分布式锁，只允许一个请求更新缓存。
2. 加上较短的过期时间。



针对「先删除缓存，再更新数据库」方案在「读 + 写」并发请求而造成缓存不一致的解决办法是「**延迟双删**」。需要一个 睡眠时间，有点玄学，极端情况下还是会缓存不一致。



**建议用「先更新数据库，再删除缓存」的方案。**



**在删除缓存（第二个操作）的时候失败，会导致缓存中的数据是旧值**，引出新问题：**如何保证「先更新数据库 ，再删除缓存」这两个操作能执行成功？**

**如果要想保证「先更新数据库，再删缓存」策略第二个操作能执行成功，我们可以使用「消息队列来重试缓存的删除」，或者「订阅 MySQL binlog 再操作缓存」，这两种方法有一个共同的特点，都是采用异步操作缓存。**



> 为什么是删除缓存，而不是更新缓存呢？

删除一个数据，相比更新一个数据更加轻量级，出问题的概率更小。在实际业务中，缓存的数据可能不是直接来自数据库表，也许来自多张底层数据表的聚合。





## 图解网络



### 基础篇



#### TCP/IP 网络模型有几层？

![image-20240416201917978](.././assets/image-20240416201917978.png)



TCP/IP 网络通常是由上到下分成 4 层，分别是**应用层，传输层，网络层和网络接口层**。



**应用层**

数据块	**传输单位：消息或报文**

我们能直接接触到的就是**应用层**（*Application Layer*），我们电脑或手机使用的应用软件都是在应用层实现。

应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP等。

应用层是不用去关心数据是如何传输的。

应用层是工作在操作系统中的用户态，传输层及以下则工作在内核态。



**传输层**

TCP头部 + 数据块	**传输单位：段**

应用层的数据包会传给传输层，**传输层**（*Transport Layer*）是为应用层提供网络支持的。

**传输层实现应用到应用的通信。**

在传输层会有两个传输协议，分别是 TCP 和 UDP。

- TCP 的全称叫传输控制协议（*Transmission Control Protocol*），大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了**保证数据包能可靠地传输给对方**。
  - 当传输层的数据包大小超过 MSS（TCP 最大报文段长度） ，就要将数据包分块，这样即使中途有一个分块丢失或损坏了，只需要重新发送这一个分块，而不用重新发送整个数据包。在 TCP 协议中，我们把每个分块称为一个 **TCP 段**（*TCP Segment*）。
  - 当设备作为接收方时，传输层则要负责把数据包传给应用，但是一台设备上可能会有很多应用在接收或者传输数据，因此需要用一个编号将应用区分开来，这个编号就是**端口**。由于传输层的**报文中会携带端口号**，因此接收方可以识别出该报文是发送给哪个应用。

- UDP 相对来说就很简单，简单到**只负责发送数据包，不保证数据包是否能抵达对方**，但它实时性相对更好，传输效率也高。当然，UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以。



**网络层**

IP头部 + TCP头部 + 数据块	**传输单位：包**

我们不希望传输层协议处理太多的事情，只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是**网络层**（*Internet Layer*）。

网络层最常使用的是 IP 协议（*Internet Protocol*），**IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文**，如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会**再次进行分片**，得到一个即将发送到网络的 IP 报文。

网络层负责将数据从一个设备传输到另一个设备，世界上那么多设备，又该如何找到对方呢？（**IP地址**）

IP 地址包括两个部分：

- 一个是**网络号**，负责标识该 IP 地址是属于哪个「子网」的。**IP地址与子网掩码按位与**
- 一个是**主机号**，负责标识同一「子网」下的不同主机。**IP地址与取反的子网掩码按位与**

IP 地址：192.168.1.1；子网掩码：255.255.255.0；网络号：192.168.1；主机号：1

寻址的过程中，先匹配到相同的网络号（表示要找到同一个子网），才会去找对应的主机。

除了寻址能力， IP 协议还有另一个重要的能力就是**路由**：找到目标地址的子网，找到后进而把数据包转发给对应的网络内。

**IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。寻址更像在导航，路由更像在操作方向盘**。



**网络接口层**

帧头 + IP 头部 + TCP 头部 + 数据块 + 帧尾 	**传输单位：帧**

生成了 IP 头部之后，接下来要交给**网络接口层**（*Link Layer*）在 IP 头部的前面加上 MAC 头部，并封装成**数据帧（Data frame）**发送到网络上。

以太网在判断网络包目的地时和 IP 的方式不同，因此必须采用相匹配的方式才能在以太网中将包发往目的地，而 MAC 头部就是干这个用的，所以，在以太网进行通讯要用到 MAC 地址。

MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息，我们可以通过 ARP 协议获取对方的 MAC 地址。

**网络接口层主要为网络层提供「链路级别」传输的服务**，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。



#### 键入网址到网页显示，期间发生了什么？



##### 孤单小弟 —— HTTP

HTTP 报文 + 数据

首先浏览器做的第一步工作就是要对 `URL` 进行解析，从而生成发送给 `Web` 服务器的 HTTP 请求信息。

http://www.server.com/dir1/file1.html 中 http是协议，www.server.com是服务器名称，/dir1/file1.html是文件的路径名。

如果省略路径名，则默认访问服务器根目录下事先设置的**默认文件**

对 `URL` 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求消息了。



##### 真实地址查询 —— DNS

通过浏览器解析 URL 并生成 HTTP 消息后，需要委托操作系统将消息发送给 `Web` 服务器。

但在发送之前，还有一项工作需要完成，那就是**查询服务器域名对应的 IP 地址**，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址。

有一种服务器就专门保存了 `Web` 服务器域名与 `IP` 的对应关系，它就是 `DNS` 服务器。

DNS 中的域名都是用**句点**来分隔的，比如 `www.server.com`，这里的句点代表了不同层次之间的**界限**。

在域名中，**越靠右**的位置表示其层级**越高**。(外国人喜欢从小到大)

实际上域名最后还有一个点，比如 `www.server.com.`，这个最后的一个点代表根域名。

也就是，`.` 根域是在最顶层，它的下一层就是 `.com` 顶级域，再下面是 `server.com`。

客户端只要能够找到任意一台 DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到位于下层的某台目标 DNS 服务器。

> 域名解析的工作流程

1. 客户端先问本地 DNS 服务器（是否有缓存）
2. 本地 DNS 再问根域名服务器（不用于域名解析，但指明顶级域名服务器）
3. 本地 DNS 再问顶级域名服务器（指向权威域名服务器）
4. 本地 DNS 返回对应的IP地址
5. 本地 DNS  返回给客户端，然后建立连接。

> 那是不是每次解析域名都要经过那么多的步骤呢？

先看缓存，在看 hosts 文件，再问 本地 DNS 服务器。



##### 指南好帮手 —— 协议栈

通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的**协议栈**。

应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。**协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，这两个传输协议会接受应用层的委托执行收发数据的操作。**

**协议栈的下面一半是用 IP 协议控制网络包收发操作**，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。

此外 IP 中还包括 `ICMP` 协议和 `ARP` 协议。

- `ICMP` 用于告知网络包传送过程中产生的错误以及各种控制信息。
- `ARP` 用于根据 IP 地址查询相应的以太网 MAC 地址。

IP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。



##### 可靠传输 —— TCP

TCP 头部 + HTTP 报文 + 数据

**TCP 报文头部的格式**

![image-20240416212122523](.././assets/image-20240416212122523.png)

> TCP 传输数据之前，要先三次握手建立连接

TCP 连接的建立，通常称为**三次握手**。三次握手目的是**保证双方都有发送和接收的能力**。

> 如何查看 TCP 的连接状态？

在 Linux 可以通过 `netstat -napt` 命令查看。

> TCP 分割数据

如果 HTTP 请求消息比较长，超过了 `MSS`的长度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。

- `MTU`：一个网络包的最大长度，以太网中一般为 `1500` 字节。
- `MSS`：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。

> TCP 报文生成

TCP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是 Web 服务器监听的端口（HTTP 默认端口号是 `80`， HTTPS 默认端口号是 `443`）。

在双方建立了连接后，TCP 报文中的**数据部分就是存放 HTTP 头部 + 数据**，组装好 TCP 报文之后，就需交给下面的网络层处理。



##### 远程定位 —— IP

IP头部 + TCP 头部 + HTTP 报文 + 数据

TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成**网络包**发送给通信对象。

在 IP 协议里面需要有**源地址 IP** 和 **目标地址 IP**：

- 源地址IP，即是客户端输出的 IP 地址；
- 目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP。

因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的**协议号**，要填写为 `06`（十六进制），表示协议为 TCP。

> 假设客户端有多个网卡，就会有多个 IP 地址，那 IP 头部的源地址应该选择哪个 IP 呢？

根据**路由表**规则，来判断哪一个网卡作为源地址 IP。在 Linux 操作系统，我们可以使用 `route -n` 命令查看当前系统的路由表。然后根据 IP 地址和子网掩码 按位与。



##### 两点传输 —— MAC

MAC 头部 + IP头部 + TCP 头部 + HTTP 报文 + 数据

在 MAC 包头里需要**发送方 MAC 地址**和**接收方目标 MAC 地址**，用于**两点之间的传输**。（还有协议类型，即IP）

一般在 TCP/IP 通信里，MAC 包头的**协议类型**只使用：

- `0800` ： IP 协议
- `0806` ： ARP 协议

> MAC 发送方和接收方如何确认?

**发送方**的 MAC 地址：直接读取网卡 ROM

**接收方**的 MAC 地址：查一下**路由表**，在路由表中找到相匹配的条目，然后把包发给 `Gateway` 列中的 IP 地址就可以了。

> 既然知道要发给谁，按如何获取对方的 MAC 地址呢？

需要 `ARP` 协议帮我们找到路由器的 MAC 地址。ARP 协议会在以太网中以**广播**的形式获取。

> 好像每次都要广播获取，这不是很麻烦吗？

**ARP 缓存**，（先查 ARP 缓存，再发送 ARP 广播查询）

> 查看 ARP 缓存内容

在 Linux 系统中，我们可以使用 `arp -a` 命令来查看 ARP 缓存的内容。



##### 出口 —— 网卡

报头和起始帧分界符 + MAC 头部 + IP头部 + TCP 头部 + HTTP 报文 + 数据 + FCS

将**数字信息转换为电信号**，才能在网线上传输，也就是说，这才是真正的数据发送过程。

负责执行这一操作的是**网卡**，要控制网卡还需要靠**网卡驱动程序**。

网卡驱动获取网络包之后，会将其**复制**到网卡内的缓存区中，接着会在其**开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列**。

- 起始帧分界符是一个用来表示包起始位置的标记
- 末尾的 `FCS`（帧校验序列）用来检查包传输过程是否有损坏



##### 送别者 —— 交换机

交换机的设计是将网络包**原样**转发到目的地。交换机工作在 MAC 层，也称为**二层网络设备**。

> 交换机的包接收操作

和网卡不同，**交换机的端口不具有 MAC 地址**。交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。

**交换机的 MAC 地址表主要包含两个信息：**

- 一个是设备的 MAC 地址，
- 另一个是该设备连接在交换机的哪个端口上。

**交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口**。

> 当 MAC 地址表找不到指定的 MAC 地址会怎么样？

交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。**只有相应的接收者才接收包，而其他设备则会忽略这个包**。

如果接收方 MAC 地址是一个**广播地址**，那么交换机会将包发送到除源端口之外的所有端口。

以下两个属于**广播地址：**

- MAC 地址中的 `FF:FF:FF:FF:FF:FF`
- IP 地址中的 `255.255.255.255`



##### 出境大门 —— 路由器

> 路由器与交换机的区别

- 因为**路由器**是基于 IP 设计的，俗称**三层**网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；
- 而**交换机**是基于以太网设计的，俗称**二层**网络设备，交换机的端口不具有 MAC 地址。

> 路由器的基本原理

路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。

当转发包时，首先路由器端口会接收发给自己的以太网包，然后**路由表**查询转发目标，再由相应的端口作为发送方将以太网包发送出去。

> 路由器的包接收操作

首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 `FCS` 进行错误校验。

如果没问题则检查 MAC 头部中的**接收方 MAC 地址**，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。

总的来说，**路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。**

> 查询路由表确定输出端口

完成包接收操作之后，路由器就会**去掉**包开头的 MAC 头部。

**MAC 头部的作用就是将包送达路由器**，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会**被丢弃**。

接下来，路由器会根据 MAC 头部后方的 `IP` 头部中的内容进行包的转发操作。

IP 地址与子网掩码进行按位与，然后匹配路由表。

实在找不到匹配路由时，就会选择**默认路由**，路由表中子网掩码为 `0.0.0.0` 的记录表示「默认路由」。

> 路由器的发送操作

首先，我们需要根据**路由表的网关列**判断对方的地址。

- 如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，**还未抵达终点**，还需继续需要路由器转发。
- 如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明**已抵达终点**。

知道对方的 IP 地址之后，接下来需要通过 `ARP` 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方 MAC 地址。

路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。

接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 `0800` （十六进制）表示 IP 协议。

网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。

发送出去的网络包会通过**交换机**到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。

接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。

在网络包传输的过程中，**源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址**，因为需要 MAC 地址在以太网内进行**两个设备**之间的包传输。



##### 互相扒皮 —— 服务器 与 客户端

发送端：通过每一层添加头部

接收端：通过每一层删除头部



> 读者问：“笔记本的是自带交换机的吗？交换机现在我还不知道是什么”

笔记本不是交换机，交换机通常是2个网口以上。

现在家里的**路由器其实有了交换机的功能**了。交换机可以简单理解成一个设备，三台电脑网线接到这个设备，这三台电脑就可以互相通信了，交换机嘛，交换数据这么理解就可以。

> 读者问：“如果知道你电脑的mac地址，我可以直接给你发消息吗？”

Mac地址只能是两个设备之间传递时使用的，如果你要从大老远给我发消息，是离不开 IP 的。

> 读者问：“请问公网服务器的 Mac 地址是在什么时机通过什么方式获取到的？我看 arp 获取Mac地址只能获取到内网机器的 Mac 地址吧？”

在发送数据包时，如果目标主机不是本地局域网，填入的MAC地址是路由器，也就是把数据包转发给路由器，路由器一直转发下一个路由器，直到转发到目标主机的路由器，发现 IP 地址是自己局域网内的主机，就会 arp 请求获取目标主机的 MAC 地址，从而转发到这个服务器主机。



#### Linux 系统是如何收发网络包的？

由于网络设备的异构性，国际标准化组织定义了一个七层的 OSI 网络模型，分别是应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层。

每一层负责的职能都不同，如下：

- 应用层，负责给应用程序提供统一的接口；
- 表示层，负责把数据转换成兼容另一个系统能识别的格式；
- 会话层，负责建立、管理和终止表示层实体之间的通信会话；
- 传输层，负责端到端的数据传输；
- 网络层，负责数据的路由、转发、分片；
- 数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址；
- 物理层，负责在物理网络中传输数据帧；

事实上，我们比较常见，也比较实用的是四层模型，即 TCP/IP 网络模型，Linux 系统正是按照这套网络模型来实现网络协议栈的。

TCP/IP 网络模型共有 4 层，分别是应用层、传输层、网络层和网络接口层，每一层负责的职能如下：

- 应用层，负责向用户提供一组应用程序，比如 HTTP、DNS、FTP 等;
- 传输层，负责端到端的通信，比如 TCP、UDP 等；
- 网络层，负责网络包的封装、分片、路由、转发，比如 IP、ICMP 等；
- 网络接口层，负责网络包在物理网络中的传输，比如网络包的封帧、 MAC 寻址、差错检测，以及通过网卡传输网络帧等；

*我们常说的七层和四层负载均衡，是用 OSI 网络模型来描述的，七层对应的是应用层，四层对应的是传输层。*

**Linux 网络协议栈的样子，类似于 TCP/IP 的四层结构**



**Linux 接收网络包的流程**

网卡是计算机里的一个硬件，专门负责接收和发送网络包，当网卡接收到一个网络包后，会通过 DMA 技术，将网络包写入到指定的内存地址，也就是写入到 Ring Buffer ，这个是一个环形缓冲区，接着就会告诉操作系统这个网络包已经到达。

> 那应该怎么告诉操作系统这个网络包已经到达了呢？

最简单的办法就是触发中断，但是影响 CPU 效率。

所以为了解决频繁中断带来的性能开销，Linux 内核在 2.6 版本中引入了 **NAPI 机制**，它是混合「中断和轮询」的方式来接收网络包，它的核心概念就是**不采用中断的方式读取数据**，而是首先采用中断唤醒数据接收的服务程序，然后 `poll` 的方法来轮询数据。

因此，当有网络包到达时，会通过 DMA 技术，将网络包写入到指定的内存地址，接着网卡向 CPU 发起硬件中断，当 CPU 收到硬件中断请求后，根据中断表，调用已经注册的中断处理函数。

硬件中断处理函数会做如下的事情：

- 需要先「暂时屏蔽中断」，表示已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知 CPU 了，这样可以提高效率，避免 CPU 不停的被中断。
- 接着，发起「软中断」，然后恢复刚才屏蔽的中断。

至此，硬件中断处理函数的工作就已经完成。

硬件中断处理函数做的事情很少，主要耗时的工作都交给软中断处理函数了。

> 软中断的处理

内核中的 ksoftirqd 线程专门负责软中断的处理，当 ksoftirqd 内核线程收到软中断后，就会来轮询处理数据。

ksoftirqd 线程会从 Ring Buffer 中获取一个数据帧，用 sk_buff 表示，从而可以**作为一个网络包交给网络协议栈进行逐层处理。**

> 网络协议栈

首先，会先进入到网络接口层，在这一层会检查报文的合法性，如果不合法则丢弃，合法则会找出该网络包的上层协议的类型，比如是 IPv4，还是 IPv6，接着再去掉帧头和帧尾，然后交给网络层。

到了网络层，则取出 IP 包，判断网络包下一步的走向，比如是交给上层处理还是转发出去。当确认这个网络包要发送给本机后，就会从 IP 头里看看上一层协议的类型是 TCP 还是 UDP，接着去掉 IP 头，然后交给传输层。

传输层取出 TCP 头或 UDP 头，根据四元组「源 IP、源端口、目的 IP、目的端口」 作为标识，找出对应的 Socket，并把数据放到 Socket 的接收缓冲区。

最后，应用层程序调用 Socket 接口，将内核的 Socket 接收缓冲区的数据「拷贝」到应用层的缓冲区，然后唤醒用户进程。



**Linux 发送网络包的流程**

发送网络包的流程正好和接收流程相反。



> 发送网络数据的时候，涉及几次内存拷贝操作？

第一次，调用发送数据的系统调用的时候，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。

第二次，在使用 TCP 传输协议的情况下，从传输层进入网络层的时候，每一个 sk_buff 都会被克隆一个新的副本出来。副本 sk_buff 会被送往网络层，等它发送完的时候就会释放掉，然后原始的 sk_buff 还保留在传输层，目的是为了实现 TCP 的可靠传输，等收到这个数据包的 ACK 时，才会释放原始的 sk_buff 。

第三次，当 IP 层发现 sk_buff 大于 MTU 时才需要进行。会再申请额外的 sk_buff，并将原来的 sk_buff 拷贝为多个小的 sk_buff。





### HTTP 篇



#### HTTP 常见面试题

 

> 那「HTTP 是用于从互联网服务器传输超文本到本地浏览器的协议」，这种说法正确吗？

这种说法是**不正确**的。因为也可以是「服务器< -- >服务器」，所以采用**两点之间**的描述会更准确。



**HTTP 常见的状态码有哪些？**

![image-20240416222529191](.././assets/image-20240416222529191.png)



**HTTP 常见字段有哪些？**

*Host：*客户端发送请求时，用来指定服务器的域名。

*Content-Length：*表明本次回应的数据长度。**HTTP 协议通过设置回车符、换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界，这两个方式都是为了解决“粘包”的问题**。

*Connection：*最常用于客户端要求服务器使用「HTTP 长连接」机制，以便其他请求复用。HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。

*Content-Type：*用于服务器回应时，告诉客户端，本次数据是什么格式。（客户端请求的时候，可以使用 `Accept` 字段声明自己可以接受哪些数据格式。`Accept: */*`表示接受任何格式数据）

*Content-Encoding：*表示服务器返回的数据使用了什么压缩格式。（客户端在请求时，用 `Accept-Encoding` 字段说明自己可以接受哪些压缩方法。）



**GET 和 POST 有什么区别？**

**GET 的语义是从服务器获取指定的资源**

**POST 的语义是根据请求负荷（报文body）对指定的资源做出处理**

**安全和幂等的概念：**

- 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。
- 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。

**从 RFC 规范定义的语义来分析：**

GET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。

POST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。

**但是实际过程中，开发者不一定会按照 RFC 规范定义的语义来实现 GET 和 POST 方法。比如：**

- 可以用 GET 方法实现新增或删除数据的请求，这样实现的 GET 方法自然就不是安全和幂等。
- 可以用 POST 方法实现查询数据的请求，这样实现的 POST 方法自然就是安全和幂等。

虽然 POST 用 body 传输数据，而 GET 用 URL 传输，这样数据会在浏览器地址拦容易看到，但是并不能说 GET 不如 POST 安全的。因为 HTTP 传输的内容都是明文的，虽然在浏览器地址拦看不到 POST 提交的 body 数据，但是只要**抓个包就都能看到了**。

所以，要避免传输过程中数据被窃取，就要使用 HTTPS 协议，这样所有 **HTTP 的数据都会被加密传输**。

> GET 请求可以带 body 吗？

RFC 规范并没有规定 GET 请求不能带 body 的。**理论上，任何请求都可以带 body 的**。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。

另外，URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的。



**HTTP缓存技术**

HTTP 缓存有两种实现方式，分别是**强制缓存和协商缓存**。

**强制缓存**指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的**主动性在于浏览器**这边。

强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：

- `Cache-Control`， 是一个相对时间；**Cache-Control 的优先级高于 Expires** 
- `Expires`，是一个绝对时间；

**协商缓存：**通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。**协商缓存就是与服务端协商之后，通过协商结果（资源是否一致）来判断是否使用本地缓存**。

协商缓存可以基于两种头部来实现：

1. 请求头部中的 `If-Modified-Since` 字段与响应头部中的 `Last-Modified` 字段
2. 请求头部中的 `If-None-Match` 字段与响应头部中的 `ETag` 字段

第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。 **Etag 的优先级更高**

**协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求**。

先 **强制缓存**，没有则 **协商缓存**。



**HTTP 特性**

- HTTP/1.1：
  - 优点是「简单、灵活和易于扩展、应用广泛和跨平台」
  - 缺点是「无状态（Cookie解决）、明文传输」，同时还有「不安全」
  - *长连接*：任意一端没有明确提出断开连接，则保持 TCP 连接状态。
  - *管道网络传输*：管道机制则是允许浏览器同时发出 A 请求和 B 请求，但是**服务器必须按照接收请求的顺序发送对这些管道化请求的响应**。即，**HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞**。（**默认不开启**，后文也当1.1没开）
  - *队头阻塞*：请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞



**HTTP 和 HTTPS**

**两者的区别：**

- HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
- HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
- 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。
- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

HTTP 由于是明文传输，所以安全上存在以下三个风险：**窃听风险、篡改风险、冒充风险**。

HTTP**S** 在 HTTP 与 TCP 层之间加入了**`SSL/TLS`** 协议，通过**信息加密、校验机制、身份证书**解决上述风险，具体操作如下：

1. **混合加密**：HTTPS 采用的是**对称加密**（通信建立后，速度快）和**非对称加密**（通信建立前，速度慢但保密性强）结合的「混合加密」方式。
2. **摘要算法 + 数字签名**：接收方通过**摘要算法（哈希函数）来计算出内容的哈希值**，与发送放发来的的结果比较。**但是并不能保证「内容 + 哈希值」不会被中间人替换**。所以需要验证身份，还是用非对称加密。数字签名**通过「私钥加密，公钥解密」的方式，来确认消息的身份**，加密的是哈希值。接收方对比摘要算法的值和公钥解密的值是否相同。
3. **数字证书**：防止替换公钥私钥，客户端用CA公钥解析出服务器数字证书的公钥。

> https 和 http 相比，就是传输的内容多了对称加密，可以这么理解吗？

1. 建立连接时候：https 比 http多了 TLS 的握手过程；
2. 传输内容的时候：https 会把数据进行加密，通常是对称加密数据；

> 我看文中 TLS 和 SSL 没有做区分，这两个需要区分吗？

两者可以视作同一个东西的不同阶段。（SSL 改名到 TLS）

> 为啥 SSL 的握手是 4 次？

SSL/TLS 1.2 需要 4 次握手。SSL/TLS 1.3 需要 3 次握手。



**HTTPS 是如何建立连接的？其间交互了什么？**

SSL/TLS 协议基本流程：

- 客户端向服务器索要并验证服务器的公钥。
- 双方协商生产「会话秘钥」。
- 双方采用「会话秘钥」进行加密通信。

TLS 在实现上分为**握手协议**和**记录协议**两层：

- **TLS 握手协议**就是我们前面说的 TLS 四次握手的过程，负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）；
- **TLS 记录协议**负责保护应用程序数据并验证其完整性和来源，所以**对 HTTP 数据加密是使用记录协议**；



**HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全**。

> 如何避免被中间人抓取数据？

- 不要信任任何证书非法的网站
-  **HTTPS 双向认证**：客户端和服务端都要验证，而不是只客户端验证服务端



HTTP/1.1 相对于 HTTP/1.0 的改进：长连接、管道网络传输

HTTP/2（基于HTTPS）相比于 HTTP/1.1的改进：头部压缩、二进制格式、并发传输（**并行交错地发送请求和响应**）、服务器主动推送资源。虽然通过 Stream 实现并发传输，但只解决了 HTTP 这一层面，TCP 层面并没有解决。无序的内容到达无法拼接，只能放到内存缓冲区。

HTTP/2 队头阻塞的问题是因为 TCP，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**

但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输，QUIC 有以下 3 个特点。

- 无队头阻塞：**当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题**。
- 更快的连接建立：握手过程只需要 1 RTT
- 连接迁移：通过**连接 ID** 来标记通信的两个端点。（避免IP地址变化时 *[热点-WiFi]* 需要重新连接）

QUIC 是一个在 UDP 之上的**伪** TCP + TLS + HTTP/2 的多路复用的协议。**目前还普及非常慢**





#### HTTP/1.1 如何优化？

三种优化思路来优化 HTTP/1.1 协议：（内容越来越多样化，延迟越来越高）

- *尽量避免发送 HTTP 请求* ：缓存
- *在需要发送 HTTP 请求时，考虑如何减少请求次数* ：
  - 减少重定向请求次数：**重定向的工作交由代理服务器完成**
  - 合并请求：**合并资源，以一个大资源的请求替换多个小资源的请求**。
  - 延迟发送请求：**按需获取**
- *减少服务器的 HTTP 响应的数据大小*：
  - 无损压缩
  - 有损压缩



#### HTTPS RSA 握手协议

传统的 TLS 握手基本都是使用 RSA 算法来实现密钥交换的。

- TLS 握手过程：**信息加密（混合加密）、校验机制（摘要算法 + 数字签名）、身份验证（数字证书）**

- RSA 握手过程

  - TLS 第一次握手：客户端发送`Client Hello`消息，包含 TLS 版本号、支持的密码套件列表，以及生成的**随机数（*Client Random*）**

  - TLS 第二次握手：确认 TLS 版本号是否支持，和从密码套件列表中选择一个密码套件，以及生成**随机数（*Server Random*）**，然后返回`Server Hello` 消息，发送「Server Certificate」给客户端，这个消息里含有数字证书。随后，服务端发了「Server Hello Done」消息，目的是告诉客户端，我已经把该给你的东西都给你了，本次打招呼完毕。

  - 客户端验证证书：比较用相同 hash 算法解密和CA 公钥解密的值是否相同。

  - TLS 第三次握手：客户端生成一个新的 **随机数 (*pre-master*)**，用服务器的 RSA 公钥加密该随机数，通过 `Client Key Exchange` 消息传给服务端。服务端用 RSA 私钥解密。至此，双方根据已经得到的三个随机数，生成**会话密钥（Master Secret）**，它是对称密钥，用于对后续的 HTTP 请求/响应的数据加解密。生成完「会话密钥」后，然后客户端发一个`Change Cipher Spec`，告诉服务端 **开始使用加密方式发送消息**。然后，客户端再发一个`Encrypted Handshake Message（Finishd）`wo消息，把之前所有发送的数据做个 **摘要**，再用会话密钥（master secret）加密一下，让服务器做个**验证**，验证加密通信「是否可用」和「之前握手信息是否有被中途篡改过」。之后就都是密文传输。

    TLS 第四次握手：服务器也是同样的操作，发`Change Cipher Spec`和`Encrypted Handshake Message`消息，如果双方都验证加密和解密没问题，那么握手正式完成。

- RSA算法缺陷：**使用 RSA 密钥协商算法的最大问题是不支持前向保密**（长期密钥在未来被破解或泄露,也不会危及过去的通信内容，一旦服务器私钥泄露就G）。



#### HTTPS ECDHE 握手协议

HTTPS 常用的密钥交换算法有两种，分别是 RSA 和 **ECDHE 算法（具有前向安全）**。

- 离散对数
  - `a^i (mod p) = b`  **当模数 p 是一个很大的质数，即使知道底数 a 和真数 b ，计算机仍无法算出离散对数 i 的**
- DH 算法（**核心的数学思想就是离散对数**）
  - 对数为私钥，根据私钥算公钥，然后公开，即使知道公钥也难求私钥（离散对数）
  - 离散对数的幂运算有交换律 `K = B^a (mod P) = A^b (mod p)` ，K 就是通信双方用的**对称加密密钥**
- DHE 算法
  - static DH 算法里有一方的私钥是静态的，海量数据可能会被破解，不具备前向安全。
  - DHE 算法干脆让**双方**的私钥在每次密钥交换通信时，都是临时随机生成，这样保证了前向安全。（E: ephermeral 短暂的）
- ECDHE 算法
  - ECC 椭圆曲线特性，可以用**更少的计算量**计算出公钥，以及最终的会话密钥。
- ECDHE 握手过程
  - 客户端可以不用等服务端的最后一次 TLS 握手，就可以提前发出加密的 HTTP 数据，**节省了一个消息的往返时间**



#### HTTPS 如何优化？

- 分析性能损耗
  - TLS 协议握手过程（网络延迟、性能损耗）
  - 握手后的对称加密报文传输（性能消耗小）
- 硬件优化
  - **HTTPS 协议是计算密集型，而不是 I/O 密集型**，所以升级**支持 AES-NI 特性的 CPU**
- 软件优化
  - 软件升级（企业的人力、时间成本高）
- 协议优化：对「密钥交换过程」进行优化
  - 密钥交换过程算法优化：**选择 ECDHE 算法，x25519 曲线，AES_128_GCM 对称加密**
  - TLS 升级：把 TLS 1.2 升级成 TLS 1.3（**完成 TLS 握手只要 1 RTT**）
- 证书优化（服务器把证书发给客户端）
  - 证书传输优化：选择 ECDHE，密钥长度比 RSA 更短
  - 证书验证优化：（验证证书是否注销）
    - CRL(*Certificate Revocation List*)：下载这个保存本地，但是实时性差，而且这个文件一直变大。
    - OCSP(*Online Certificate Status Protocol*)：**向 CA 发送查询请求，让 CA 返回证书的有效状态**（网络开销）
    - OCSP Stapling：服务器向 CA 周期性地查询证书状态，获得一个带有时间戳和签名的响应结果并缓存它，后续直接发给客户端检查。
- 会话复用（复用首次协商出来的对称密钥）
  - 下面三者都面临重放攻击，前两者还没有前向安全，所以应当对会话密钥设定一个合理的过期时间
  - Session ID：**客户端和服务器首次 TLS 握手连接后，双方会在内存缓存会话密钥，并用唯一的 Session ID 来标识**
  - Session Ticket：**服务器不再缓存每个客户端的会话密钥，而是把缓存的工作交给了客户端**（类似于 Cookie）
  - **Pre-shared Key**：重连 TLS1.3 只需要 **0 RTT**



#### HTTP/2 牛逼在哪里？

- HTTP/1.1 协议的性能问题：内容多样化，带来了高延迟。
- 兼容 HTTP/1.1
  - 没有引入新的协议名，还是 `http://`
  - 只在应用层做了改变，网络层还是基于TCP。
    - 语义不变：请求方法、状态码、头字段等规则保留不变
    - 语法改变：基本改变了 HTTP 报文的传输格式
- 头部压缩：**HPACK** 算法（静态字典【61个高频词】 + 动态字典【62开始，随时更新，丢包会阻塞无法建立动态表 - 队头阻塞】 + 哈夫曼算法）
- 二进制帧：将 HTTP/1 的文本格式改成二进制格式传输数据。**二进制帧传输**
- 并发传输：**多个 Stream 复用一条 TCP 连接，达到并发的效果**，不同Stream可以乱序发送，同一Stream内有序。
- 服务器主动推送资源

*在 http 层面解决了队头阻塞，但是没有解决 TCP 层面，TCP不连续则会存放到内核缓存区中，完整后才能被应用层接收*



#### HTTP/3 强势来袭

- 美中不足的 HTTP/2
  - 队头阻塞：TCP 丢包
  - TCP 与 TLS 的握手时延迟：需要经过 TCP 三次握手和 TLS 四次握手（TLS 1.2）的过程
  - 网络迁移需要重新连接： TCP 连接是由四元组（源 IP 地址，源端口，目标 IP 地址，目标端口），IP变则得重连。
- QUIC 协议的特点（将不可靠传输的 UDP 协议变成“可靠”的）
  - 无队头阻塞：UDP + Stream
  - 更快的连接建立：**QUIC 内部包含了 TLS**
  - 连接迁移：UDP
- HTTP/3 协议
  - QPACK（静态字典【91个高频词】 + 动态字典【两个特殊的单向流来同步双方的动态表】 + 哈夫曼算法）





#### 既然有 HTTP 协议，为什么还要有 RPC ?

- TCP
  - 作为程序员，一般使用Socket 进行编程。
  - 例如 `fd = socket(AF_INET, SOCK_STREAM, 0);`，`SOCK_STREAM`就是指字节流传输，即TCP协议。
- 仅使用 TCP 有什么问题
  - TCP 是有三个特点，**面向连接**、**可靠**、基于**字节流**（没办法区分边界，即**粘包问题**）。
  - 因为有粘包问题，所以需要加一个消息头（写明完整包长度）。这需要双方约定好，也就是协议（HTTP 和 RPC）
- HTTP 和 RPC
  - TCP 是传输层协议，基于它造出来的 **HTTP 和各类 RPC 协议都只是定义了不同消息格式的应用层协议**。
  - HTTP：在浏览器输入网址访问就用到 HTTP 协议
  - RPC(Remote Procedure Call) 远程过程调用。不是具体协议，而是一种**调用方式**。
  - RPC 协议有很多，但**不一定非得使用 TCP，改用 UDP 或者 HTTP，其实也可以做到类似的功能。**
  - 先有 TCP(70年代)，然后有 RPC(80年代) ，才有 HTTP(90年代)。
  - **HTTP 主要用于 Browser/Server (B/S) 架构，而 RPC 更多用于 Client/Server (C/S) 架构。**
- HTTP 和 RPC 有什么区别
  - 服务发现
    - HTTP 通过 DNS 服务器解析
    - PRC 通过中间服务保存
  - 底层连接形式
    - HTTP 长连接
    - PRC 长连接 + 连接池（提升网络性能）
  - 传输的内容
    - 将结构体转为二进制数组的过程就叫**序列化**，反过来将二进制数组复原成结构体的过程叫**反序列化**。
    - HTTP/1.1 冗余信息多，RPC 定制化程度高，性能更好，公司内部微服务用的多。
    - HTTP/2 优化的挺好，但是很多公司内部用很多年了，一般也就没换。



#### 既然有 HTTP 协议了，为什么还要有 WebSocket？

- 使用 HTTP 不断轮询
  - 经典场景：扫码登录，网页并不知道用于是否扫码，所以一直询问服务器
  - 存在问题：消耗带宽，有卡顿感。
- 长轮询
  - 设置请求超时时间，时间内服务器收到打扫请求，立马反馈给客户端。
  - **长轮询机制：**发起一个请求，在较长时间内等待服务器响应的机制
- WebSocket 是什么：全双工 TCP，被 HTTP/1.1 用成了半双工，为什么支持全双工，提出了基于 TCP 的新协议 WebSocket
  - 怎么建立 WebSocket 连接
    - 浏览器在 **TCP 三次握手**建立连接之后，都**统一使用 HTTP 协议**先进行一次通信。
      - 使用普通 HTTP 请求 则后续继续用 HTTP
      - 想要建立 WebSocket 连接，就会在请求中戴上 **特殊的 header 头**。
  - WebSocket 抓包
    - **经历了三次TCP握手之后，利用 HTTP 协议升级为 WebSocket 协议**。
  - WebSocket 的消息格式
    - 数据包在 WebSocket 中被叫做**帧**
      - opcode 字段：标志是什么类型的数据帧（text、二进制、关闭连接信号）
      - payload 字段：真正想要传输的数据长度（单位是字节，“111”的长度为3）
      - payload data 字段：真正传输的数据
      - Tips：**TCP 有粘包问题**，所以上层协议一般都是 **消息头 + 消息体** 的格式
  - WebSocket 的使用场景
    - 网页/小程序游戏，网页聊天室，以及一些类似飞书这样的网页协同办公软件。（需要**服务器主动发送给客户端，两者频繁交互的场景**）



### TCP 篇



#### TCP 三次握手和四次握手面试题

- TCP 基本认识
  - TCP 头部格式
    - 序列号：发送一次数据，就累加一次数据字节数大小。**用来解决网络包乱序问题**
    - 确认应答号：下一次期望收到的序列号。**用来解决丢包问题**
    - 控制位：**ACK（将确认应答号字段变为有效）**, RST, **SYN（希望建立连接，并初始化序列号）**, FIN
  - IP 不可靠，需要 TCP 来保证可靠。
  - TCP 是**面向连接的（一对一）、可靠的、基于字节流**的传输层通信协议。
  - 建立一个 TCP 连接是需要客户端与服务端达成**Socket（IP地址 + 端口号）、序列号（解决乱序）、窗口大小（流量控制）**的共识。
  - **通过 TCP 四元组（源地址、源端口、目标地址、目标端口）唯一确定一个连接**。
  - 最大 TCP 连接数 = 客户端 IP 数 * 客户端端口数（会受到服务端文件描述符和内存的限制）
  - TCP 和 UDP 的区别：连接、服务对象、可靠性、拥塞控制和流量控制、首部开销、传输方式、分片不同
  - TCP 使用场景：FTP 文件传输、 HTTP/HTTPS
  - UDP 使用场景： DNS、SNMP、多媒体通信、广播通信
  - TCP 和 UDP 可以共用一个端口号
- TCP 连接建立
  - **三次握手过程**
    - 第一个报文：SYN 报文。客户端：SYN = 1，随机生成序列号
    - 第二个报文：SYN + ACK 报文。服务端：SYN = 1，ACK = 1 ，随机生成序列号，确认应答号  = 客户端序列号 + 1
    - 第三次报文：ACK 报文。客户端：ACK = 1，确认应答号 = 服务端序列号 + 1
    - **第三次握手是可以携带数据的，前两次握手是不可以携带数据的**
  - **为什么三次握手才可以初始化 Socket、序列号和窗口大小并建立 TCP 连接？**
    - *避免历史连接*（主要原因）
    - *同步双方初始序列号*
    - *避免资源浪费*
    - 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；
    - 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。
  - 为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？
    - 为了防止历史报文被下一个相同四元组的连接接收（主要方面）；
    - 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；
  - 初始序列号 ISN 是如何随机产生的？ **随机数是会基于时钟计时器递增**
  - 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？
    - `MTU`：一个网络包的最大长度，以太网中一般为 `1500` 字节；
    - `MSS`：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；
    -  TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**。TCP 不分片，留给 IP 分片，丢失的话就需要重传整个 IP 报文的所有分片。
  - 第一次握手失败：客户端触发「超时重传」机制，重传 SYN 报文，而且**重传的 SYN 报文的序列号都是一样的**。
  - 第二次握手失败：**客户端就会触发超时重传机制，重传 SYN 报文**；**服务端这边会触发超时重传机制，重传 SYN-ACK 报文**。
  - 第三次握手失败：服务端这边会触发超时重传机制，重传 SYN-ACK 报文。客户端的**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**。
  - **SYN 攻击**：短时间伪造不同 IP 发送 SYN 报文到服务端。
    - 表现：**将TCP 半连接队列占满，后续再在收到 SYN 报文就会丢弃**（SYN 队列，半连接队列。Accept 队列，全连接队列）
    - 如何避免？
      - 调大 netdev_max_backlog ：调大保存数据包的队列
      - 增大 TCP 半连接队列
      - 开启 net.ipv4.tcp_syncookies：SYN 队列返回 SYN Cookie。
      - 减少 SYN+ACK 重传次数
- TCP 连接断开
  - TCP 断开连接是通过**四次挥手**方式。
  - 过程：（双方都可以主动断开，下面以客户端主动举例）
    - 第一次挥手：客户端：FIN = 1 （仅仅表示客户端不再发送，但还能接收）
    - 第二次挥手：服务端：ACK 应答报文 （可能还有数据要处理和发送）
    - 第三次挥手：服务端：FIN 报文 （服务端也不再发送了，同意关闭连接）
    - 第四次挥手：客户端：ACK 应答报文。
    - 服务端收到ACK后就关闭，客户端需要等待 2MSL (TIME_WAIT)后关闭。**主动关闭的一方需要等待关闭**
  - 第一次挥手失败：客户端超时重传 FIN 报文
  - 第二次挥手失败：客户端超时重传 FIN 报文。**ACK报文不会重传**，所以服务端没反应。
  - 第三次挥手失败：服务端超时重发 FIN 报文
  - 第四次挥手失败：服务端超时重发 FIN 报文
  - TIME_WAIT 为什么是 2MSL？
    - `MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**
    - 2MSL 其实是相当于**至少允许报文丢失一次**。如果客户端又接收到了服务端重发的 FIN 报文，那么 **2MSL 时间将重新计时**。
  - 需要 TIME-WAIT 状态，主要是两个原因：
    - 防止历史连接中的数据，被后面相同四元组的连接错误的接收；
    - 保证「被动关闭连接」的一方，能被正确的关闭；
  - TIME_WAIT 危害：占用系统资源、占用端口资源
  - 优化 TIME_WAIT?
    - 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项；
    - net.ipv4.tcp_max_tw_buckets
    - 程序中使用 SO_LINGER ，应用强制使用 RST 关闭。
    - **如果服务端要避免过多的 TIME_WAIT 状态的连接，就永远不要主动断开连接，让客户端去断开，由分布在各处的客户端去承受 TIME_WAIT**。
  - **什么场景下服务端会主动断开连接呢？**
    - 第一个场景：HTTP 没有使用长连接(**根据大多数 Web 服务的实现，不管哪一方禁用了 HTTP Keep-Alive，都是由服务端主动关闭连接**)
    - 第二个场景：HTTP 长连接超时(大量的客户端建立完 TCP 连接后，很长一段时间没有发送数据)
    - 第三个场景：HTTP 长连接的请求数量达到上限(**如果达到这个参数设置的最大值时，则 nginx 会主动关闭这个长连接**)
  - **当服务端出现大量 CLOSE_WAIT 状态的连接的时候，通常都是代码的问题，这时候我们需要针对具体的代码一步一步的进行排查和定位，主要分析的方向就是服务端为什么没有调用 close**
  - 建立连接后，客户端故障了怎么办？TCP保活机制，每隔一段时间发送探测报文，都没回则判断连接死亡。
  - 建立连接后，服务端崩溃了怎么办？**TCP 的连接信息是由内核维护的**，服务端进程没了，也还能发送 FIN 报文与客户端四次挥手。
- Socket 编程
  - 监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。
  - **现在通常认为 backlog 是 accept 队列**
  - **客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。**
  - 没有 accept ，也能建立 TCP 连接。因为accept只负责从TCP 全连接队列中取出已建立连接的socket。
  - 没有 listen，也能建立 TCP 连接。两个客户端之间连接。



#### TCP 重传、滑动窗口、流量控制、拥塞控制

- 重传机制
  - 超时重传
    - TCP 在两种情况下会超时重传：数据保丢失、确认应答丢失
    - `RTT` （Round-Trip Time 往返时延）指的是**数据发送时刻到接收到确认的时刻的差值**，也就是包的往返时间。
    - 超时重传时间是以 `RTO` （Retransmission Timeout 超时重传时间）表示，**略大于 RTT**
  - 快速重传
    - **不以时间为驱动，而是以数据驱动重传**。
    - 当收到三个相同的 ACK 报文时(即中间有丢失数据包)，会在定时器过期之前，重传丢失的报文段。
    - 快速重传解决了超时时间的问题，但是无法确定是重传一个还是后面的所有数据包。
  - SACK（Selective Acknowledge）选择性重传
    - 在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将已收到的数据的信息发送给「发送方」**，这样就可以只重传丢失的数据。
  - D-SACK （Duplicate SACK）
    - **使用了 SACK 来告诉「发送方」有哪些数据被重复接收了**
    - 好处就是让发送方知道发生了什么情况（发出去的包丢了，回应的包丢了，网络延迟等等）
- 滑动窗口：窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。
  - 发送窗口：**可用窗口大小 = SND.WND -（SND.NXT - SND.UNA）**
  - 接收窗口：指定好了
  - 接收窗口的大小是**约等于**发送窗口的大小的。
- 流量控制：**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**
  - 操作系统缓冲区与滑动窗口的关系：**TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况**
  - 窗口关闭：**如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。**
  - 糊涂窗口综合征：**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症**。
  - 流量控制是避免「发送方」的数据填满「接收方」的缓存
- 拥塞控制：**避免「发送方」的数据填满整个网络。**网络没有出现拥塞，cwnd增大，反之减少。
  - 慢启动：**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**发包的个数是**指数性的增长**。
    - 拥塞窗口`cwnd`  < 慢启动门限 `ssthresh` 时，使用慢启动算法，否者拥塞避免。
  - 拥塞避免：**每当收到一个 ACK 时，cwnd 增加 1/cwnd**。**发包的个数是线性增长。**
  - 拥塞发生
    - 超时重传：`ssthresh` 设为 `cwnd/2`，`cwnd` 重置为 `1`。**后续慢启动**
    - 快速重传：`cwnd = cwnd/2，ssthresh = cwnd`。（发送端收到三个前一次包的ACK即快速重传）**后续快速恢复**
  - 快速恢复
    - 快速重传和快速恢复算法一般同时使用（网络也不那么糟糕）
    - 速恢复开始时 `csnd = ssthresh > 3`，即处理拥塞避免，线性增长。

![image-20240418165230726](.././assets/image-20240418165230726.png)

### IP 篇



#### IP 基础知识全家桶

- IP 基本认识

  - IP 的作用
    - IP 在 TCP/IP 参考模型中处于第三层，也就是**网络层**。
    - 网络层的主要作用是：**实现主机与主机之间的通信，也叫点对点（end to end）通信。**
  - IP 与 MAC 的关系
    - **MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输。**
    - 在网络中数据包传输中也是如此，**源IP地址和目标IP地址在传输过程中是不会变化的（前提：没有使用 NAT 网络），只有源 MAC 地址和目标 MAC 一直在变化。**

- IP 地址的基础知识

  - IP 地址的定义

    - IP 地址（IPv4 地址）由 `32` 位正整数来表示，二进制的方式处理的
    - **点分十进制**：32位 IP 地址每 8 位一组，共 4 组。然后转换成十进制。

  - IP 地址的分类

    - IP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类。

    - | 类别 | IP 地址范围（小） | IP 地址范围（大） | 结构                       | 最大主机数          |
      | ---- | ----------------- | ----------------- | -------------------------- | ------------------- |
      | A    | 0.0.0.0           | 127.255.255.255   | 0，7位网络号，24位主机号   | 2^24 - 2 = 16777214 |
      | B    | 128.0.0.0         | 191.255.255.255   | 10，14位网络号，16位主机号 | 2^16 - 2 = 65534    |
      | C    | 192.0.0.0         | 223.255.255.255   | 110，21位网络号，8位主机号 | 2^8 - 2 = 254       |

    - 最大主机数要 -2 是因为：主机号全为 1 用于广播，全为 0 指定某个网络

    - 广播地址可以分为本地广播（在本网络之间广播）和直接广播（在不同网络之间广播）。

    - | 类别 | IP 地址范围（小） | IP 地址范围（大） | 结构               | 用途     |
      | ---- | ----------------- | ----------------- | ------------------ | -------- |
      | D    | 224.0.0.0         | 239.255.255.255   | 1110，28位组播地址 | IP 多播  |
      | E    | 240.0.0.0         | 255.255.255.255   | 1111，28位留待后用 | 预留使用 |
      
    - 多播用于**将包发送给特定组内的所有主机。**
    
    - **广播无法穿透路由**，若想给其他网段发送同样的包，就可以使用可以穿透路由的多播。
    
    - IP 分类的优点：快速判断网络类型。第0位是0还是1？第1位是0还是1？（**得按序判断**）
    
    - IP 分类的缺点：同一网络下没有地址层次；不能很好的与现实网络匹配（C太少，B太多）

  - 无分类地址 CIDR
    - 表示形式 `a.b.c.d/x`，其中 `/x` 表示前 x 位属于**网络号**， x 的范围是 `0 ~ 32`，这就使得 IP 地址更加具有灵活性。
    - 还有另一种划分网络号与主机号形式，那就是**子网掩码**，掩码的意思就是掩盖掉主机号，剩余的就是网络号。**做子网划分后的 ip 地址：网络地址＋（子网网络地址＋子网主机地址）**
    - 为什么要分离网络号和主机号？路由寻址过程中，先找到对应的网络号再发。
  - 公有 IP 地址 与 私有 IP 地址
    - 私有 IP 地址通常是内部的 IT 人员管理，公有 IP 地址是由 `ICANN` 组织管理
  - IP 地址与路由控制
    - IP地址的**网络地址**这一部分是用于进行路由控制。
    - 计算机使用一个特殊的 IP 地址 **127.0.0.1 作为环回地址**。与该地址具有相同意义的是一个叫做 `localhost` 的主机名。使用这个 IP 或主机名时，数据包不会流向网络。
  - IP 分片与重组
    - 以太网的 MTU 是 `1500` 字节。
    - 当 IP 数据包大小大于 MTU 时， IP 数据包就会被分片。
    - **在分片传输中，一旦某个分片丢失，则会造成整个 IP 数据报作废**，所以 TCP 引入了 `MSS` 也就是在 TCP 层进行分片不由 IP 层分片，那么对于 UDP 我们尽量不要发送一个大于 `MTU` 的数据报文。
  - IPv6 基本认识
    - IPv4 的地址是 32 位的，8位一组，十进制表示。IPv6 的地址是 128 位的，16位一组，冒号隔开，十六进制表示。
    - 如果出现连续的 0 时还可以将这些 0 省略，并用两个冒号 「::」隔开。但是，一个 IP 地址中只允许出现一次两个连续的冒号。
  - IPv4 首部与 IPv6 首部，IPv6 的改进之处：
    - **取消了首部校验和字段。**
    - **取消了分片/重新组装相关字段。**
    - **取消选项字段。**

- IP 协议相关技术

  - **DNS （Domain Name System）域名解析**，DNS 可以将域名网址自动转换为具体的 IP 地址。（域名方便人类记忆，**右边层级高**）
  - 通过 **ARP（Address Resolution Protocol） 地址解析协议**，可以求得下一跳的 MAC 地址。ARP 是借助 **ARP 请求（广播发送）与 ARP 响应**两种类型的包确定 MAC 地址的。
    - RARP 协议正好相反，它是**已知 MAC 地址求 IP 地址**。

  - **DHCP（Dynamic Host Configuration Protocol）动态主机配置协议。 动态获取 IP 地址**，大大省去了配 IP 信息繁琐的过程。
    - 客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址，快到期时重新请求。
    - 交互过程全都使用 UDP 广播通信，只能局域网通信。**出现 DHCP 中继代理来解决这一问题，客户端 - DHCP 中继代理 - DHCP**

  - **网络地址转换 NAT（Network Address Translation）** ，缓解了 IPv4 地址耗尽的问题。
    - 对外通信时，NAT 路由器把私有 IP 地址转换成公有 IP 地址。
    - **网络地址与端口转换 NAPT**：把 IP 地址 + 端口号一起进行转换。公有地址相同，以不同端口号区分。
    - 缺点：外部无法主动与内部建立连接；转换操作性能开销；NAT 路由器重启，连接全部重置
    - 解决方案：改用IPv6，NAT穿透技术（客户端自己建立端口映射条目，对外通信）

  - ICMP 全称是 **Internet Control Message Protocol**，也就是**互联网控制报文协议**。
    - **确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。**
    - ICMP 包头封装在 IP 包里。包头类型大致分为两类：「**查询报文类型**」「**差错报文类型**」

  - **IGMP（Internet Group Management Protocol） 是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间**
    - IGMP 报文向路由器申请加入和退出组播组




#### ping 的工作原理

- ping 是基于 `ICMP` 协议工作的
- ICMP 全称是 **Internet Control Message Protocol**，也就是**互联网控制报文协议**。
  - **确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。**
  - ICMP 包头封装在 IP 包里。包头类型大致分为两类：「**查询报文类型**」「**差错报文类型**」
    - 查询报文类型：回送应答——类型为 `0`、回送请求—— 类型 为 `8`（**两者统称为回送消息，ping就是利用这个消息实现的**）
    - 差错报文类型：
      - 目标不可达消息 —— 类型 为 `3`（包括不可达原因，5种：0网络不可达；1主机不可达；2协议不可达；3端口不可达；4需要进行分片但设置了不分片）
      - 原点抑制消息 —— 类型 `4`：**缓和拥堵情况**
      - 重定向消息 —— 类型 `5`：消息中包含了**最合适的路由信息和源数据**
      - 超时消息 —— 类型 `11`：IP 包中有一个字段叫做 `TTL` （`Time To Live`，生存周期），它的**值随着每经过一次路由器就会减 1，直到减到 0 时该 IP 包会被丢弃。**
- ping （查询报文类型的使用）
  - **使用了 ICMP 里面的 ECHO REQUEST（类型为 8 ） 和 ECHO REPLY （类型为 0）**。
  - A发送 回送请求，B返回 回送应答
- traceroute（差错报文类型的使用）
  - 作用1：**故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。**；发送UDP时填入不可能端口，当返回端口不可达时，说明 UDP 到达目的主机。
  - 作用2：**故意设置不分片，从而确定路径的 MTU**。



#### 断网了，还能 ping 通 127.0.0.1 吗？

- 127.0.0.1
  - **127 开头的都属于回环地址**，也是 `IPV4` 的特殊地址，
  - 在IPV4下用的是 **ping 127.0.0.1** 命令。在IPV6下用的是 **ping6 ::1** 命令。（::说明省略了一长串0）
- ping
  - ping 是应用层命令，**尝试发送消息，判断是否可达。**
  - ping 应用的底层，用的是网络层的**ICMP协议**。
- TCP 发数据和 ping 类似
- ping 回环地址和**通过TCP等各种协议发送数据到回环地址**都不会出网络，在本地打个转就回来了，所以**断网还能 ping 通 `127.0.0.1`**
- **ping 回环地址和 ping 本机地址(ipconfig查IPv4)没有区别**
- **127.0.0.1，localhost，0.0.0.0**
  - 这三个 IP 都能访问 nginx 的欢迎页面
  - 默认情况下，使用 `localhost` 跟使用 `127.0.0.1` 确实是没区别的。`localhost` 是域名，默认解析为`127.0.0.1`
  - `0.0.0.0` 表示本机所有 IPV4地址。所以用服务器监听`0.0.0.0`，那客户端用上面两个地址都能访问到服务器。



## 图解系统



### 硬件结构



#### CPU 是如何执行程序的？

- 图灵机的工作方式：用机器来模拟人们用纸笔进行数学运算的过程
- 冯诺依曼模型：**运算器、控制器、存储器、输入设备、输出设备**
  - 内存：存储数据的基本单位是**字节（*byte*）**
  - 中央处理器：CPU
    - 32 位和 64 位，通常称为 CPU 的位宽，代表的是 CPU 一次可以计算（运算）的数据量。（一次计算 4/8 字节）
    - CPU 内部还有一些组件，常见的有**寄存器、控制单元和逻辑运算单元**等。
      - 寄存器：存储计算时的数据
        - 通用寄存器：存放需要进行计算的数据
        - 程序计数器：存储 CPU 要执行的**下一条指令所在的内存地址**
        - 指令寄存器：存放当前**执行指令本身**

      - 控制单元：控制 CPU 工作
      - 逻辑运算单元：负责计算

  - 总线：用于 CPU 和内存以及其他设备之间的通信
    - 地址总线：指定CPU 要操作的内存地址
    - 控制总线：发送和接收信号
    - 数据总线：读写内存数据

  - 输入输出设备：

- 线路位宽与 CPU 位宽
  - 一个地址是1字节，32条地址总线，2^32=4GB
  - CPU 的位宽最好不要小于线路位宽
  - **如果计算的数额不超过 32 位数字的情况下，32 位和 64 位 CPU 之间没什么区别的，只有当计算超过 32 位数字的情况下，64 位的优势才能体现出来**。

- 程序执行的基本过程
  - 一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增（32位CPU指令长度为4），开始顺序读取下一条指令。
  - CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束，这个不断循环的过程被称为 **CPU 的指令周期**。


> 硬件的 64 位和 32 位指的是 CPU 的位宽，软件的 64 位和 32 位指的是指令的位宽。
>
> 指令位宽高于 CPU 位宽直接运行不了，反之需要一套兼容机制即可。



#### 磁盘比内存慢几万倍？

- 存储器的层次结构（越上面速度越快，容量越小，成本越高，前两者都在 CPU 内部）
  - 寄存器：寄存器的访问速度非常快，一般要求在半个 CPU 时钟周期内完成读写。**纳秒级别**
  - CPU Cache：**SRAM（*Static Random-Access* Memory，静态随机存储器）**
    - L1 一级缓存： `2~4` 个时钟周期，每个 CPU 核心都有自己的 L1,缓存内容分成**指令缓存和数据缓存**
    - L2 二级缓存：`10~20` 个时钟周期。每个 CPU 核心都有一个自己的 L2.
    - L3 三级缓存：`20~60`个时钟周期。多个CPU核心共用的。
  - 内存：**DRAM （*Dynamic Random Access Memory*，动态随机存取存储器）**
    - `200~300` 个 时钟周期
    - 只有不断刷新，数据才能被存储起来
  - SSD/HDD
- 存储器的层次关系
  - **每个存储器只和相邻的一层存储器设备打交道，并且存储设备为了追求更快的速度，所需的材料成本必然也是更高，也正因为成本太高，所以 CPU 内部的寄存器、L1\L2\L3 Cache 只好用较小的容量，相反内存、硬盘则可用更大的容量，这就我们今天所说的存储器层次结构**。
- 存储器之间的实际价格和性能差距



#### 如何写出让 CPU 跑得更快的代码？

- CPU Cache 有多快：L1 比 内存读取快100多倍
- CPU Cache 的数据结构和读取过程是什么样的？
  - CPU Cache 是由很多个 **Cache Line （缓存块）**组成的
  - Cache Line 是 CPU 对内存读取数据的基本单位，字 word 是 CPU 从 CPU Cache 读取的基本单位
  - Cache Line 是由有效位、组标记、实际数据组成。
  - **直接映射 Cache**，取模运算，把内存块地址始终映射在一个缓存块中
- 如何写出让 CPU 跑得更快的代码？
  - 提升数据缓存命中率
    - **遍历数组时，按照内存布局顺序访问(先行后列)，将可以有效的利用 CPU Cache 带来的好处，得到性能提升**
  - 提升指令缓存命中率
    - CPU 中有分支预测器。如果分支预测到写下来要执行的指令，就会放到缓存中，执行更快。
    - 先排序再遍历 > 先遍历再排序（这里排序帮助分支预测了，`if array[i] < 50`）
  - 提升多核 CPU 缓存命中率
    - 把**线程绑定在某一个 CPU 核心上**，减少切换时候的消耗。



#### CPU 的缓存一致性

- CPU Cache 的数据写入
  - 写直达：**把数据同时写入内存和 Cache 中**（无论如何，都要写内存，速度慢）
    - 如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；
    - 如果数据没有在 Cache 里面，就直接把数据更新到内存里面。
  - 写回：**当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中**（减少数据写回内存的频率）
- 缓存一致性问题
  - **写传播：**某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache。
  - **事务的串行化：**某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的。
- 总线嗅探：CPU 需要每时每刻监听总线上的一切活动，但是不管别的核心的 Cache 是否缓存相同的数据，都需要发出一个**广播事件**，这无疑会加重总线的负载。（**实现写传播**）
- MESI 协议（基于总线嗅探机制的 MESI 协议**实现事务的串行化**）
  - **M**odified - 已修改：脏标记，代表Cache  Block 已经被修改，但还未被写入内存。
  - **E**xclusive - 独占：只有一个 CPU 的 Cache 有这个数据，可以随意操作。
  - **S**hared - 共享：多个 CPU 核心的 Cache 里都有，修改的时候要广播通知其他核心标记为 已失效。
  - **I**nvalidated - 已失效。
    - 当 Cache Line 状态是「已修改」或者「独占」状态时，修改更新其数据不需要发送广播给其他 CPU 核心，这在一定程度上减少了总线带宽压力。
    - 「独占」和「共享」状态都代表 Cache Block 里的数据是干净的，也就是说，这个时候 Cache Block 里的数据和内存里面的数据是一致性的。





#### CPU 是如何执行任务的？

- CPU 如何读写数据的？
  - CPU 架构：寄存器 - L1 L2 L3 - 内存 - 硬盘
  - CPU 读写单位：**CPU Cache Line（一般是64字节） 是 CPU 从内存读取数据到 Cache 的单位**。
  - CPU 伪共享问题：因为多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象。（**得重新读取 Cache Line**）
  - 避免伪共享方法
    - 对于热点数据，应该尽量避免刚好在同一个 Cache Line
    - Linux 使用宏定义，空间换时间 （**Cache Line 大小字节对齐**）
    - Java 并发框架 Disruptor 使用「字节填充 + 继承」（**字节填充**）

- CPU 如何选择线程的？
  - 进程与线程：在 Linux 内核中，进程和线程都是用 `task_struct` 结构体表示的，区别在于线程的 task_struct 结构体里部分资源是共享了进程已创建的资源，更轻量化。
  - 普通任务与实时任务：相应时间的要求高低。（前者优先级 `100-139`，后者  `0-99`）
  - 调度类（三种调度类：Deadline，Realtime，Fair）
    - 前两种调度类组合的调度策略：（**应用于实时任务**）
      - SCHED_DEADLINE：按照 deadline 调度，时间近的优先调度。
      - SCHED_FIFO：相同优先级，先来先服务。优先级高的可以插队。
      - SCHED_RR：相同优先级，时间片轮转。优先级高的可以插队。
    - Fair 调度类（**应用于普通任务**）
      - SCHED_NORMAL：普通任务使用的调度策略
      - SCHED_BATCH：后台任务的调度策略。不影响其他需要交互的任务，可以降低它的优先级。
  - 完全公平调度：平常遇到基本都是普通任务，公平性很重要。
    - 理念是想让分配给每个任务的 CPU 时间是一样。
    - 给每个任务一个 vruntime，运行越久，值越大。优先选择值小的任务。
    - 考虑到优先级，vruntime 还需要一个权重 （nice 值）。
  - CPU 运行队列：描述在此 CPU 上所运行的所有进程，其队列包含三个运行队列。
  - 调整优先级：
    - 普通任务，调整 nice 值。nice 值越低，任务的优先级就越高。
    - 或者直接将普通任务变为实时任务。



#### 什么是软中断？

- 中断是什么？
  - 中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。
  - **中断请求的响应程序，也就是中断处理程序，要尽可能快的执行完，这样可以减少对正常进程运行调度地影响。**
  - 中断处理程序在响应中断时，可能还会**「临时关闭中断」**。处理中断时，无法相应后来的中断。
- 什么是软中断？把一些处理比较耗时且复杂的事情，交给「软中断处理程序」去做，也就是中断的下半部
  - **上半部直接处理硬件请求，也就是硬中断**，主要是负责耗时短的工作，特点是快速执行；
  - **下半部是由内核触发，也就说软中断**，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行；
- 系统里有哪些软中断？
- 如何定位软中断 CPU 使用率过高的问题？



#### 为什么 0.1 + 0.2 不等于 0.3 ？

- 进制转换
  - 十进制数转二进制采用的是**除 2 取余法**
  - 小数转二进制采用的是 **乘 2 取整法**。**并不是所有小数都可以用二进制表示**

- 为什么负数要用补码表示？
  - 负数在计算机中是以「补码」表示的，**所谓的补码就是把正数的二进制全部取反再加 1**
  - 如果负数不是使用补码的方式表示，则在做基本对加减法运算的时候，**还需要多一步操作来判断是否为负数，如果为负数，还得把加法反转成减法，或者把减法反转成加法**。（对性能不友好）
  - **用了补码的表示方式，对于负数的加减法操作，实际上是和正数加减法操作一样的**。
- 十进制小数与二进制的转换
  - **由于计算机的资源是有限的，所以是没办法用二进制精确的表示 0.1，只能用「近似值」来表示，就是在有限的精度情况下，最大化接近 0.1 的二进制数，于是就会造成精度缺失的情况**。
- 计算机是怎么存小数的？
  - 浮点数，采用 IEEE 指定的国际标准。（符号位 + 指数位 + 尾数）
  - 32位单精度浮点数 `float`（1 + 8 + 23） ，64位多精度浮点数 `double` （1 + 11 + 52）
  - **float 中的「指数位」就跟这里移动的位数有关系，把移动的位数再加上「偏移量」（避免判断指数正负），float 的话偏移量是 127，相加后就是指数位的值了**。右移为正，左移为负。
  - IEEE 标准规定，二进制浮点数的小数点左侧只能有 1 位，并且还只能是 1，**既然这一位永远都是 1，那就可以不用存起来了**。节约一位空间，尾数多存一位小数，精度更高一点。
- 0.1 + 0.2 == 0.3?
  - **因为有的小数无法可以用「完整」的二进制来表示，所以计算机里只能采用近似数的方式来保存，那两个近似数相加，得到的必然也是一个近似数**。



### 操作系统结构



#### Linux 内核 vs Windows 内核

- 内核：**作为应用连接硬件设备的桥梁**
  -  4 个基本能力：进程调度、内存管理、硬件通信、提供系统调用。
  - 把内存分成了两个区域：内核空间、用户空间
  - **内核程序执行在内核态，用户程序执行在用户态。**
- Linux 的设计
  - MultiTask 多任务：支持并发（一段时间内执行了多个任务）或并行（多个任务被多个核心同时执行）
  - SMP 对称多处理：每个 CPU 的地位是相等的，对资源的使用权限也是相同的，多个 CPU 共享同一个内存，每个 CPU 都可以访问完整的内存和硬件资源。
  - ELF 可执行文件链接格式：可执行文件的存储格式
  - Monolithic Kernel **宏内核**：意味着 Linux 的内核是一个完整的可执行程序，拥有最高权限。
    - 宏内核的特征是系统内核的所有模块，比如进程调度、内存管理、文件系统、设备驱动等，都运行在内核态。
    - 与宏内核相反的是**微内核**，微内核架构的内核只保留最基本的能力。其他一些模块和服务则由用户态管理
    - 还有一种内核叫 **混合类型内核**，就像宏内核包裹着一个微内核，其他模块基于微内核搭建。
- Windows 的设计
  - 也支持 MultiTask 和 SMP
  - 可执行文件的格式叫 PE，称为 可移植执行文件
  - 使用的内核叫做 Windows NT(New Technology)，是混合型内核。



### 内存管理



#### 为什么要有虚拟内存？

- 虚拟内存
  - **单片机的 CPU 是直接操作内存的「物理地址」**。
  - **操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**
    - 我们程序所使用的内存地址叫做**虚拟内存地址**（*Virtual Memory Address*）
    - 实际存在硬件里面的空间地址叫**物理内存地址**（*Physical Memory Address*）。
    - 操作系统通过**内存分段和内存分页**来管理虚拟地址与物理地址之间的关系。
  - **虚拟内存的作用：**
    - 可以使进程的运行内存超过物理内存大小。因为局部性原理，没有经常使用的内存可以放到内存之外。
    - 每个进程的虚拟内存空间相互独立。解决了多进程之间地址冲突的问题。
    - 页表里的页表项中有一些标记属性的比特，能提供更好的安全性。
- 内存分段
  - 分段机制下的虚拟地址由两部分组成，**段选择因子**和**段内偏移量**。
  - 不足：**外部内存碎片，内存交换的效率低**
    - 内存碎片主要分为，内部内存碎片和外部内存碎片。**内存分段**是根据实际需求分的，所以**不会出现内部碎片**，但是每段长度不固定，不能利用所有内存空间，**会出现外部碎片**。
    - 解决「外部内存碎片」的问题就是**内存交换**。（相当于重新整理一下，放入硬盘再放回内存）
    - **如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。**
- 内存分页
  - **分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。
  - **采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。**
  - 但是**内存分页机制会有内部内存碎片**，不足一页也需要分配一页。
  - 通过换入换出，在需要的时候才加载到内存中。**页数少，所以内存交换的效率就相对比较高。**
  - 在分页机制下，虚拟地址分为两部分，**页号**和**页内偏移**。
  - 简单的分页缺陷？页表占用空间大，每个进程都得有一个页表，有空间上的缺陷。
  - **多级页表**：利用了**局部性原理，如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表**。（存在时间上的开销，转换页表）
  - **TLB (Translation Lookaside Buffer)**：专门存放程序最常访问的页表项
    - 在 CPU 芯片里面，封装了内存管理单元（*Memory Management Unit*）芯片，它用来完成地址转换和 TLB 的访问与交互。
    - 有了 TLB 后，那么 CPU 在寻址时，会**先查 TLB，如果没找到，才会继续查常规的页表。**
    - TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。
- **段页式内存管理：结合内存分段和内存分页。**
  - 实现的方式：
    - 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
    - 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；
  - 地址结构就由**段号、段内页号和页内位移**三部分组成。
    - 第一次访问段表，得到页表起始地址；
    - 第二次访问页表，得到物理页号；
    - 第三次将物理页号与页内位移组合，得到物理地址。
- Linux 内存布局
  - **Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理**。
  - **Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。**



#### malloc 是如何分配内存的？

- Linux 进程的内存分布。
  - 虚拟地址空间的内部又被分为**内核空间和用户空间**两部分。
  - 用户空间从低到高分别是 6 种不同的内存段：**代码段、数据段、BSS段、堆、文件映射、栈。**
  - **堆和文件映射段的内存是动态分配的。**
- malloc 是如何分配内存的？
  - malloc() 并不是系统调用，而是 C 库里的函数，用于动态分配内存。
  - malloc 通过两种方式向操作系统申请堆内存。（分配内存小的时候用 brk() ，大的时候用 mmap() ）
    - 方式一：通过 brk() 系统调用从堆分配内存。通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间
    - 方式二：通过 mmap() **系统调用**在文件映射区域分配内存；调用中「私有匿名映射」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存。
- malloc() 分配的是物理内存吗？
  - **malloc() 分配的是虚拟内存**。
  - 分配后虚拟内存如果没有被访问的话，是不会映射到物理内存的。
  - 访问的时候触发缺页终端，然后系统建立映射关系。
- malloc(1) 会分配多大的虚拟内存？
  - malloc() **会预分配更大的空间作为内存池**。
- free 释放内存，会归还给操作系统吗？
  - malloc 通过 brk() 方式申请的内存，free 后还在内存池里。当进程退出后，操作系统就会回收进程的所有资源。
  - malloc 通过 mmap 方式申请的内存，free 后直接归还给系统。
- 为什么不全部使用 mmap 来分配内存？
  - **频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换（mmap为系统调用，需要进入内核态），还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大**。
- 既然 brk 那么牛逼，为什么不全部使用 brk 来分配？
  - brk 申请的内存释放后，缓存在内存池中。**等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还存在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数，这将大大降低 CPU 的消耗**。
  - 系统频繁地 malloc 和 free ，尤其对于小块内存，堆内将产生越来越多不可用的碎片，导致“内存泄露”
  - 所以，malloc 实现中，默认分配大块内存用 mmap ，小块内存用 brk()。
- free() 函数只传入一个内存地址，为什么能知道释放多大的内存？
  - malloc 返回给用户态的内存起始地址比进程的堆空间起始地址多的 16 字节，保存了该内存块的描述信息。
  - 执行 free() 函数时，free 会对传入进来的内存地址向左偏移 16 字节，然后从这个 16 字节的分析出当前的内存块的大小。



#### 内存满了，会发生什么？

- 内存分配的过程是怎么样的？

  - malloc 申请虚拟内存，不会分配物理内存。访问的时候发生缺页中断，才分配物理内存，建立映射关系。
  - 如果内存不足，内核开始回收内存。
    - **后台内存回收**：唤醒 kswapd 内核线程回收内存，异步不阻塞。
    - **直接内存回收**：如果后台异步回收跟不上申请内存的速度，就开始直接回收。同步会阻塞。
    - OOM：如果直接回收还跟不上申请内存的速度，内核放大招触发 OOM(Out Of Memory)机制。
      - 根据算法选择一个占用物理内存较高的进程，然后将其杀死。循环这个过程直到内存够分配。

- 哪些内存可以被回收？

  - 文件页：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。
    - **回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存**。
  - 匿名页：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。
    - **通过 Linux 的 Swap 机制**：不常访问的放入磁盘，需要时重新读入。
  - **文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。**

- **减少回收内存带来的性能影响**

  - 调整文件页和匿名页的回收倾向
    - 更倾向于文件页的回收：因为文件页对于干净页的回收不会发生磁盘I/O
  - 尽早触发 kswapd 内核线程异步回收内存
    - 三个阈值（按剩余内存）：页高阈值、页低阈值、最小阈值
    - 超过页低阈值，kswapd 线程开始执行，直到高于页高阈值。
    - 超过最小阈值，触发直接内存回收。
    - 调整 min_free_kbytes，它虽然设置的是页最小阈值（pages_min），但另外两个阈值也是根据它算的。
  - NUMA 架构下的内存回收策略
    - **SMP 架构**指的是一种**多个 CPU 处理器共享资源的电脑硬件架构**，即每个 CPU 地区平等。
    - NUMA 架构，非一致存储访问结构（Non-uniform memory access）。
      - 将每个 CPU 分组，每一组用 node 表示。**每个 Node 有自己独立的资源，包括内存、IO 等**，，每个 Node 之间可以通过互联模块总线（QPI）进行通信。
      - 在 NUMA 架构下，当某个 Node 内存不足时，系统可以从其他 Node 寻找空闲内存，也可以从本地内存中回收内存。

- 如何保护一个进程不被 OOM 杀掉？

  - ``` c
    // points 代表打分的结果
    // process_pages 代表进程已经使用的物理内存页面数
    // oom_score_adj 代表 OOM 校准值 -1000-1000
    // totalpages 代表系统总的可用页面数
    points = process_pages + oom_score_adj*totalpages/1000
    ```

  - **用「系统总的可用页面数」乘以 「OOM 校准值 oom_score_adj」再除以 1000，最后再加上进程已经使用的物理页面数，计算出来的值越大，那么这个进程被 OOM Kill 的几率也就越大**。

  - 消耗内存越大越容易被杀

  - 如果你想某个进程无论如何都不能被杀掉，那你可以将 oom_score_adj 配置为 -1000。（**重要的系统服务可以这样设置**）



#### 在 4G 物理内存的机器上，申请 8G 内存会怎么样？

- 操作系统虚拟内存大小
  - 32 位系统：`32` 位系统的内核空间占用 `1G`，位于最高处，剩下的 `3G` 是用户空间；
    - 在申请虚拟内存阶段就会失败
  - 64 位系统：`64` 位系统的内核空间和用户空间都是 `128T`，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。
    - 可以正常申请虚拟内存。（申请但不用，系统不会进行映射）
    - 能申请127T多的虚拟内存，应该程序本身占用一定部分，然后申请虚拟内存也需要少量物理内存记录。
- Swap 机制的作用：Swap 就是把一块磁盘空间或者本地文件，当成内存来使用。（**匿名页回收的方式是通过 Linux 的 Swap 机制**）
  - 没有开启 Swap：超过物理内存，程序直接 OOM。
  - 开启 Swap：超过物理内存，程序可以正常运行。



#### 如何避免预读失效和缓存污染的问题？

- Linux 和 MySQL 的缓存
  - Linux 操作系统的缓存：Linux 操作系统是会对读取的文件数据进行缓存的，会缓存在文件系统中的 **Page Cache**，Page Cache 起到了加速访问数据的作用。
  - MySQL 的缓存：Innodb 存储引擎设计了一个**缓冲池**（Buffer Pool），Buffer Pool 属于内存空间里的数据。
    - 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。
    - 当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。
- **传统 LRU 算法的缺陷**
  - 预读失效导致缓存命中率下降
  - 缓存污染导致缓存命中率下降
- 预读失效，怎么办？
  - 什么是预读机制
    - Linux 操作系统为基于 Page Cache 的读缓存机制提供**预读机制**（**多读一点**），MySQL 的 Buffer Pool 类似。
  - 预读失效会带来什么问题？
    - 如果**这些被提前加载进来的页，并没有被访问**，就相当于白做了。
    - **不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是热点数据，这样就大大降低了缓存命中率** 。
  - 如何避免预读失效造成的影响？
    - **思路：让预读页停留在内存里的时间要尽可能的短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在内存里的时间尽可能长**。
    - Linux 操作系统实现两个了 LRU 链表：**活跃 LRU 链表（active_list）和非活跃 LRU 链表（inactive_list）**；
      - **预读页加入到 inactive list 区域的头部，当页被真正访问的时候，才将页插入 active list 的头部**，active list 末尾的页放到 inactive list 头部。
    - MySQL 的 Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：**young 区域 和 old 区域**。（两者一定的比例，默认63:37）
      - **预读的页加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部** ，young区域末尾的到old区域头部。
- 缓存污染，怎么办？
  - 什么是缓存污染？**批量读取数据时，大量数据占用活跃链表，淘汰热点数据**
    - **如果这些大量的数据在很长一段时间都不会被访问的话，那么整个活跃 LRU 链表（或者 young 区域）就被污染了**。
  - 缓存污染会带来什么问题？缓存未命中，产生大量磁盘I/O，影响系统性能。
  - 怎么避免缓存污染造成的影响？
    - **思路：提高进入到活跃 LRU 链表（或者 young 区域）的门槛，就能有效地保证活跃 LRU 链表（或者 young 区域）里的热点数据不会被轻易替换掉**。
    - Linux：第二次访问才从 inactive list 升级到 active list。
    - MySQL InnoDB：第二次 + 停留 old 时间判断。



#### 深入理解 Linux 虚拟内存管理



**64 位 CPU 对应 48 位虚拟内存地址：全局页目录项(9位) + 上层页目录项(9位) + 中间页目录项(9位) + 页表项(9位) + 页内偏移(12位)**

**32 位 CPU 对应 32位虚拟内存地址：页目录项(10位) + 页表项(10位) + 页内偏移(12位)**

48 位能表示 256 TB（128 TB + 128 TB），32位能表示 4GB（1 TB + 3 TB）

多个进程执行同一程序操作变量，会发生混乱。使用虚拟地址，可以隔离进程，防止多进程运行时造成的内存地址冲突

进程**用户态**虚拟内存空间：**代码段、数据段、BSS段、堆、文件映射于匿名映射区、栈、内核空间**。（地址从低到高）



**Linux 进程虚拟内存空间**

- 32 位

  - 用户态虚拟内存空间为 3 GB，虚拟内存地址范围为：0x0000 0000 - 0xC000 000
  - 低地址区域为保留区，无效指针null就是指到这里的。代码段从0x0804 8000开始。
  - **堆 地址的增长方向是从低地址到高地址增长。**

  - **文件映射与匿名映射区，栈 的地址增长方向是从高地址向低地址增长**。

- 64 位

  - 用户态虚拟内存空间为 128 GB，虚拟内存地址范围为：0x0000 0000 0000 0000 - 0x0000 7FFF FFFF F000
  - 高 8 位都是 0（核心态 都是 1）
  - 增长方向和结构 与 32 位 类似，底下也有保留区。

  

  **进程虚拟内存空间的管理**

  **每个进程都有唯一的 `mm_struct` 结构体，mm_struct 结构体来表示进程虚拟内存空间的全部信息。**

  **子进程在新创建出来之后它的虚拟内存空间是和父进程的虚拟内存空间一模一样的，直接拷贝过来**。

  内核通过 TASK_SIZE （定义了分界线）划分用户态和内核态的虚拟内存空间

![image-20240419193433119](.././assets/image-20240419193433119.png)

**内核是通过一个 mm_struct 结构的内存描述符来表示进程的虚拟内存空间的，并通过 task_size 域来划分用户态虚拟内存空间和内核态虚拟内存空间。**

结构体 `vm_area_struct`，正是这个结构体描述了这些虚拟内存区域 VMA（virtual memory area）

结构体 `vm_area_struct` 结构描述的是 [vm_start，vm_end) 这样一段左闭右开的虚拟内存区域。



内核态虚拟内存空间是所有进程共享的，**不同进程进入内核态之后看到的虚拟内存空间全部是一样的。**不同进程在用户态虚拟内存空间中访问同一个虚拟地址，看到的内容是不一样的。（背后映射到了不同的物理内存中）

进程进入内核态之后使用的仍然是虚拟内存地址，只不过在内核中使用的虚拟内存地址被限制在了内核态虚拟内存空间范围中。



**内核虚拟内存空间**

**内核对物理内存的管理都是以页为最小单位来管理的，每页默认 4K 大小**

![image-20240419194846179](.././assets/image-20240419194846179.png)

在 64 位体系下的内核虚拟内存空间与物理内存的映射就变得非常简单，由于虚拟内存空间足够的大，即便是内核要访问全部的物理内存，**直接映射**就可以了。

![image-20240419195000878](.././assets/image-20240419195000878.png)



**物理内存：随机访问存储器（ random-access memory ）也叫 RAM。**

RAM 分为两类：

- 静态 RAM（ `SRAM` ）：访问速度为 1 - 30 个时钟周期，但是容量小，造价高。（ L1Cache，L2Cache，L3Cache）
- 动态 RAM ( `DRAM` )：访问速度为 50 - 200 个时钟周期，但是容量大，造价便宜些（主存）

主存包括多个存储器模块和一个存储控制器。

DRAM 芯片的 IO 单位为一个` supercell` ，也就是一个字节(8 bit)。

CPU 与内存之间的数据交互是通过总线（bus）完成的，而数据在总线上的传送是通过一系列的步骤完成的，这些步骤称为总线事务（bus transaction）。

【**以 CPU 的视角说**】

- 数据从内存传送到 CPU 称之为读事务（read transaction）
- 数据从 CPU 传送到内存称之为写事务（write transaction）

**总线上传输的地址均为物理内存地址**。

CPU 只会访问虚拟内存，在操作总线之前，需要把虚拟内存地址转换为物理内存地址，总线上传输的都是物理内存地址。



#### 深入理解 Linux 物理内存管理

内核是以页为基本单位对物理内存进行管理的，通过将物理内存划分为一页一页的内存块，每页大小为 4K。



### 进程管理



#### 进程、线程基础知识

- 进程

  - 进程的概念：**运行中的程序，就被称为「进程」（Process）**
    - **并行**：多个任务轮着做；**并发**：多个任务一起做
    - **CPU 可以从一个进程切换到另外一个进程，在切换前必须要记录当前进程中运行的状态信息，以备下次切换回来的时候可以恢复执行。**
  - 进程的状态：
    - **进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。**
    - 进程还有另外两个基本状态：**创建状态、结束状态**
    - 运行状态：进程占用 CPU
    - 就绪状态：其他进程处于运行态而暂时停止
    - 阻塞状态：等待某一时间做完再执行。这时给他运行也无法运行。
      - 在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。
      - **挂起状态：描述进程没有占用实际的物理内存空间的情况**
        - 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；
        - 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；
  - 进程的控制结构
    - 用**进程控制块**（*process control block，PCB*）数据结构来描述进程
    - **PCB 是进程存在的唯一标识**，即**PCB 与 进程 共存亡**。
    - PCB 包含：进程描述信息，进程控制和管理信息，资源分配清单，CPU 相关信息
    - PCB 通常是通过**链表**的方式进行组织，把具有**相同状态的进程链在一起，组成各种队列**。
  - 进程的控制：**创建、终止、阻塞、唤醒**
  - 进程的上下文切换
    - **一个进程切换到另一个进程运行，称为进程的上下文切换**。
    - CPU 上下文切换分成：**进程上下文切换、线程上下文切换和中断上下文切换**。
    - **进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

- 线程

  - 为什么使用线程？线程之间可以并发运行且共享相同的地址空间。
  - 什么是线程？**线程是进程当中的一条执行流程。**
    - 优点：一个进程可以同时存在多个线程，线程之间可以并发运行且共享地址空间和文件等资源。
    - 缺点：进程中的一个线程崩溃时，会导致其所属的进程的所有线程崩溃。
  - **线程与进程的比较**
    - **进程是资源分配的单位，线程是 CPU 调度的单位；（最大的区别）**
    - 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如**寄存器和栈**；
    - 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；
    - 线程能减少并发执行的时间和空间开销；
      - 创建快、终止快、切换快、数据交互效率高。
  - 线程的上下文切换
    - 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；
    - **当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据**
  - 线程的实现
    - **用户线程**：用户空间实现的线程，用户态的线程库来完成线程的管理。
      - **用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。**
      - **线程控制块（*Thread Control Block, TCB*）**
      - 用户线程和内核线程的对应关系一对一
    - **内核线程**：内核中实现的线程，由内核管理的线程。
      - **内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。**
      - 用户线程和内核线程的对应关系多对一
    - **轻量级进程**：在内核中来支持用户线程。
      - **轻量级进程（*Light-weight process，LWP*）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度**。
      - LWP 与用户线程的对应关系就有三种：`1:1`, `N:1`,`M:n`

- 调度：选择一个进程运行这一功能是在操作系统中完成的，通常称为**调度程序**（*scheduler*）

  - > 前面说 线程 是调度的基本单位，这里却说进程调度的原因是很多相关书籍都这么说。所以理解能只有一个线程的进程吧。

  - 调度时机：进程的三种基本运行状态转换时，就会触发系统调度。

    - 根据如何处理时钟中断 ，把调度算法分为两类：
      - 非抢占式调度算法：被阻塞或退出时才会调用另外的进程
      - 抢占式调度算法：到点就挂起

  - 调度原则（5点）

    - 为了提高 **CPU 利用率**，在这种发送 I/O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择一个进程来运行。
    - 要提高**系统的吞吐率**，调度程序要权衡长任务和短任务进程的运行完成数量。
    - 如果进程的等待时间很长而运行时间很短，那**周转时间**就很长，这不是我们所期望的，调度程序应该避免这种情况发生。
    - 就绪队列中进程的**等待时间**也是调度程序所需要考虑的原则。
    - 对于交互式比较强的应用，**响应时间**也是调度程序需要考虑的原则。

  - 调度算法（单核 CPU 常见的调度算法）

    - 先来先服务（适合于 CPU 繁忙型作业的系统，不适合 I/O 繁忙型作业的系统）
    - 最短作业优先调度算法（长作业不友好）
    - 高响应比优先调度算法【(等待时间 + 要求服务时间) / 要求服务的时间】（无法实现，因为无法获知服务时间）
    - 时间片轮转调度算法（公平）
    - 最高优先级调度算法（静态优先级和动态优先级）
    - 多级反馈队列调度算法（前面两者的结合，兼顾长短作业）
      - 每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
      - 新进程放到第一级队列末尾，时间片内未完成则进入第二级队列末尾
      - 有新进程进入高优先级队列时，停止当前进程并移入队尾，执行新进程。



#### 进程间有哪些通信方式？（6种）

**内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。**

- 管道：使用简单，**通信方式效率低，不适合进程间频繁地交换数据**。
  - **所谓的管道，就是内核里面的一串缓存**。
  - **匿名管道`|`，它的通信范围是存在父子关系的进程**。数据无格式的流并且大小受限，单向。
  - **命名管道`mkfifo myPipe`，它可以在不相关的进程间也能相互通信**。
  - 两者数据都是**先进先出**

- 消息队列：（适合频繁交换数据）
  - **消息队列是保存在内核中的消息链表**
  - **消息队列不适合比较大数据的传输**
  - **消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销**

- 共享内存：（减少用户态与内核态消数据拷贝开销）
  - **共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**。

- 信号量（防止多进程竞争共享资源）
  - **信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据**。
  - 控制信息号的两种原子操作：（资源P减V增）
    -  **P 操作**，这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
    -  **V 操作**，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；
    - 信号初始化为 `1`，就代表着是**互斥信号量**，只能有一个进程同时访问。
    - 信号初始化为 `0`，就代表着是**同步信号量**，进程a（生成）应当在进程b后执行。

- 信号：（异常情况的工作模式下）
  - 信号是进程间通信机制中**唯一的异步通信机制**
  - 进程对信号的处理方式：执行默认操作、捕捉信号、忽略信号

- Socket（同主机或不同主机之间的进程通信）
  - 监听的 socket 和真正用来传送数据的 socket，是「**两个**」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。
  - 三种常见的通信方式：基于 TCP 协议的通信方式、基于 UDP 协议的通信方式、本地进程间通信方式




#### 多线程冲突了怎么办？

线程是调度的基本单位，进程则是资源分配的基本单位。

- 竞争与协作
  - 互斥的概念：「操作 A 和操作 B 不能在同一时刻执行」
    - **临界区（*critical section*），它是访问共享资源的代码片段，一定不能给多线程同时执行。**
    - **互斥（*mutualexclusion*）：保证一个线程在临界区执行时，其他线程应该被阻止进入临界区**
  - 同步的概念：「操作 A 应在操作 B 之前执行」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执行」等；
    - **并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步**。
- 互斥与同步的实现（信号量比锁的功能更强一些）
  - 锁
    - 忙等待锁（也被称为自旋锁）
      - **原子操作就是要么全部执行，要么都不执行，不能出现执行到一半的中间状态**
      - **原子操作指令 —— 测试和置位（*Test-and-Set*）指令**：测试旧值，设置新值。
      - 当获取不到锁时，线程就会一直 while 循环
    - 无忙等待锁
      - 当没获取到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。
  - 信号量
    - *P 操作*：将 `sem` 减 `1`，相减后，如果 `sem < 0`，则进程/线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；
    - *V 操作*：将 `sem` 加 `1`，相加后，如果 `sem <= 0`，唤醒一个等待中的进程/线程，表明 V 操作不会阻塞
    - P 操作是用在进入临界区之前，V 操作是用在离开临界区之后，这两个操作是必须成对出现的。
    - PV 操作的函数是由操作系统管理和实现的，所以操作系统已经使得执行 PV 函数时是具有原子性的。
    - 初值为 1，实现互斥。初值为 0，实现同步。
  - 生成者-消费者问题
    - **生产者**在生成数据后，放在一个缓冲区中；**消费者**从缓冲区取出数据处理；任何时刻，**只能有一个**生产者或消费者可以访问缓冲区；
    - 先生产在消费，**需要同步**。同一时刻只能有一个访问缓冲区，**需要互斥**。
    - 需要三个信号量：`mutex` 实现互斥，初始为 1；`fullBuffers` 消费者询问缓冲区是否有数据，初始为 0；`emptyBuffers` 生产者询问缓存区是否有空位，初始为 n（缓存区大小）。
- 经典同步问题
  - **哲学家就餐问题**（对于互斥访问有限的竞争问题一类的建模过程十分有用。）
    - 哲学家只有拿到左右两边的叉子时才能吃饭。
    - 方案一：使用pv，可能会发生同时竞争左边叉子导致死锁的现象。
    - 方案二：pv + 加上互斥信号量，每次进餐只有一位哲学家，效率低。
    - 方案三：pv + 偶数位先拿左边后拿右边，奇数位先拿右边后拿左边。(不会死锁，可以两人同时进餐)
    - 方案四：pv + 数组 state记录状态（三个状态，相当于生产者消费者的信号量）
  - **读者-写者问题**（为数据库访问建立了一个模型）
    - 读者只会读取数据，不会修改数据，而写者即可以读也可以修改数据。
    - 读读允许，读写互斥，写写互斥。
    - 方案一：信号量（读者优先，写者可能饥饿）
    - 方案二：信号量（写者优先，读者可能饥饿）
    - 方案三：信号量（flag，公平访问）



#### 怎么避免死锁？

- 死锁的概念：**两个线程都在等待对方释放锁**
  - 同时满足四个条件才会发生：**互斥、占有且等待、不可强占用、循环等待**
    - 互斥：**多个线程不能同时使用同一个资源**
    - 占有且等待：**线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1**
    - 不可强占用：**在自己使用完之前不能被其他线程获取**
    - 循环等待：获取资源的顺序构成了环形链

- 模拟死锁问题的产生
- 利用工具排查死锁问题
  - Java中使用 jstack 工具，它是 jdk 自带的线程堆栈分析工具
- 避免死锁问题的发生
  - **最常用的方法：使用资源有序分配法，来破环环路等待条件**。（都要ab资源，则获取时统一顺序）



#### 什么是悲观锁、乐观锁？

- 互斥锁和自旋锁
  - 最底层的两种就是会「互斥锁和自旋锁」，有很多高级的锁都是基于它们实现的。
  - **互斥锁**加锁失败后，线程会**释放 CPU** ，给其他线程；
    - 互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本。**两次线程上下文切换成本**
    - **如果被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁。**防止上下文切换的时间比锁的时间都长。
  - **自旋锁**加锁失败后，线程会**忙等待**，直到它拿到锁；
    - 通过 CPU 提供的 `CAS` 函数（*Compare And Swap*），在「用户态」完成加锁和解锁操作
    - **在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。**
  - **当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对**。
- 读写锁：**读写锁适用于能明确区分读操作和写操作的场景**
  - 读优先锁，写优先锁
  - **公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。**
  - 互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。
- 悲观锁和乐观锁
  - 悲观锁：**多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁**。（前面三者都属于悲观锁）
  - 乐观锁：**先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作**。
  - **只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。**（在线文档，SVN，Git 都用了乐观锁思想）



> CAS 不是乐观锁吗，为什么基于 CAS 实现的自旋锁是悲观锁？

CAS 是乐观锁没错，但是 CAS 和自旋锁不同之处，自旋锁基于 CAS 加了while 或者睡眠 CPU 的操作而产生自旋的效果，加锁失败会忙等待直到拿到锁，自旋锁是要需要事先拿到锁才能修改数据的，所以算悲观锁。



#### 一个进程最多可以创建多少个线程？

- **进程的虚拟内存空间上限**，因为创建一个线程，操作系统需要为其分配一个**栈空间**，如果线程数量越多，所需的栈空间就要越大，那么虚拟内存就会占用的越多。
- **系统参数限制**，虽然 Linux 并没有内核参数来控制单个进程创建的最大线程个数，但是有系统级别的参数来控制整个系统的最大线程个数。
- 实际情况：
  - 32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程。
  - 64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制，而会受系统的参数或性能限制。



#### 线程崩溃了，进程也会崩溃吗？

- **C/C++ 语言里，线程崩溃后，进程也会崩溃。**
-  **Java 中，线程崩溃不会导致 JVM 崩溃**
- 在进程中，**各个线程的地址空间是共享的**，既然是共享，那么某个线程对地址的**非法访问**就会导致内存的不确定性，进而可能会影响到其他线程，这种操作是危险的，操作系统会认为这很可能导致一系列严重的后果，于是干脆让整个进程崩溃。
- 非法访问：针对只读内存写入数据；访问了进程没有权限访问的地址空间（比如内核空间）；访问了不存在的内存。
- 线程崩溃后，进程是如何崩溃的呢？**通过信号**。
- **JVM 自定义了自己的信号处理函数，拦截了 SIGSEGV 信号，针对 *StackoverflowError* 和 *NullPointerException* 不让它们崩溃**。



### 调度算法



#### 进程调度、页面置换、磁盘调度算法

- 进程调度算法（也称 CPU 调度算法）
  - 发生 CPU 调度时机：运行态 - 等待态/就绪态/终止态；等待态 - 就绪态。
  - 先来先服务算法：按顺序一次服务。
    - 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。
  - 最短作业优先调度算法：**优先选择运行时间最短的进程来运行**
    - 对长作业不利
  - 高响应比优先调度算法：**每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行**
    - 实际无法实现，因为无法计算响应比
    - 优先权：（等待时间 + 要求服务时间）/ （要求服务时间）
  - 时间片轮转调度算法：**每个进程被分配一个时间段，称为时间片（\*Quantum\*），即允许该进程在该时间段中运行。**
  - 最高优先级调度算法：**从就绪队列中选择最高优先级的进程进行运行**
    - 按照优先级可以分为：静态优先级和动态优先级
    - 按照处理优先级的方式可以分为：非抢占式和抢占式
  - 多级反馈队列调度算法：「时间片轮转算法」和「最高优先级算法」的综合和发展。
    - 多级队列，优先级从高到低，优先级越高的时间片越短。
    - 新进程放到第一级队列末尾，先来先服务。没在时间片内完成，转入下一级队列末尾。
    - 高优先级队列为空，调度执行低优先级。进程运行时，有新进程进入高优先级队列，将当前进程移至末尾，执行新进程。
    - **兼顾了长短作业，同时有较好的响应时间。**
- 页面置换算法
  - 当 CPU 访问的页面**不在物理内存**时，便会产生一个**缺页中断**，请求操作系统将所缺页调入到物理内存。
  - 如果物理内存中找不到空闲页，需要「页面置换算法」。
  - 页面置换算法是在**出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面**。
  - 最佳页面置换算法：**置换在「未来」最长时间不访问的页面**。（时机无法实现，因为无法预知）
  - 先进先出置换算法：**选择在内存驻留时间很长的页面进行中置换**
  - 最近最久未使用的置换算法：**选择最长时间没有被访问的页面进行置换**（由于开销比较大，实际应用中比较少使用。）
  - 时钟页面置换算法：把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。
    - 指针指到访问位为0，就淘汰页面。
    - 指针指到访问位为1，就置0，继续移动。
  - 最不常用置换算法：**当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰**。
- 磁盘调度算法
  - 先来先服务算法
  - 最短寻道时间优先算法：优先选择从当前磁头位置所需寻道时间最短的请求
    - 可能会出现饥饿情况：**原因是磁头在一小块区域来回移动**
  - 扫描算法：**磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向**
    - 中间磁盘相应频率比两边高很多
  - 循环扫描算法：**磁道只响应一个方向上的请求**，到边缘后移动至另一边最边缘。
  - LOOK 与 C-LOOK 算法（分别优化了扫描算法和循环扫描算法）
    - LOOK 算法：磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而**不需要移动到磁盘的最始端或最末端，反向移动的途中会响应请求**。
    - C-LOOK 算法：磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，**反向移动的途中不会响应请求**。（反向还是到边缘，正向到最远请求位置）



### 文件系统



#### 文件系统全家桶

- 文件系统的组成
  - Linux：**一切皆文件**，为每个文件分配两个数据结构：索引节点和目录项
  - 索引节点 *inode* ：记录文件元信息。（文件的唯一标识，存储在磁盘，会被加载到内存）
  - 目录项 *dentry* ：记录文件名字、索引节点指针以及层级关系。（内核维护，缓存在内存）
  - 目录项和索引节点的关系是多对一。一个文件可以有多个别名。硬链接的实现就是多个目录项中的索引节点指向同一个文件。
  - 目录也是文件，也是用索引节点唯一标识。普通文件在磁盘里面保存的是文件数据，而目录文件在磁盘里面保存子目录或文件。
  - 目录不是目录项，**内核会把已经读过的目录用目录项这个数据结构缓存在内存**
  - 文件系统把多个扇区组成了一个**逻辑块**，每次读写的最小单位就是逻辑块（数据块）
  - 磁盘格式化，会分成三个区域：超级快（文件系统详细信息）、索引节点区（索引节点）、数据块区（文件或目录数据）。
- 虚拟文件系统：给用户提供一个统一的接口
  - 根据存储位置的不同，可以把文件系统分为三类：磁盘的文件系统、内存的文件系统、网络的文件系统。
- 文件的使用：用户习惯以字节的方式读写文件，而操作系统则是以数据块来读写文件
- 文件的存储
  - 连续空间存储：**文件存放在磁盘「连续的」物理空间中，读写效率高**
    - **文件头里需要指定「起始块的位置」和「长度」**
    - **存在「磁盘空间碎片」和「文件长度不易扩展」的缺陷。**
  - 非连续空间存储
    - 链表方式：**消除磁盘碎片，文件长度可以动态扩展**
      - 隐式链表：**文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置**
      - 显示链表：**把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中**，这张表格称为**文件分配表（*File Allocation Table，FAT*）**，对于大磁盘而言占用空间大。
    - 索引方式：为每个文件创建一个「**索引数据块**」，里面存放的是**指向文件数据块的指针列表**（类似目录）
      - **文件头需要包含指向「索引数据块」的指针**
      - 大文件可能出现索引数据块放不下索引信息，使用**链式索引块**，**在索引数据块留出一个存放下一个索引数据块的指针**
- 空闲空间管理
  - 空闲表法：为所有空闲空间建立一张表，表内容包括空闲区的第一个块号和该空闲区的块个数。
  - 空闲链表法：每一个空闲块里有一个指针指向下一个空闲块
  - 位图法：利用二进制的一位来表示磁盘中一个盘块的使用情况
- 文件系统的结构
  - **块组**：「一个块的位图 + 一系列的块」，外加「一个块的 inode 的位图 + 一系列的 inode 的结构」
- 目录的存储
  - **普通文件的块里面保存的是文件数据，而目录文件的块里面保存的是目录里面一项一项的文件信息。**
  - 列表：一项一项列出来
  - 哈希表：文件名进行哈希计算，查找效率高。
- 软链接和硬链接
  - 硬链接是**多个目录项中的「索引节点」指向一个文件**，也就是指向同一个 inode
    - **硬链接是不可用于跨文件系统的**
    - **只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。**
  - 软链接相当于重新创建一个文件，这个文件有**独立的 inode**，但是这个**文件的内容是另外一个文件的路径**
    - **软链接是可以跨文件系统的**
    - **目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已**
- 文件 I/O
  - 缓冲与非缓冲 I/O：**根据「是否利用标准库缓冲」划分**
  - 直接与非直接 I/O：**根据是「否利用操作系统的缓存」**
  - 阻塞与非阻塞 I/O VS 同步与非同步 I/O
    - **阻塞 I/O：阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程**。
    - **非阻塞I/O** 的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好。**最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。**
    -  **基于非阻塞 I/O 的多路复用：I/O 多路复用接口最大的优势在于，用户可以在一个线程内同时处理多个 socket 的 IO 请求**
    - 上述都是同步 I/O。因为都需要等待**内核将数据从内核空间拷贝到应用程序空间**。
    - 真正的**异步 I/O** 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。**和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作**



#### 进程写文件时，进程发生过了崩溃，已写入的数据会丢失吗？（不会）

因为进程在执行 write （使用缓冲 IO）系统调用的时候，实际上是将文件数据写到了内核的 page cache，它是文件系统中用于缓存文件数据的缓冲，所以即使进程崩溃了，文件数据还是保留在内核的 page cache，我们读数据的时候，也是从内核的 page cache 读取，因此还是依然读的进程崩溃前写入的数据。内核会找个合适的时机，将 page cache 中的数据持久化到磁盘。但是如果 page cache 里的文件数据，在持久化到磁盘化到磁盘之前，系统发生了崩溃，那这部分数据就会丢失了。

- Page Cache
  - **Page Cache 的本质是由 Linux 内核管理的内存区域**
  - page 在操作系统中通常为 4KB 大小（32bits/64bits），而 Page Cache 的大小则为 4KB 的整数倍。
  - **`Page Cache = Buffers + Cached + SwapCached`**
  - 操作系统为基于 Page Cache 的读缓存机制提供**预读机制**（PAGE_READAHEAD）
  - 优势： 加快数据访问；减少 I/O 次数，提高系统磁盘 I/O 吞吐量
  - 劣势：占用额外物理空间；对应用层并没有提供很好的管理 API；在某些应用场景下比 Direct I/O 多一次磁盘读 I/O 以及磁盘写 I/O。
- Page Cache 与文件持久化的一致性 & 可靠性
  - **任何系统引入缓存，就会引发一致性问题。**
  - **吞吐量与数据一致性保证是一对矛盾。**
  - 当前 Linux 下以两种方式实现文件一致性：
    1. **Write Through（写穿）**：向用户层提供特定接口，应用程序可主动调用接口来保证文件一致性；
    2. **Write back（写回）**：系统中存在定期任务（表现形式为内核线程），周期性地同步文件系统中文件脏数据块，这是默认的 Linux 一致性方案



### 设备管理



#### 键盘敲入 A 字母时，操作系统期间发生了什么？

- 设备控制器
  - 每个设备都有一个叫**设备控制器（*Device Control*）** 的组件，CPU 是通过设备控制器来和设备打交道的。
  - 控制器是有三类寄存器，它们分别是**状态寄存器（*Status Register*）**、 **命令寄存器（*Command Register*）以及数据寄存器（*Data Register*）**
  - 输入输出设备可分为两大类 ：**块设备（*Block Device*）（硬盘、USB）和字符设备（*Character Device*）（鼠标）**
- I/O 控制方式
  - 控制器相当于一个小 CPU，它可以自己处理一些事情，但完成任务后如何通知 CPU ?（轮询、中断）
  - 但中断的方式对于频繁读写数据的磁盘，并不友好，CPU 频繁被中断。解决方法：**DMA(*Direct Memory Access*)**
  - 实现 DMA 功能要有 「DMA 控制器」硬件的支持。
- 设备驱动程序
  - 为了屏蔽「设备控制器」的差异，引入了**设备驱动程序**。
  - 设备控制器是硬件，设备驱动程序软件。
  - 不同的设备控制器虽然功能不同，但是**设备驱动程序会提供统一的接口给操作系统**。
- 通用块层
  - 对于块设备，为了减少不同块设备的差异带来的影响，Linux 通过一个统一的**通用块层**，来管理不同的块设备。
- 存储系统 I/O 软件分层
  - Linux 存储系统的 I/O 由上到下可以分为三个层次，分别是文件系统层、通用块层、设备层。
    - **文件系统层**，包括虚拟文件系统和其他文件系统的具体实现，它向上为应用程序统一提供了标准的文件访问接口，向下会通过通用块层来存储和管理磁盘数据。
    - **通用块层**，包括块设备的 I/O 队列和 I/O 调度器，它会对文件系统的 I/O 请求进行排队，再通过 I/O 调度器，选择一个 I/O 发给下一层的设备层。
    - **设备层**，包括硬件设备、设备控制器和驱动程序，负责最终物理设备的 I/O 操作。
- 键盘敲入字母时，期间发生了什么？
  1. **键盘控制器**就会产生扫描码数据，并将其缓冲在键盘控制器的寄存器中，紧接着键盘控制器通过总线给 CPU 发送**中断请求**
  1. CPU 收到中断请求后，操作系统会**保存被中断进程的 CPU 上下文**，然后调用键盘的**中断处理程序**。
  1. 键盘的中断处理程序是在**键盘驱动程序**初始化时注册的，那键盘**中断处理函数**的功能就是从键盘控制器的寄存器的缓冲区读取扫描码，再根据扫描码找到用户在键盘输入的字符
  1. 得到了显示字符的 ASCII 码后，就会把 ASCII 码放到「读缓冲区队列」，接下来就是要把显示字符显示屏幕了，显示设备的驱动程序会定时从「读缓冲区队列」读取数据放到「写缓冲区队列」，最后把「写缓冲区队列」的数据一个一个写入到显示设备的控制器的寄存器中的数据缓冲区，最后将这些数据显示在屏幕里。
  1. 显示出结果后，**恢复被中断进程的上下文**



### 网络系统



#### 什么是零拷贝？

- 为什么要有 DMA 技术？
  - 没有DMA：整个数据的传输过程，都要需要 CPU 亲自参与搬运数据的过程，而且这个过程，CPU 是不能做其他事情的。
  - DMA 技术：**在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务**。 **CPU 不再参与「将数据从磁盘控制器缓冲区搬运到内核空间」的工作，这部分工作全程由 DMA 完成**。（CPU 仍需要将数据从内核缓存区拷贝到用户缓冲区）
- 传统的文件传输有多糟糕？
  - 传统 I/O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I/O 接口从磁盘读取或写入。期间共**发生了 4 次用户态与内核态的上下文切换**，因为发生了两次系统调用，一次是 `read()` ，一次是 `write()`。还**发生了 4 次数据拷贝**，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的。
    - 第一次拷贝：DMA，磁盘数据拷贝到内核缓冲区
    - 第二次拷贝：CPU，内核缓冲区拷贝到用户缓冲区
    - 第三次拷贝：CPU，用户缓冲区拷贝到内核 socket 缓冲区
    - 第四次拷贝：DMA，内核 socket 缓冲区拷贝到网卡缓冲区
  - **要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数**。
- 如何优化文件传输的性能？
  - **要想减少上下文切换到次数，就要减少系统调用的次数**。
  - 在文件传输的应用场景中，**用户缓冲区是没有必要存在的**
- 如何实现零拷贝？
  - 两种方式：mmap + write；sendfile
  - **mmap + write**：用 `mmap()` 替换 `read()`。`mmap()` 系统调用函数会直接把内核缓冲区里的数据「**映射**」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。（**减少了一次数据拷贝，上下文切换还是4次**）
  - **sendfile**：系统提供的函数，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如果网卡支持SG-DMA（*The Scatter-Gather Direct Memory Access*）技术，还可以直接把内核缓冲区拷贝到网卡。这就是所谓的**零拷贝（*Zero-copy*）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。**
    - **零拷贝技术：sendfile + SG-DMA**
    - 零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，**只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。**
    - **零拷贝技术可以把文件传输的性能提高至少一倍以上**
    - 使用零拷贝项目：Kafka，Nginx
- Page Cache 有什么作用？
  - **优点**：缓存最近被访问的数据；预读功能。
  - **但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DMA 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能**
  - 所以，针对大文件的传输，不应该使用 PageCache，也就是说不应该使用零拷贝技术。
- 大文件传输用什么方式实现？
  - **在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术**。
  - 异步体现在内核向磁盘发送读请求，不用等待直接放回。知道内核将数据拷贝到进程缓冲区的时候通知进程。
  - 直接体现在绕过了 Page Cache

**总结：**

- 传输大文件的时候，使用「异步 I/O + 直接 I/O」；
- 传输小文件的时候，则使用「零拷贝技术」；



#### I/O 多路复用：select/poll/epoll

- 最基本的 Socket 模型
  - 要想客户端和服务器能在网络中通信，那必须得使用 Socket 编程，它可以跨主机间通信。
  - 调用 `socket()` 函数后，调用 `bind()` 函数，**绑定 IP 地址和端口**（目的是为了确定发到哪里，哪张网卡，哪个端口）
  - 然后调用 `listen()` 实现监听。然后调用 `accept()` 来从内核获取连接，没有则等待客户端连接。
  - 监听的 Socket 和真正用来传数据的 Socket 是两个：
    - 一个叫作**监听 Socket**；
    - 一个叫作**已连接 Socket**；
  - 连接完成后，客户端和服务端通过 `read()` 和 `writer` 来读写数据。
  - 最基础的 TCP 的 Socket 编程，它是**阻塞 I/O 模型**，基本上只能一对一通信，那为了服务更多的客户端，我们需要改进网络 I/O 模型。
- 如何服务更多的用户？
  - 理论值：**最大 TCP 连接数 = 客户端 IP 数×客户端端口数**。
  - 实际限制：文件描述符、系统内存
- 多进程模型：为每个客户端分配一个进程来处理请求
  - 父进程，fork() 函数创建一个子进程，子进程复制父进程的文件描述符。
  - 父进程只关心 **监听 Socket**，子进程只关心 **已连接 Socket**
  - **进程的上下文切换**不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。开销大。
- 多线程模型
  - 线程频繁创建和销毁开销也不小。所以使用**线程池**的方式来避免线程的频繁创建和销毁。
- I/O 多路复用
  - 只使用一个进程来维护多个 Socket
  - 类似一个 CPU **并发**多个进程，所以也叫做时分多路复用。
  - select/poll/epoll 内核提供给用户态的多路复用系统调用，**进程可以通过一个系统调用函数从内核中获取多个事件**。
- select/poll
  - **都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合**
- epoll
  - 通过两个方面，解决 select/poll 问题：
    - 在内核里使用**红黑树来跟踪进程所有待检测的文件描述字**（增删改时间复杂度O(logn)）
    - 使用**事件驱动**的机制，内核里**维护了一个链表来记录就绪事件**
  - **epoll 被称为解决 C10K 问题的利器**。（C10K，一万个客户端）
  - 支持两种事件触发模式，分别是**边缘触发（*edge-triggered，ET*）和水平触发（*level-triggered，LT*）**。
    - 边缘触发：**服务器端只会从 epoll_wait 中苏醒一次**，需要保证一次读完内核缓冲区。
    - 水平触发：**服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束**



#### 高性能网络模式：Reactor 和 Proactor

- 演进
  - 每一条连接创建进程 - 每一条连接创建线程 - 线程池（资源复用）- I/P 多路复用
- **Reactor ：对 I/O 多路复用作了一层封装，将面向过程改为面向对象**
  - 直译是反应堆，这里的反应指的是「**对事件反应**」，也就是**来了一个事件，Reactor 就有相对应的反应/响应**。
  -  **I/O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 / 线程**。
  - Reactor 模式主要由 **Reactor** 和**处理资源池**这两个核心部分组成，它俩负责的事情如下：
    - Reactor 负责**监听和分发事件**，事件类型包含连接事件、读写事件；
    - 处理资源池负责**处理事件**，如 read -> 业务逻辑 -> send；
  - 单 Reactor 单进程 / 线程
    - C语言单进程，Java单线程。
    - 全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争。
    - 缺点：**无法充分利用 多核 CPU 的性能**，**如果业务处理耗时比较长，那么就造成响应的延迟**；
    - **不适用计算机密集型的场景，只适用于业务处理非常快速的场景**。
  - 单 Reactor 多进程 / 线程
    - **能够充分利用多核 CPU 的能力**
    - **因为一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方**。
  - 多 Reactor 多进程 / 线程
    - 通过多个 Reactor 来解决了前面的缺陷，主 Reactor 只负责监听事件，响应事件的工作交给了从 Reactor。
    - 大名鼎鼎的两个开源软件 Netty 和 Memcache 都采用了「多 Reactor 多线程」的方案
    - 采用了「多 Reactor 多进程」方案的开源软件是 Nginx，不过方案与标准的多 Reactor 多进程有些差异。
  - 多 Reactor 单进程 / 线程（复杂且没有性能优势，实际不使用）
- Proactor
  - **Reactor 是非阻塞同步网络模式，而Proactor 是异步网络模式**
  - **阻塞I/O，等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程**。
  - **非阻塞 I/O**，非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，`read` 调用才可以获取到结果。「数据从内核态拷贝到用户态」还是要等。
  - 阻塞和非阻塞都是同步的。
  - **异步 I/O 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待**。
- Reactor 和 Proactor
  - **Reactor 是非阻塞同步网络模式，感知的是就绪可读写事件**。**「来了事件操作系统通知应用进程，让应用进程来处理」**
  - **Proactor 是异步网络模式， 感知的是已完成的读写事件**。**「来了事件操作系统来处理，处理完再通知应用进程」**
  - **Reactor 模式是基于「待完成」的 I/O 事件，而 Proactor 模式则是基于「已完成」的 I/O 事件**。



#### 什么是一致性哈希？

- 如何分配请求？（其实这个问题就是「负载均衡问题」）
  - 加权轮询：配置高的，权重高，承担更多请求。（无法应对分布式系统，因为数据水平切分）
- 使用哈希算法有什么问题？
  - **如果节点数量发生了变化，也就是在对系统做扩容或者缩容时，必须迁移改变了映射关系的数据**
  - 需要我们进行**迁移数据**，重新对数据和节点做映射。最坏情况所有数据都要迁移。
- 使用一致性哈希算法有什么问题？
  - 哈希算法是对节点的数量进行取模运算，而**一致哈希算法是对 2^32 进行取模运算，是一个固定的值**。
  - **一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上**。
  - 映射的结果值往**顺时针的方向的找到第一个节点**，就是存储该数据的节点。
  - **在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响**。
  - **一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题**。
- 如何通过虚拟节点提高均衡度？
  - **不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。**
  - 节点 A 加上编号来作为虚拟节点：A-01、A-02、A-03
  - **节点数量多了后，节点在哈希环上的分布就相对均匀了**
  - **当节点变化时，会有不同的节点共同分担系统的变化，因此稳定性更高**。
  - **带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景**。



### Linux 命令



#### 如何查看网络的性能指标？

- 性能指标有哪些？（带宽、延时、吞吐率、PPS(Packet Per Second)）
  - *带宽*，表示链路的最大传输速率。
  - *延时*，表示请求数据包发送后，收到对端响应，所需要的时间延迟。
  - *吞吐率*，表示单位时间内成功传输的数据量。
  - *PPS*，全称是 Packet Per Second（包 / 秒），表示以网络包为单位的传输速率。
- 网络配置如何看？（`ifconfig` 和 `ip` 命令）
  - `ifconfig` 和 `ip` 命令只显示的是网口的配置以及收发数据包的统计信息，看不到协议栈里的信息。
- socket 信息如何查看？（`netstat` 或者 `ss`）
- 网络吞吐率和 PPS 如何查看？（`sar` 命令）
  - 用法是给 `sar` 增加 `-n` 参数就可以查看网络的统计信息
- 连通性和延时如何查看？（`ping` 命令）



#### 如何从日志分析 PV、UV？

页面访问次数（*PV*），访问人数（*UV*）

- 别急着开始
  - `ls -lh` 命令可以查看日志文件的大小（日志不大用）
  - 使用 `scp` 命令将文件传输到闲置的服务器再分析（日志大的时候）
- 慎用 cat
  -  `cat` 命令是用来查看文件内容，有多少读多少。（不适用大文件）
  -  `less` 命令，按序读取，往下看的时候才加载。（大文件用）
  - `tail` 命令，返回倒数x行的内容（`tail -n x`）
- PV 分析
  - 访问量，日志多少行就又多少访问量。
  - 使用 `wc -l` 命令
- PV 分组
  - **`awk` 是一个处理文本的利器**
- UV 分析：也使用 `awk`
- UV 分组：也是用 `awk`
- 终端分析：也是用 `awk`
- 分析 TOP 3 的请求：也是用 `awk`

在Linux终端中，竖线符号 "|" 代表着管道符号（Pipe），它的作用是将一个命令的输出作为另一个命令的输入。使用管道可以将多个命令串联起来，让它们协同工作，从而实现更复杂的操作。



## Java 面试题



### MySQL 面试题



#### SQL 基础



**SQL 和 NOSQL**

- SQL 关系型数据库：数据以行列二维表的形式存储
  - 支持 ACID，即原子性 Atomicity，一致性 Consistency，隔离性 Isolation 和持续性 Durability。
- NoSQL 非关系型数据库：数据以 JSON 或 键值对 的形式存储
  - 支持 BASE，即基本可用 Basically Available，软状态 Soft state 和最终一致性 Eventually consistent。



**三大范式**

- 第一范式：每一列不可分割
- 第二范式：每一列都和主键相关，而不是部分相关（针对联合主键）
- 第三范式：非主属性不依赖与其他非主属性（消除传递依赖）

后面还有 BCNF 范式 、第四范式 和第五范式。

一般来说，在关系型数据库设计中，最高也就遵循到 BCNF，普遍还是3NF。但也不绝对，有时候为了提高某些查询性能，我们还需要破坏范式规则，也就是**反规范化**。



**连表查询**

- 内连接 inner join：返回匹配的
- 左外连接 left join：返回左表所有行
- 右外连接 right join：返回右表所有行
- 全连接 full join：返回两个表的所有行，MySQL 中需要通过 left join + union + right join 实现 full join



**避免插入重复数据**

- 添加 UNIQUE 约束
- 使用 INSERT ... ON DUPLICATE KEY UPDATE 插入时有重复键则更新
- 使用 INSERT IGNORE 插入时有重复键忽略



**SQL执行顺序**

1. FROM
2. ON
3. OUTER JOIN (LEFT JOIN, RIGHT JOIN, FULL JOIN?)
4. WHERE
5. GROUP BY
6. AGG FUNC (COUNT, AVG, SUM...)
7. HAVING
8. SELECT
9. DISTINCT
10. ORDER BY
11. LIMIT / OFFSET



#### 存储引擎



**SQL 过程**

- 客户端

- 服务层

  - 连接器
  - 查询缓存
    - 8.0 后被删除：查询缓存无效化问题（表的数据发生变化，缓存就无效了），维护一致性成本高

  - 解析器：词法分析（识别关键字），语法分析（是否满足语法规则），语法树

  - 执行 SQL
    - 预处理阶段：检查表或字段是否存在
    - 优化阶段：选择成本最小的执行计划
    - 执行阶段：根据执行计划，从存储引擎中获取记录。

- 存储引擎



- InnoDB
  - 索引和数据一起保存，B+ 树
  - 支持事务
  - 行级锁：锁的粒度更小，更好支持并发性能
  - 崩溃恢复：redo log
- Myisam
  - 索引和数据分离保存
  - 不支持事务
  - 表级锁
  - 不支持崩溃恢复



#### 索引



索引类型：

- 按「数据结构」分类：B+树索引、Hash索引、Full-text索引
  - InnoDB 和 MyISAM 都只支持 B+树索引 和 Full-text 索引
  - Memory 只支持 B+树索引和 hash索引
- 按「物理结构」分类：聚簇索引（主键索引）、二级索引（辅助索引）
  - 主键索引叶子节点放的是所有数据
  - 二级索引叶子结点放的是主键值（回表）
- 按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引
  - 主键索引：建立在主键字段上的索引
  - 唯一索引：建立在 unique 字段上的索引
  - 普通索引：建立在普通字段上的索引（不为主键不为 unique）
  - 前缀索引：针对字符串类型字段前几个字符建立的索引（减少索引的存储空间） 
- 按「字段个数」分类：单列索引、联合索引
  - 单列索引：建立在一个字段上的索引
  - 联合索引：建立在多个字段上的索引
    - 最左匹配原则：按照最左有限的方式进行索引匹配
    - 不遵循 最左匹配原则 会导致索引失效
    - 最左匹配原则匹配到范围查询就停止匹配，即 范围查询后面的字段无法用到联合索引



索引下推：通过把索引过滤条件下推到存储引擎，来减少 MySQL 存储引擎访问基表的次数。

覆盖索引：索引中包含了要查询的所有列。



联合索引 abc：

- 查ac，a走联合索引，c走索引下推
- 查ba，ab都走联合索引



创建表时，InnoDB 会根据不同场景选择索引：

- 有主键选主键作为索引
- 没有主键选第一个不包含null值的唯一列作为索引
- 上述条件都不满足，则生成一个隐式自增id列作为索引



主键的选择：

- 唯一 且 非空
- 最好递增，避免频繁页分裂，影响性能
- 不建议用业务数据作为主键，防止后续变动
- 单机系统 考虑 自增字段，分布式系统 考虑 分布式 ID 方案



索引失效的场景：

1. 使用 左 或 左右 模糊匹配
2. 对 索引列 使用函数 或 计算
3. 联合索引不遵循最左匹配原则
4. where 子句中 or 前后有非索引列



InnoDB 的数据是按「数据页」为单位来读写的，默认大小为 16K，数据页之间是双向链表的结构。每一个节点都是一个数据页。

数据页中的记录按照「主键」顺序组成单向链表。数据页中有一个**页目录**，是由多个槽组成的，槽相当于分组记录的索引，槽记录了每组地址偏移量，相当于指向了该组最后一个记录，可以通过二分法快速确定记录在哪个槽。



**B+树 的优点**

- 对比 B树

  - 非叶子节点：B+树只存放索引信息，B树存放索引信息和数据（B+树 减少 IO，相对来说更少数据）

  - 叶子结点：B+树链表连接，B树没有链表连接（利于范围查询）

- 对比 二叉树

  - B+树的时间复杂度为 O(log d N)，d为最大子节点个数，N为叶子节点个数（实际应用中，d>100，导致高度一般就 3-4 层）
  - 二叉树的时间复杂度为 O(log 2 N)

- 对比 Hash

  - B+树的应用场景过多，例如范围搜索。Hash 只适合等值查询。



#### 事务



事务的特性 ACID

- Atomicity 原子性：通过 undo log 保证
- Consistency 一致性：通过其他三个特性保证
- Isolation 隔离性：通过 MVCC 或者 锁机制 保证
- Durability 持久性：通过 redo log 保证



处理多个事务可能产生的并发问题：

- 脏读：读到其他其他事务未提交数据
- 不可重复读：查询结果不同
- 幻读：查询结果的记录数量不同



事务的隔离级别：

- 读未提交：事务没提交时，所做的变更就能被其他事务看到
- 读已提交：MVCC，提交后才能看到 （解决了脏读）
- 可重复读：MVCC，事务看到的数据和启动该事务时保持一致（解决了脏读 和 不可重复读，很大程度上避免了 幻读，默认的隔离级别）
  - 快照读(普通查询，读取进入事务时候的快照)通过 MVCC 避免幻读
  - 当前读(select ... for update, update, insert, delete ，读取最新数据）通过引入临键锁避免幻读
  - 幻读发生的场景：
    - A快照读记录为空，B新增记录x提交，A更新该条记录，A快照读查到记录数据
    - A快照读查范围数据n条，B新增记录x提交，A当前读再查范围数据 n + 1 条
  - 为了避免上述两种场景，在开启事务后，需要尽快执行当前读
- 串行化：加锁，后访问的事务必须等前一个事务执行完成才能执行（解决了脏读、不可重复读 和 幻读）
  - 普通查询也会对记录加 S 型 next-key 锁



**MVCC：**通过「版本链」来控制并发事务访问同一个记录时。

- 读已提交：在「每个select语句执行前」都会重新生成一个 Read View
- 可重复读：执行第一条select时，生成一个 Read View，然后整个事务期间都在用这个 Read View



Read View 有四个重要字段：

- creator_trx_id：创建该 ReadView 事务的事务id
- m_ids：创建时，活跃且未提交的事务id列表
- min_trx_id：创建时，活跃且未提交的最小事务id
- max_trx_id：创建时，下一个事务id（即还没有开始的事务）



InnoDB 中聚簇索引的隐藏列：

- trx_id：事务对该记录进行改动时，把该事务的id记录在 trx_id
- roll_pointer：事务对该记录进行改动时，旧版本的记录会被写入到 undo log 中，这个指针指向 旧版本记录



记录的可见分析

- trx < min_trx_id：该记录在创建 ReadView 之前的事务生成，可见
- trx >= max_trx_id：该记录是创建 ReadView 之后的事务生成，不可见
- trx  在 min_trx_id 和 max_trx_id 之间
  - trx_id 在 m_ids：该记录属于活跃未提交事务，不可见
  - trx_id 不在 m_ids：事务已提交，可见



#### 锁



类型：

- 全局锁：锁整个数据库，锁后数据库只读，主要用于全库备份
- 表级锁
  - 表锁：锁全表
  - 元数据锁：CRUD 加的是 MDL 读锁；表结构变更加的是 MDL 写锁
  - 意向锁：CRUD 前先加意向独占锁，再加独占锁（方便快速判断表里是否有记录被加锁）
- 行级锁（以下三种锁都有 S 锁 和 X 锁）
  - 记录锁：锁记录
  - 间隙锁(,)：只存在于可重复读，解决幻读问题
    - 间隙锁的 S锁 和 X锁，并没有区别。
    - 间隙锁之间是兼容的，即区域内可以添加多个间隙锁。
    - 插入意向锁：特殊的间隙锁，间隙锁锁的是范围，插入意向锁锁的是一个点，两者不兼容。
  - 临键锁(,]：记录锁 + 间隙锁，锁定一个范围，以及记录自身

共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥。



加锁：

- insert：正常情况下不会生成锁结构，通过 trx_id 实现 隐式锁。
  - 插入的位置如果有间隙锁，则生成插入意向锁，并进入等待状态。

- select：没加锁，可以通过 `select ... lock in share mode`加共享锁(S型锁) 和`select ... for update` 加排它锁(X型锁)
- update, delete：加独占锁(X型锁)



死锁的四个必要条件：**互斥、请求和保持、不可剥夺、循环等待**。

在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态：

- 设置事务等待锁的超时时间

- 开启主动死锁检测



#### 日志



- bin log 二进制日志，是 Server 层生成的日志，主要用于**数据备份 和 主从复制**
  - 追加写，记录变更操作。先写到 bin log cache
  - 有三种格式
    - STATEMENT：记录 SQL（可能导致从库重放结果不一样，使用now() 等函数）
    - ROW：记录修改后的记录数据
    - MIXED：根据情况，自动选择上述两种模式
- undo log 回滚日志，是 Innodb 存储引擎层生成的日志，实现了事务中的**原子性**，主要用于**事务回滚 和 MVCC**
  - 记录事务开始前的数据（包含 trx_id 和 roll_pointer）
  - 执行相反的操作即可回滚失误
  - 被存储在 Buffer Pool 缓冲池 中的 Undo 页 中，内存中，不可靠。
- redo log 重做日志，是 Innodb 存储引擎层生成的日志，实现了事务中的**持久性**，主要用于**崩溃恢复**
  - 记录事务提交后的数据，物理文件，可靠。
  - 循环写，write_pos 表示写入位置，checkpoint 表示擦除位置，Buffer Pool 的脏页(写入缓存池的修改还未写入磁盘)写入磁盘后即可擦除。
  - 但其实 redo log 也不是直接写到磁盘的，先是写到了 redo log buffer
  - bin log 是 server 层的日志，没有脏页信息，无法实现崩溃恢复
- relay log 中继日志，从库通过 io 线程拷贝主库的 bin log 后本地生成的日志
- slow query log 慢查询日志，用于记录执行时间过长的sql，需要设置阈值后手动开启

**WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上**。



bin log 和 redo log 都要写入磁盘，为了保证两者的一致性，MySQL 使用了 内部 XA 事务（两阶段提交）：

- prepare 阶段：将 XID 写入 redo log，事务状态设置为 prepare，同时持久化到磁盘
- commit 阶段：将 XID 写入 bin log，持久化到磁盘。将 redo log 的事务状态设置为 commit

MySQL 重启后会扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就查 bin log 中是否有相同的 XID。有则提交事务，没有则回滚失误。（**两阶段提交是以 binlog 写成功为事务提交成功的标识**）



#### 性能调优



使用 explain 是查看 sql 的执行计划，部分参数如下：

- key：实际用到的索引
- rows：扫描行数
- type：扫描类型（效率从高到底）
  - const：结果只有一条的主键或唯一索引扫描（通常是与常量比较）
  - eq_ref：唯一索引扫描（通常是多表联查）
  - ref：非唯一索引扫描（索引不唯一，所以还需要在等值索引的小范围继续扫描）
  - range：索引范围扫描（在索引范围内扫描）
  - index：全索引扫描（对索引表进行全扫描，好处是无需排序，尽量避免）
  - all：全表扫描（全表扫描，尽量避免）
- extra：其他
  - Using filesort：无法利用索引完成排序，需要内部排序甚至文件排序，效率底
  - Using temporary：使用临时表保存中间结果，效率底
  - Using index：使用了覆盖索引，避免了回表



#### 架构



主从复制过程：

- **写入 Binlog**：主库写 binlog 日志。
- **同步 Binlog**：从库创建 I/O 线程连接主库的 log dump 线程，接受 binlog 并写到 relay log 中。
- **回放 Binlog**：从库创建 SQL 线程，回放 binlog，同步数据。



主从延迟处理：强制走主库方案



分库：拆分数据库（解决并发连接过多，单机MySQL扛不住的问题）

分表：拆分数据表（解决表单数据过大，查询过慢的问题）

分库和分表都可以通过垂直和水平两种维度进行拆分。



### Redis



#### 数据类型及其底层数据结构



- Key

- Value

  - String：字符串、整数或浮点数
    - 底层结构：int 和 SDS（len值保存长度，可以存二进制数据）
    - 应用场景：缓存对象、分布式锁
    - 常用指令：
      - `set username:1 jim` 
      - `SET lock_key unique_value NX PX 10000`nx参数保证只在key不存在时操作,px为过期时间，释放锁 
  - List：一个链表，每个节点都包含一个字符串
    - 底层结构：压缩列表（元素个数小于 512 个，每个元素小于 64字节），双向链表。3.2版本后用 quicklist 实现
    - 应用场景：消息队列
    - 常用指令：
      - LPUSH + BRPOPLPUSH 实现消息队列
        - 消息队列的三大需求：消息保序、处理重复的消息和保证消息可靠性
        - 一边进一边出 保证了**消息保序**
        - BRPOPLPUSH 保证了阻塞读取，避免一直请求。以及消息者消费后备份消息，保证消息可靠。
        - 缺陷：不支持**消费组**实现，组内消费者分担消息消费，组间消费者可以重复消费（Stream 支持）
      - `LPUSH mq "111000102:stock:99"`（111000102 为消息id，保证了**消息不重复**）
      - `BRPOPLPUSH mq mq_bak 10`10为超时时间，将mq的最右元素返回并弹出到mq_bak

  - Hash：键值对
    - 底层结构：压缩列表（元素个数小于 512 个，每个元素小于 64字节），哈希表。7.0版本后用 listpack 实现
    - 应用场景：购物车(cart_id,[{iphone 11, 5599}, {apple watch s4, 2299}])
      - 也可以用 String 实现，String 保存一个 JSON 字符串即可。如果数据变更频繁就用 hash。
    - 常用指令：
      - `HSET uid:1 name jim  `
      - `HGET uid:1 name`

  - Set：无序并唯一字符串
    - 底层结构：整数集合（元素个数小于 512 个），哈希表
    - 应用场景：点赞、共同关注（交并差集操作）
    - 常用指令：
      - `SADD article:1 uid:1`添加
      - `SREM article:1 uid:1`删除

  - ZSet：有序并唯一键值对(浮点数-字符串，根据浮点数排序)
    - 底层结构：压缩列表（元素个数小于 128 个，每个元素小于 64 字节），跳表。7.0后用 listpack 实现
    - 应用场景：排行榜
    - 常用指令：
      - `ZADD read:ranking 200 jim` 添加 注意是 分数 在前
      - `ZREVRANGE read:ranking 0 2 WITHSCORES`展示阅读量前三的人及其分数
  - BitMap：一连串的二进制数组（占用空间小）
    - 底层结构：Redis 的 String ，但只能保存二进制 0 或 1
    - 应用场景：签到统计
    - 常用命令：
      - `setbit uid:sign:1:202409 2 1`2为偏移量，用来定位，记录用户9月3日已签到
      - `getbig uid:sign:1:202409 2 `查询
  - HyperLogLog：提供不精确的去重计数
    - 底层结构：比较复杂
    - 应用场景：百万级uv计数
    - 常用命令：
      - `pfadd page1:uv user1 usr2`添加两个访问用户
      - `pfcount page1:uv`计数
  - GEO：存储地理位置信息
    - 底层结构：和 zset 一致
    - 应用场景：滴滴打车
    - 常用命令：
      - `GEOADD cars:locations 116.034579 39.03045 33` 写入车辆经纬度信息，33是id
      - `GEORADIUS cars:locations 116.000000 39.000000 5 km ASC COUNT 10`返回10个 5km内最近的车辆信息
  - Stream：专门为消息队列设计，支持发布订阅模式、消费组、自动生成唯一ID、自动保存消费者读取消息并在消费成功后返回确认消息等功能
    - 应用场景：消费队列（但仍存在消息丢失和消息积压的问题）
    - 常见命令：
      - `XADD mq * name xiaolin` *表示生成唯一ID
      - `XGROUP CREATE mymq group1 0-0`创建名为group1的消费者，并从第一条消息开始读取
      - `XREADGROUP GROUP group1 consumer1 STREAMS mymq >`group1中的consumer1消费者开始消费，> 表示从第一条未读消息开始



数据结构

- SDS：在原本字符数组之上，增加了三个元数据：len 记录字符串长度、alloc记录分配的空间长度、flags 表示类型，用来解决 C 语言字符串的缺陷。
  - O(1) 复杂度获取字符串长度（len）
  - 二进制安全（len，不需要标识符标识出结尾位置）
  - 不会发生缓冲区溢出 (追加前 alloc - len 来判断是否需要扩容)
- 压缩列表：由连续内存块组成的顺序型数据结构，类似于数组（只适合保存节点数量不多的场景）
  - 压缩列表结构：zlbytes | zltail | zllen | entry1 | ... | entryN | zlend
    - zlbytes：记录整个压缩列表占用字节数
    - zltail：记录列表尾偏移量
    - zllen：记录节点数量
    - zlend：标识结束，固定值 0xFF
    - entry： prelen | encoding | data
      - prelen：记录前一个节点的长度（实现 向前遍历）
      - encoding：记录当前节点的数据类型和长度
      - data：实际数据
  - 缺陷：容易引发 **连锁更新**（连续多次的空间扩展操作）
    - 前一个元素大于等于254字节，下一个元素的 prevlen 也需要增大
    - 下一个元素的 prevlen 增大，整体也超过 254，导致下一个元素的 prevlen 也需要增大
    - ...
- 双向链表：包含 头指针 head、尾指针 tail、节点数量 len、以及可以自定义实现的 dup 复制、free 释放、match 比较 函数。
  - 通过自定义函数，链表节点可以保存各种不同类型的值
- quicklist：结构体 和 链表 类似，却别在于节点的结构。
  - qulicklistNode：前后指针、压缩列表指针、压缩列表字节大小、压缩列表元素个数
  - 添加元素时，先检查 压缩列表 能否容纳，不能容纳则再创建一个 quicklistNode
  - 通过控制 压缩列表字节大小、压缩列表元素个数 来避免潜在的 连锁更新 问题（没有完全避免）
- 哈希表：保存键值对的结构
  - Redis 采用了 拉链法 来解决冲突
  - 采用了 渐进式 rehash 来扩容：数据的迁移的工作不再是一次性完成，而是分多次迁移。
- 跳表：支持平均 O(logN) 复杂度的节点查找
  - 跳表是在链表基础上改进过来的，实现了一种「多层」的**有序链表**
  - 降低时间复杂度，需要尽可能相邻层数节点数量2:1。为此，跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。
  - 跳表结构：头尾节点、长度、最大层数
  - 调表节点结构：元素值，权重，后向指针，level数组（每个level：前向指针、跨度）
  - 对比平衡树：范围查找更简单，插入和删除更简单
- listpack：设计的目的是替代压缩列表，最大的特点就是 listpack entry 不再包含 prevlen
  - listpack 结构：listpack 总字节数 | listpack 元素数量 | listpack entry1 | ... | listpack entryN | listpack 结尾标识
  - listpack entry 结构：encoding | date | len
    - encoding：编码类型
    - data：实际数据
    - len：encoding + data 的 总长度
  - 压缩列表使用 prevlen 是为了 向前遍历，listpack 使用 len 向前遍历



#### 线程模型



Redis 为什么快：

- 大部分操作都在内存中进行
- 单线程模型避免了竞争（**命令只有一个线程在执行**，关闭文件、AOF 刷盘、释放内存创建了单独线程）
- I/O 多路复用机制，一个线程处理多个 IO 流（6.0 后引入了多线程 IO）
  - “多路”指的是多个网络连接客户端，“复用”指的是复用同一个线程
  - 使用 Reactor 模式：一个进程管理多个连接。（6.0 后引入了多线程 IO）

6.0 后，Redis 启动后默认创建 7 个线程：一个主线程，关闭文件、AOF 刷盘、释放内存各一个，三个 IO 线程





#### 事务



Redis 保证原子性：

- 单线程，不存在多线程安全问题
- lua 脚本实现将 多个命令 视为 整体执行（lua 脚本写好边界条件，防止报错）



一般都使用事务保证原子性，但是 Redis 的事务不支持回滚，它只负责把多个命令放在一起执行，防止其他命令插队。



#### 持久化



Redis 读写都在内存中，为了保证数据不丢失，提供了两种持久化方式：

- AOF 日志：Redis 执行完一条命令后，将 **命令** 追加写入日志文件中保存
  - 写回磁盘策略：
    - Always 同步写回；
    - Everysec：每隔一秒写回
    - No：由操作系统控制写回
  - 优缺点：数据安全性更好，但影响性能(IO 和 重写)同时恢复较慢
- RDB 快照：记录某一瞬间的**内存数据**
  - 两个命令来生成 RDB
    - save：主线程执行
    - bgsave：创建一个子线程来执行，避免阻塞主线程
  - 优缺点：速度快，占用空间小，但数据安全性较差（恢复期间写入会导致数据不一致）
- 一般都是用混合持久化（前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据）



#### 缓存淘汰 和 过期删除



- 缓存淘汰：内存写满后的处理策略（大体上有八种）
  - 不进行数据淘汰的策略
    1. noeviction：超过最大内存，不淘汰，直接不提供服务，返回错误。禁止写入，但仍可以查询删除。（**默认的内存淘汰策略**）
  - 进行数据淘汰的策略
    1. 在设置了过期时间的数据中进行淘汰
       1. volatile-random：随机淘汰设置了过期时间的任意键值；
       2. volatile-ttl：优先淘汰更早过期的键值。
       3. volatile-lru：淘汰所有设置了过期时间的键值中，最久未使用的键值；
       4. volatile-lfu（：淘汰所有设置了过期时间的键值中，最少使用的键值；
    2. 在所有数据范围内进行淘汰
       1. allkeys-random：随机淘汰任意键值;
       2. allkeys-lru：淘汰整个键值中最久未使用的键值；
       3. allkeys-lfu：淘汰整个键值中最少使用的键值。
- 过期删除：将已过期的键值对进行删除，Redis 采用的删除策略是 **惰性删除 + 定期删除**
  - 惰性删除：不主动删除 key，而是当查看或修改 key 时，先判断是否过期，过期就删除并返回null
  - 定期删除：每隔一段时间「随机」从数据库中取出一批 key 进行检查，删除其中的过期key。如果批次中 过期 key 占比过高，则再次抽取一批。



#### 集群



- **主从复制**：主从服务器的数据同步

  - 包括三种模式：**全量复制、基于长连接的命令传播、增量复制**。
  - 第一次同步，全量复制。后续命令传播。如果网络断开，根据 repl_backlog_buffer 缓冲区判断是全量同步还是增量同步。

  - 全量复制：基于 sync 命令，传输的是 RDB 文件
    - 使用场景：初次同步、从服务器数据丢失、主从服务器数据差异过大

  - 增量复制：基于 psync 命令，用于断网补发，传输的是 命令。
    - 如何实现：主服务器根据从服务器记录的偏移量，来发送增量数据。
      - **repl_backlog_buffer**：环形缓冲区，在主服务器中，记录了已经执行的命令
      - **replication offset**：标记环形缓冲区的偏移量，主从服务器都有
      - Tips：如果从服务器的数据已经环形缓冲区中，则需要进行全量复制，为了避免全量复制的性能损耗，尽量将环形缓冲区设置的大一点。

- **哨兵机制**：实现 主从节点 故障转移

  - 哨兵节点主要负责三件事情：**监控、选主、通知**

  - 监控

    - 三个定时监控：主从信息获取，哨兵信息发布，节点心跳检测（向主从节点以及其他哨兵发送）
    - 主观下线和客观下线
      - 主观下线：哨兵节点认为某个节点有问题。（心跳检测没有回应）
      - 客观下线：超过一定数量 quorum 的哨兵节点认为主节点有问题。（ quorum 的值建议设置为哨兵个数的二分之一加 1）

  - 选主 + 通知

    - 选主：每个哨兵发送命令给其余哨兵，其余哨兵如果是第一次收到该命令则同意，否则拒绝。如果每个哨兵获得的同意数大于等于 max(quorum, num(sentinels) / 2 + 1) 则成为Leader。如果没有哨兵满足则进行下一轮选举。

    - Leader 实现故障转移：选择节点成为主节点；向其余节点发送命令，使其成为新主节点的从节点；监视老主节点，上线后通知其成为新主节点的从节点。
      - 选择主节点的参考依据：响应时间短、从节点优先级高、复制偏移量大（越大越完整）、runid 小

- **集群模式**：将数据存储在多个服务器上（一份数据一个服务器存不下）

  - **虚拟槽分区**：每个键通过哈希算法映射到槽上，**每个集群节点负责一定范围的槽**。槽的个数是2 的 14 次方，和 HashMap 中数组长度是 2 的幂次方一样，能够保证扩容后，大部分数据停留在扩容前的位置，少部分需要迁移。
  - 支持主从复制和主节点的自动故障转移（与哨兵类似）



大 key 问题：某个 key 对应的 value 占用空间过大，或者元素过多

解决方案：拆分，定期清理没用数据



热 key 问题：某个 key 被大量访问

解决方案：读写分离



# 面渣逆袭

## Java SE



### Java 概述



Java 特点：面向对象(封装继承多态)、平台无关性、支持多线程、编译与解释并存

平台无关性的原理：Java 程序是通过 Java 虚拟机在系统平台上运行的，只要该系统可以安装相应的 Java 虚拟机，该系统就可以运行 java 程序。

**字节码** 是 Java 程序经过编译之类产生的.class 文件，字节码能够被虚拟机识别，从而实现 Java 程序的跨平台性。

Java 从源代码到运行的步骤

1. 编译：`.java` 被  **jdk 中的 javac** 编译为 虚拟机能理解的字节码 `.class`
2. 解释：**虚拟机** 执行字节码，翻译成机器码
3. 执行：执行机器码

c++ 没有内置多线程机制



JVM （Java 虚拟机） < JRE （Java 运行时环境） < JDK （Java 软件开发包）

JVM + 核心类库 = JRE

JRE + 开发工具 = JDK



### 基础语法



Java 的数据类型分两种：**基本数据类型**和**引用数据类型**。

**基本数据类型：**

- 数值型
  - 整数类型（byte、short、int、long）（1、2、4、8 字节）
  - 浮点类型（float、double）（4、8字节）
- 字符型（char）（2字节）
- 布尔型（boolean）（1比特）

**引用数据类型**：数组、类、接口



自动类型转换：表数范围小的可以赋给大的。

![image-20240516210133478](.././assets/image-20240516210133478.png)

**在 Java 里面，没小数点的默认是 int,有小数点的默认是 double**

- `float = 3.4` 不正确，不能将 double 直接赋值给 float，需要写成 `float f = 3.4F` 或者 强制类型转换 `float f = (flaot)3.4` 
- `short s = 1; s = s + 1;`不正确，因为 1 是 int，不能复制给 short。需要写成`short s = 1; s += 1;`，这样表达隐含强制类型转换



装箱就是把基本数据类型变成其对应的引用数据类型，拆箱反之。

Integer 是 int 的包装类，属于引用数据类型。



`&` 是 逻辑与，`&&` 是短路与。前者需要判断两个条件，后者前一个条件 false，直接返回 false。`|` 和 `||`同理。



switch(expr) 的作用范围：

- Java 5 以前：byte, short, char, int
- Java 5 开始：引入枚举类型 enum
- Java 7 开始：String

Long 在所有版本中都不可以。（浮点型 和 char 还有 boolean 也不行）

枚举类型：用于表示一组有限的命名常量

``` java
enum Color {
    RED,
    GREEN,
    BLUE
}
```



乘 2 的 n 次方最有效率的方式是 **左移 n 位**。



`i = i++;` 值不变：

**`i++` 是一个表达式，是有返回值的**，它的返回值就是 i 自加前的值。

Java对自加是这样处理的：首先把 i 的值（注意是值，不是引用）拷贝到一个临时变量区，然后对 i 变量加 1，最后返回临时变量区的值。

``` java
// i++ 干的事情 
int tmp = i;
i = i + 1;
return i;
```



IEEE 754 标准的单精度浮点数格式：

float 32位 ：符号位 1 + 指数 8（原本的值加上 127，这样可以表示正负） + 尾数 23（省略1不写）

尾数计算：25.125(D) = 11001.001(B) = 1.1001001 * 2 ^ 4 (B) 

指数计算：4 + 127 = 131(D)  = 10000011(B)

0 10000011 10010010000000000000000



float 储存在舍入误差  0.1+ 0.2 != 0.3

保证数据的高准确性（金融方面），需要使用`BigDecimal` 

在处理小额支付或计算时，可以转换为较小的货币单位（如分），可以提供运算速度同时保证准备性。

BigDecimal 0.1元 用 int 10分 来算.



### 面向对象



面向过程：拆分成一个一个步骤，然后一次调用函数。

面向对象：分解成各个对象，加强代码重用。

面向对象编程的三大特性：封装、继承、多态

- 封装：把对象的属性私有化，向外提供可访问的方法。
- 继承：允许子类继承父类的属性和方法
- 多态：同一个行为具有不同的表现形式
  - **三个前置条件：子类继承父类、子类重写父类方法、父类引用指向子类的对象**
  - 多态的目的是为了提高代码的**灵活性和可扩展性**，使得代码更容易维护和扩展。比如说动态绑定，**允许在程序在运行时再确定调用的是子类还是父类的方法。**

``` java
//子类继承父类
class Wangxiaoer extends Wanger {
    public void write() { // 子类重写父类方法
        System.out.println("记住仇恨，表明我们要奋发图强的心智");
    }

    public static void main(String[] args) {
        // 父类引用指向子类对象
        Wanger wanger = new Wangxiaoer();
        wanger.write();
    }
}

class Wanger {
    public void write() {
        System.out.println("勿忘国耻");
    }
}

```



重载：名字相同，但参数个数不同的方法（发生在同一个类下）

重写：子类和父类，一样的方法名一样的参数，但是不同的方法体（发生在子类中）

- 需要遵守 里氏代换原则：子类在扩展父类的功能时，不应改变父类原有的行为(throw)



面向对象设计中的五个基本设计原则：（SOLID 原则）

- 单一职责原则 SRP：一个类应该只有一个职责。
- 开闭原则 OCP：实体应该对扩展开放，对修改关闭。
- 里氏替换原则 LSP：子类在继承时不能改变父类已有的行为(throw)
- 接口隔离原则 ISP：一个类不应该依赖于它不需要的接口
- 依赖反转原则 DIP：高级模块不应该依赖低级模块，两者都应该依赖于抽象



访问修饰符的可见性：

|           | 同一个类中 | 同一个包中 | 子类中 | 全局范围 |
| --------- | ---------- | ---------- | ------ | -------- |
| private   | yes        |            |        |          |
| default   | yes        | yes        |        |          |
| protected | yes        | yes        | yes    |          |
| public    | yes        | yes        | yes    | yes      |



this 可以理解为 **指向对象本身的一个指针**



一个类只能继承一个抽象类；但一个类可以实现多个接口。

``` java
// 抽象类
abstract class Animal {
    String name;

    Animal(String name) {
        this.name = name;
    }

    // 抽象方法
    abstract void makeSound();

    // 具体方法
    void sleep() {
        System.out.println(name + " is sleeping");
    }
}

// 接口
interface Swimmable {
    void swim();
}

interface Flyable {
    void fly();
}

// 一个类只能继承一个抽象类
class Dog extends Animal {
    Dog(String name) {
        super(name);
    }

    // 实现抽象方法
    void makeSound() {
        System.out.println(name + " says woof");
    }
}

// 一个类可以实现多个接口
class Fish implements Swimmable, Flayable {
    // 实现接口方法
    public void swim() {
        System.out.println("The fish is swimming");
    }
    public void fly() {
        System.out.println("The fish can not fly");
    }
}

```



- **静态变量**：static 修饰的变量，也被称为类变量。属于类。在内存中仅有一个副本。
- **实例变量**：依存于某一个实例，需要先创建对象才能通过对象访问到它。
- **静态方法**：static 修饰的方法，也被称为类方法。可以通过 `类名.方法名` 或 `对象名.方法名` 使用。不能访问其中非静态的成员变量和方法。
- **实例方法**：依存于类的实例，需要使用 `对象名.方法名` 使用，可以访问类的所有成员变量和方法。



final 关键字的作用

- 修饰一个**类**时，表明这个类不能被继承。（String，Integer 等包装类都是 final 修饰的）
- 修饰一个**方法**时，表明这个方法不能被重写。
- 修饰一个**变量**时，表示这个变量一旦初始化就不能修改（如果是引用类型的变量，引用不可变，引用指向的内容可以变）



final, finally, finalize 区别：

- final 如上
- finally 是异常处理的一部分，finally 块的代码总是会被执行
- finalize 是 Object 的一个方法，不能显式地调用 finalize 方法，因为它总是由垃圾回收器在适当的时间自动调用。



`==` 操作符和 `equals()` 方法用于比较两个对象：

- `==`：用于比较两个对象的引用，即它们是否指向同一个对象实例。
- **equals() 方法**：用于比较两个对象的内容是否相等。



`hashCode()` 方法的作⽤是获取哈希码，它会返回⼀个 int 整数。哈希码是由对象的内存地址或者对象的属性计算出来的，通常不会重复，可以用来作为 键值对 的键，提高查询效率。

**重写 equals 时必须重写 hashCode ⽅法** 的原因是为了 维护 `equals()`和 `hashCode()`之间的一致性，确保键值对正确检索对象。如果没有重写，则 equals 为 true 是，对应的哈希码可能不同，导致出错。

不同的对象也可能有相同的哈希码，这种情况称为 哈希冲突。所以在哈希表处理键时，不仅比较哈希码，还比较 equals 。



Java 参数是值传递，不是引用传递。

- 值传递：方法调用时会将实际参数的值复制一份传递给方法，方法内的修改不会影响实际参数，修改的是副本。
- 引用传递：方法调用时会将实际参数的引用（内存地址）传递给方法，方法内的修改会影响到实际参数指向的对象，因为它们指向同一个内存地址。

在Java中，虽然传递的是对象的引用的副本，但由于对象是可变的，因此在方法内部对对象的修改会影响到原始对象。这导致了一些人错误地认为Java是引用传递。但从传递参数的方式来看，Java中的参数传递是值传递。



浅拷贝：仅拷贝被拷贝对象的成员变量的值。（拷贝基本数据类型的值，引用数据类型的地址）

深拷贝：完全拷贝对象，包括堆中的对象。

深拷贝是安全的，浅拷贝引用类型，如果变量修改，会影响原对象。

浅拷贝 通过 Object 提供的 clone() 方法实现

深拷贝 通过 重写 clone() 方法，或者 序列化 实现。



Java 创建对象的方式：new，反射机制，clone()，序列化



### String



String 不是基本数据类型，被 final 修饰，不可继承。



- **String**：适用于字符串内容不经常改变的场景。在使用字符串常量或进行少量的字符串操作时使用。
- **StringBuilder**：适用于单线程环境下需要频繁修改字符串内容的场景，比如在循环中拼接或修改字符串。
- **StringBuffer**：适用于多线程环境下需要频繁修改字符串内容的场景，保证了字符串操作的线程安全。



`String s = "abc"`：Java 首先检查字符串常量池中是否存在，如果存在，则让新的变量引用，如果不存在，则在字符串常量池创建，然后让变量引用它。（s 指向字符串常量池）



`String s = new String("abc")`：分为两步，第一步就是上面的过程，第二步是在堆中创建一个新的字符串对象，初始化为字符串常量池中的一个副本。（s 指向 堆）

这种方法创建了 1 或者 2 个对象，堆中肯定有一个，字符串常量池看之前是否有，没有的话也得创建一个。



String 不可变的好处：安全、容易缓存和重用（字符串常量池出现的原因）、哈希值固定不变，适合作为键。

String 中通过 "+" 拼接时，会在堆中产生新的对象。"+" 其实是通过 StringBuilder 实现的 



intern() 用于返回当前字符串的引用。如果常量池存在，则返回对应的引用，如果不存在，则在常量池添加后返回引用。

``` java
// s1 != s2 s1 != s3 s2 == s3  
String s1 = new String("abc");  // 在常量池和堆中创建对象，返回堆中的引用
String s2 = "abc";  // 常量池已有，返回常量池引用
String s3 = s1.intern();  // 常量池也有，返回常量池引用。

```



### Integer



**自动装箱** 过程中，会使用`Integer.valueOf()`方法来创建`Integer`对象。

`Integer.valueOf()`方法会针对数值在 -128 到 127 之间的`Integer`对象使用缓存。

``` java
// a == b，大于127 则会创建两个不同对象
Integer a = 127;
Integer b = 127;
```

要比较`Integer`对象的数值是否相等，应该使用`equals`方法，而不是`==`运算符。



Integer 缓存池，默认范围是 -128 到 127。主要目的是优化性能和内存使用。



new Integer(10) == new Integer(10) 结果为 false

`== `比较的是内存地址，不是值，两者在指向 堆 中的不同位置。



String 转成 Integer 的两个方法：（本质其实都是调用 `parseInt(String s, int radix)`，radix 表示进制）

``` java
Integer.parseInt(String s)
Integer.valueOf(String s)
```



### Object



Object 主要提供了 11 个方法：

- 对象比较：hashCode(), equals()
- 对象拷贝：clone()
- 对象转字符串：toString()
- 多线程调度：wait(), wait(long timeout), wait(long timeout, int nanos), notify(), notifyAll()
- 反射：getClass()
- 垃圾回收：finalize()





### 异常处理



`Throwable` 是 Java 语言中所有错误和异常的基类。它有两个主要的子类：Error 和 Exception。

- Error:  程序无法处理。
- Exception：程序可以处理。
  - 编译时异常（编译不通过）
  - 运行时异常



异常的处理方式：

- 抛出异常：
  - throw：用在方法上，后面跟的是异常类
  - throws：用在方法内，后面跟的是异常对象
- 捕获异常：try catch（finally 无论 try 中有无异常都要执行）



### I/O

 IO 流：

- 按照数据流方向划分：输入流、输出流
- 按照数据单位划分：字节流、字符流
- 按照功能划分：节点流、处理流、管道流



Java 的 IO 流体系到了一个设计模式——**装饰器模式**。（通过将对象放入包装对象中来动态地扩展其功能）



Java 缓冲区预防溢出：

- 合理设置缓冲区大小
- 控制写入数据量



为什么有了字节流还需要字符流？

字符流虽然是由 Java 虚拟机将字节转换得到的，但这个过程比较耗时，而且容易出现乱码问题，所以干脆提供了直接操作字符的接口。



IO 分类：

- BIO Blocking I/O：阻塞式 IO，等待 IO 完成。（适合连接少）
- NIO Non-blocking I/O：非阻塞式 IO，线程等待 IO 时，可以执行其他任务。（适合连接多但连接时间短）
- AIO Asynchronous I/O：异步 IO，线程发起 IO 请求后立即返回，IO 完成后通过回调函数通知线程。（适合连接多且连接时间长）



### 序列化



**序列化就是把 Java 对象转为二进制流**，方便存储和传输。

**反序列化就是把二进制流恢复成对象**。



Serializable 接口 是一个标记，没有具体作用。如果不实现这个接口，可能会报错。

serialVersionUID 就是起验证作用，验证序列化的对象和反序列化的对象 ID 是否一致。



序列化的时候是不包含静态变量的。对不不想进行序列化的变量，使用 `transient` 关键字修饰。



序列化方式：Java 对象流序列化、JSON 序列化、protoBuff 序列化



### 泛型 

`<T>`

泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。

泛型一般有三种使用方式:**泛型类**、**泛型接口**、**泛型方法**。

**常用的通配符为： T，E，K，V，？**



**泛型擦除（类型擦除）**：Java 的泛型是伪泛型，这是因为 Java 在编译期间，所有的类型信息都会被擦掉。因为 Java 的范型只存在于源码里，编译的时候给你静态地检查一下范型类型是否正确，而到了运行时就不检查了。

``` java
// 以下两者在 JRE 看来没有区别
// 源码还是得按上面的写
LinkedList<Integer> list = new ListedList<Integer>();
LinkedList list = new ListedList();
```

**类型擦除是为了向下兼容，JDK 5 之前没有泛型。**



### 注解



**Java 注解本质上是一个标记**

有了标记之后，我们就可以在编译或者运行阶段去识别这些标记，然后搞一些事情，这就是注解的用处。



### 反射



**反射是指在运行时动态地获取类的信息以及操作类的属性、方法和构造函数的能力。**

应用场景：注解、AOP



反射的基本原理可以简述如下：

1. 首先，通过类的全限定名（包名加类名）或对象的`getClass()`方法获取对应的`Class`对象。
2. 然后，通过`Class`对象的方法，可以获取类的构造函数、属性、方法等信息。
3. 最后，通过`Constructor`、`Field`和`Method`等类的实例，可以动态地创建对象、读写属性、调用方法等操作。



### JDK 1.8 新特性



- 接口默认方法：允许给接口添加一个非抽象的方法实现，只需要 `default` 用关键字修饰即可
- Lambda 表达式和函数式接口：函数作为一个方法的参数
- Stream API：用函数式编程方式在集合类上进行复杂操作
- 日期时间 API：改进日期时间管理
- optional 类：解决空指针异常的问题



Lambda 表达式本质上是一段匿名内部类，也可以是一段可以传递的代码。

只有那些函数式接口（Functional Interface）才能缩写成 Lambda 表示式。

函数式接口（Functional Interface）就是只包含一个抽象方法的声明。针对该接口类型的所有 Lambda 表达式都会与这个抽象方法匹配。（例如：Comparator, Runnable 等等）



Optional 是用于防范控制还早呢异常，可以看做是包装对象的容器。



Stream 流可以对一个包含一个或多个元素的集合做各种操作。（Filter, map 转换 等

- 中间操作： Filter 过滤, map 转换
- 终端操作：sorted 排序，match 匹配，count 技术，reduce 规约成一个值



## Java 集合框架



### 引言



Java 集合框架可以分为两条大的支线：

- Collection：List、Set、Queue
- Map

![image-20240517153029520](.././assets/image-20240517153029520.png)



ArrayDeque 是一个基于数组的双端队列，可以在两端插入和删除元素。

LinkedList，它既可以当作 List 使用，也可以当作 Queue 使用。



1. ArrayList：ArrayList 可以看作是一个动态数组，它可以在运行时动态扩容。优点是访问速度快，可以通过索引直接查到元素。缺点是插入和删除元素可能需要移动元素，效率就会降低。
2. LinkedList：LinkedList 是一个双向链表，它适合频繁的插入和删除操作。优点是插入和删除元素的时候只需要改变节点的前后指针，缺点是访问元素时需要遍历链表。
3. HashMap：HashMap 是一个基于哈希表的键值对集合。优点是插入、删除和查找元素的速度都很快。缺点是它不保留键值对的插入顺序。
4. LinkedHashMap：LinkedHashMap 在 HashMap 的基础上增加了一个双向链表来保持键值对的插入顺序。



### List



ArrayList 和 LinkedList 的区别主要体现在**数据结构、用途、是否支持随机访问、内存占用**等方面

- ArrayList
  - 基于动态数组，适合查找，支持随机访问，内存占用主要体现在预留空间
- LinkedList
  - 基于链表，适合增删（体现在效率上，不需要移动元素，时间复杂度还是一样 O(n)），不支持随机访问，内存占用主要体现在指针



ArrayList 的扩容机制：

初始的数组容量在定义的时候确定，满了后创建一个 1.5 被的新数组，然后拷贝过去。

ArrayList 使用`transient`修饰存储元素的`elementData`的数组，不让存储元素的数组被序列化。这是出于效率考虑，因为 ArrayList 长度为 100，但实际可能只用了 50。所以它 通过**readObject、writeObject** 自定义序列化和反序列化的策略。



- 快速失败：一旦检测到异常立即抛出
  - 直接遍历原有集合内容
  - java.util 包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改），比如 ArrayList 类。
- 安全失败：尽量继续执行程序，不立即抛出
  - 复制原有集合内容遍历
  - java.util.concurrent 包下的容器都是安全失败，可以在多线程下并发使用，并发修改，比如 CopyOnWriteArrayList 类。



实现 ArrayList 线程安全：

- 使用 Vector 代替 ArrayList。（不推荐，Vector 是一个历史遗留类）
- 使用 Collections.synchronizedList 包装 ArrayList，然后操作包装后的 list。
- 使用 CopyOnWriteArrayList 代替 ArrayList。
- 在使用 ArrayList 时，应用程序通过同步机制去控制 ArrayList 的读写。



CopyOnWriteArrayList 就是线程安全版本的 ArrayList。CopyOnWrite 写时复制，已经说明了其原理。它采用读写分离的并发策略，读操作无锁，写操作加锁，复制写完，然后将引用指向新容器。



### Map



JDK 8 中 HashMap 的数据结构是`数组`+`链表`+`红黑树`。

HashMap 的核心是一个动态数组，用于存储键值对。这个数组的每个元素称为一个“桶”（Bucket），每个桶的索引是通过对键的哈希值进行哈希函数处理得到的。

哈希冲突时，通过拉链法解决。当链表的长度超过 8 时，且数组的长度大于 64，链表就会转换为红黑树。红黑树的**查询效率**是 O(logn)，比链表的 O(n) 要快。

扩容机制：达到阈值（容量 * 负载因子）时，扩容成原来的两倍。然后重新计算元素哈希值，放入新数组中。



红黑树是一种自平衡的二叉查找树：

1. 每个节点要么是红色，要么是黑色；
2. 根节点永远是黑色；
3. 所有的叶子节点都是是黑色的（下图中的 NULL 节点）；
4. 红色节点的子节点一定是黑色的；
5. **从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点**



不用二叉树的原因：当插入数据有序时，可能会退化成链表。

不用平衡二叉树的原因，维护平衡的成本高。

红黑树是一种折中的方案，保证了树平衡的同时，保证了插入和删除操作的性能，查询效率是 O(logn)

**红黑树是一种自平衡的二叉查找树**，每个节点都大于其左子树中的任何节点，小于其右子节点树种的任何节点。

红黑树通过 **旋转(左旋和右旋) 和 染色** 保持平衡。



map 中 只重写 equals 没重写 hashcode 会导致 equals 相同的元素被放入 不同的桶中，



put() 流程：

1. hash 方法计算哈希值（hashcode() + 右移16位）
2. 扩容
3. 计算下标(`n- 1 & hash`)，放入。链表大于 8，数组大于 64 转换成 红黑树。 

get() 流程：

1. hash 方法计算哈希值（hashcode() + 右移16位）
2. 计算下标(`n- 1 & hash`)
3. 找到结果返回。如果会链表则遍历，如果为树，则查找红黑树。



hash 函数： `return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);`

key 的 hashCode 和 其右移16位做异或运算 是为了降低哈希碰撞的概率。这种方式利用了hashcode的 高16位 和低16位。

hashcode() 返回 int 类型的哈希值，32位。



HashMap 容量是 2 的倍数是为了快速定位元素下标。`(n - 1) & hash`

` n - 1` 相当于 低位掩码，当前位以及更高位没有意义，能被整除。余数就是低位，只需要通过与操作把低位获取即使余数。



如果你传入 17 作为初始容量，HashMap 实际上会被初始化为大小为 32 的哈希表。（转换为大于或等于 17 的最小 2 的幂）

不传入初始容量，则默认为 16



HashMap 里哈希构造函数的方法叫 除留取余法，除以一个不大于长度的数然后取余。

其他哈希函数的构造方法：直接定址、数字分析、平方取中、折叠法等



解决哈希冲突方法：

- 再哈希法：两套哈希算法，遇到冲突用另外一套。
- 开放地址法：遇到哈希冲突，寻找下一个空位。
  - 线性探测：从该位置开始依次找空位
  - 二次探测：从冲突位置开始以（1, -1, 4, -4, 9, -9）方式寻找
  - 双重哈希：和再哈希类似
- 拉链法



key 相等的条件：

1. 先用 `==` 判断两者引用的对象是否相同，相同则 key 一定相同
2. 引用对象不相同则 看 `hashcode()` 和 `equals()`，这两者相同也可说明 key 相同。

``` java
(k = e.key) == key || (key != null && key.equals(k))
```



红黑树节点的大小大概是普通节点大小的两倍，所以转红黑树，牺牲了空间换时间，更多的是一种兜底的策略，保证极端情况下的查找效率。

链表转红黑数阈值为 8 的原因：统计学中，节点个数为 8 的概率仅为 0.00000006

红黑数转链表阈值为 6 的原因：防止刚好在 8 附近，两者不断转换，浪费资源。



选择了 0.75 作为 HashMap 的默认加载因子这是对 空间 成本和 时间 成本平衡的考虑。设置小了浪费空间，设置大了浪费查找时间。



JDK 8 的 新 hash 算法（无符号右移 16 位） 保证了数组扩容后 **要么在原来的位置，要么在 原来的位置 + 原来的容量**

扩容后，只需要一次位运算即可判断位置，计算成本相对较低。

具体来说，就是判断原哈希值的高位中新增的那一位是否为 1，如果是，该元素会被移动到原位置加上旧容量的位置；如果不是，则保持在原位置。





JDK 1.8 对 HashMap 的优化：

1. 数据结构：从 数组 + 链表 改成了 数组 + 链表 + 红黑树
2. 链表插入方式：从 头插法 改成了 尾插法
3. 扩容 rehash：从 重新 hash 定位 到 简单逻辑判断就可确定。（高位新增是否为 1）
4. 扩容时机：从 先判断再插入 到 先插入到判断
5. 散列函数：从 四次移位和四次异或 到 一次



HashMap 在多线程下的问题：

- 多线程下扩容会死循环：JDK 1.7 中使用头插法，多线程扩容时可能出现环形链表，导致死循环。 JDK 1.8 已经修复。
- put 可能导致元素丢失：多线程没有加锁，哈希冲突时 put 被其他线程覆盖掉，没有用上链表。
- put 和 get 并发，导致 get 为 null：线程 1 put 时触发扩容，线程 2 get 为 null。



解决 HashMap 线程不安全：

- 直接在 Hashtable 方法上加入 `synchronized` 关键字（不推荐）
- Collections.synchronizedMap(Map) 包装器
- ConcurrentHashMap，使用 CAS + synchronized 关键字



HashMap 内部节点无序，LinkedHashMap 或者 TreeMap 是有序的。

- LinkedHashMap：维护了一个双向链表，有 before 和 after 标志前后节点。
- TreeMap：通过 key 的比较器决定元素顺序就，底层是 红黑树。



TreeMap 是基于红黑树实现的，put 元素的时候会先判断根节点是否为空，如果为空，直接插入到根节点，如果不为空，会通过 key 的比较器来判断元素应该插入到左子树还是右子树。

get 元素的时候会通过 key 的比较器来判断元素的位置，然后递归查找。

在没有发生哈希冲突的情况下，HashMap 的查找效率是 O(1)。适用于查找操作比较频繁的场景。而 TreeMap 是基于红黑树实现的，所以 TreeMap 的查找效率是 O(logn)。并且保证了元素的顺序，因此适用于需要大量范围查找或者有序遍历的场景。



### Set



HashSet 其实是由 HashMap 实现的，只不过值由一个固定的 Object 对象填充，而键用于操作。

HashSet 主要用于去重，它会自动去重，因为使用 HashMap 实现的。

HashSet 的 add 方法是通过调用 HashMap 的 put 方法实现的，通过哈希值判断是否重复，如果重复，则覆盖。



## Java 并发编程



### 基础



- 并行：多个处理器同时处理任务
- 并发：单个处理器通过时间片轮转的方式处理任务



线程安全：一段代码块或者一个方法在多线程环境中被多个线程同时执行时能够正确地处理共享数据

三个要素来确保线程安全：

- 原子性：共享变量的修改操作不可分割（互斥锁 synchronized 或者原子操作 AtomicInteger 来保证）
- 可见性：共享变量修改后可以立即被其他线程看到（volatile 关键字）
- 活跃性问题：确保线程不会因为死锁、饥饿、活锁等问题导致无法继续执行

活锁是彼此让步而无法向前推进。



基本单位、内存空间、开销、通信、崩溃影响范围 五个角度：

- **进程是操作系统分配资源的基本单位，线程是操作系统调度的基本单位**。
- 进程拥有独立的内存空间，线程共享所属进程的内存空间。
- 进程的创建和销毁需要资源的分配和回收，开销较大；线程的创建和销毁只需要保存寄存器和栈信息，开销较小。
- 进程间的通信比较复杂，而线程间的通信比较简单。
- 进程间是相互独立的，一个进程崩溃不会影响其他进程；线程间是相互依赖的，一个线程崩溃可能影响整个程序的稳定性。

一个进程中可以有多个线程，多个线程共用进程的堆和方法区（JDK 8 为元空间）资源，但是每个线程都会有自己的程序计数器和栈。



协程通常被视为比线程更轻量级的并发单元，它们主要在一些支持异步编程模型的语言中得到了原生支持（Kotlin、Go）



Java 中 线程之间的通信通过共享内存的方式来完成。JMM Java 内存模型决定一个线程的共享变量的写入何时对另外一个线程可见。

线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory，JMM 的抽象概念），本地内存中存储了共享变量的副本。

线程 A 和 线程 B 通信的步骤：

1. 线程 A 把 其本地内存中的共享变量副本刷新到主内存中
2. 线程 B 到主内存中读取共享变量同步到其本地内存



Java 中创建线程主要有三种方式，分别为继承 Thread 类、实现 Runnable 接口、实现 Callable 接口。

- 继承 Thread 类，重写 `run()`方法，调用 `start()`方法启动线程。
  - Java 不支持多重继承，所以如果类已经继承了另一个类，就不能使用这种方法了。
- 实现 Runnable 接口，重写 `run()` 方法，然后创建 Thread 对象，将 Runnable 对象作为参数传递给 Thread 对象，调用 `start()` 方法启动线程。
  - 避免 Java 的单继承限制，更加符合面向对象的编程思想。将 任务代码 和 线程控制代码 解耦。
- 实现 Callable 接口，重写 `call()` 方法，然后创建 FutureTask 对象，参数为 Callable 对象；紧接着创建 Thread 对象，参数为 FutureTask 对象，调用 `start()` 方法启动线程。
  - 可以获取线程的执行结果

本质都需要通过 start() 启动线程。

使用 start() 才能创建新线程，如果直接使用 run()，则是在主线程中执行，没有创建新线程。



在确定一个系统 **最多可以创建多个线程** 时，需要考虑系统的内存大小外和Java 虚拟机栈的大小。可以通过命令查看 JVM 栈的默认大小。

启动一个 Java 程序，会启动的线程：main线程、垃圾回收线程、编译器线程。



线程常用的调用方法：

- 等待
  - wait()：阻塞挂起，直到 其他线程调用共享对象的 notify() 或 notifyAll()；其他线程调用阻塞线程的 interrupt() 方法，然后阻塞进程异常返回。
  - wait(long timeout)：多了一个超时参数，指定时间没有被唤醒，则超时返回
  - wait(long timeout, int nanos)：nanos 参数表示额外的纳秒部分
  - join()：当一个线程调用另一个线程的 `join()` 方法时，调用线程将会被阻塞，直到被调用线程执行完毕或者超时，才会继续执行。
- 通知（唤醒线程的两个方法）
  - notify()：唤醒一个在这个共享变量上调用 wait 系列方法后被挂起的线程。一个共享变量上可能会有多个线程在等待，具体唤醒哪个等待的线程是随机的。
  - notifyAll()：唤醒所有在该共享变量上调用 wait 系列方法而被挂起的线程。
- 让出优先权
  - yield()：暗示线程调度器，请求让出自己的 CPU
- 中断：**设置线程的中断标志并不能直接终止该线程的执行。被中断的线程会根据中断状态自行处理。**
  - interrupt()：设置中断标志为 true 并立即返回（实际并没有被中断）
  - isinterrupted()： 检测当前线程是否被中断。
  - interrupted()： 检测当前线程是否被中断，同时如果中断，则会清除中断标志。
- 休眠
  - sleep(long millis)：暂时让出指定时间的执行权。

stop() 方法用来强制线程停止执行，目前已经处于废弃状态，因为危险。



Java 中，线程有六种状态：

| 状态         | 说明                                                         |
| :----------- | :----------------------------------------------------------- |
| NEW          | 初始状态：线程被创建，但还没有调用 start()方法               |
| RUNNABLE     | 运行状态：Java 线程将操作系统中的 **就绪 Ready 和 运行 Running** 两种状态笼统的称作“运行” |
| BLOCKED      | 阻塞状态：表示线程阻塞于锁                                   |
| WAITING      | 等待状态：表示线程进入等待状态，进入该状态表示当前线程需要等待其他线程做出一些特定动作（通知或中断） |
| TIME_WAITING | 超时等待状态：该状态不同于 WAITIND，它是可以在指定的时间自行返回的 |
| TERMINATED   | 终止状态：表示当前线程已经执行完毕                           |



上下文切换：当线程使用完时间片后，就会处于就绪状态并让出 CPU 让其他线程占用（实现并发）



Java 中的线程分为两类，分别为 daemon 线程（守护线程，例如垃圾回收线程）和 user 线程（用户线程，例如 main 线程）。

只要有一个用户线程还没结束，正常情况下 JVM 就不会退出。守护线程(例如垃圾回收)不影响 JVM 的退出。



线程间通信：

- volatile 和 synchronized 关键字
  - volatile 用来修饰成员变量，告知程序均需从共享内存中读取，保证可见性
  - synchronized 可以修饰方法，确保同一时间只有一个线程执行
- 等待/通知机制：wait() notify()
- 管道输入/输出流：用于线程之间的数据传输，媒介为内存。也实现了字节和字符流。
- 使用 Thread.join() ：当 join() 的线程结束后才继续当前线程
- 使用 ThreadLocal：使每个线程拥有独立副本



sleep() 和 wait() 区别：

- 所属类： Thread 类； Object 类。
- 锁的释放：不会释放任何锁；会释放锁。
- 使用对象：任何地方；必须在同步代码块或者同步方法中别调用，因为 wait() 方法的前提是当前线程必须持有对象的锁。
- 唤醒条件：指定时间后自动唤醒；notify() notifyAll()



线程安全：多线程环境下，多个线程对共享资源的访问不会导致数据的不一致性。

使用场景：实现单例模式，懒汉式单例则在第一次使用时初始化，这种方式需要使用双重检查锁定来确保线程安全，volatile 用来保证可见性，syncronized 用来保证同步。



### ThreadLocal



ThreadLocal 是 Java 中提供的一种 **用于实现线程局部变量** 的工具类。它允许每个线程都拥有自己的独立副本，从而实现线程隔离，用于解决多线程中共享对象的线程安全问题。



解决线程安全问题的方法：

- ThreadLocal：

  ``` java
  //创建一个ThreadLocal变量
  public static ThreadLocal<String> localVariable = new ThreadLocal<>();
  //设置ThreadLocal变量的值
  localVariable.set("沉默王二是沙雕");
  //获取ThreadLocal变量的值
  String value = localVariable.get();
  //删除ThreadLocal变量的值
  localVariable.remove();
  ```

- synchronized 修饰 方法或代码块

  ``` java
  public synchronized void method() {
      // 线程安全的操作
  }
  ```

- ReentrantLock

  ``` java
  ReentrantLock lock = new ReentrantLock();
  
  public void method() {
      lock.lock();
      try {
          // 线程安全的操作
      } finally {
          lock.unlock();
      }
  }
  ```

- 原子变量类（如 AtomicInteger，AtomicLong 等）,它们利用 CAS（比较并交换），实现了无锁的原子操作，适用于简单的计数器场景。

  ``` java
  AtomicInteger atomicInteger = new AtomicInteger(0);
  
  public void increment() {
      atomicInteger.incrementAndGet();
  }
  ```

- 线程安全的集合类，如 ConcurrentHashMap，CopyOnWriteArrayList 等。

  ``` java
  ConcurrentHashMap<String, String> map = new ConcurrentHashMap<>();
  ```

- volatile 变量

  ``` java
  private volatile boolean flag = false;
  ```

  

ThreadLocal 可以用来储存用户信息。假如在服务层和持久层也要用到用户信息，就可以在控制层拦截请求把用户信息存入 ThreadLocal，另外，cookie、session 等等数据隔离都可以通过 ThreadLocal 去实现。



ThreadLocal 本身并不存储任何值，它只是作为一个映射，来映射线程的局部变量。当一个线程调用 ThreadLocal 的 set 或 get 方法时，实际上是访问线程自己的 ThreadLocal.ThreadLocalMap。ThreadLocalMap 是 ThreadLocal 的静态内部类，它内部维护了一个 Entry 数组，key 是 ThreadLocal 对象，value 是线程的局部变量本身。



ThreadLocal 的实现原理就是，每个线程维护一个 Map，key 为 ThreadLocal 对象，value 为想要实现线程隔离的对象。

1、当需要存线程隔离的对象时，通过 ThreadLocal 的 set 方法将对象存入 Map 中。

2、当需要取线程隔离的对象时，通过 ThreadLocal 的 get 方法从 Map 中取出对象。

3、Map 的大小由 ThreadLocal 对象的多少决定。

在 ThreadLocalMap 中，`key = new ThreadLocal<>()` 是一个 **弱引用对象**。当 JVM 进行垃圾回收时，如果发现了弱引用对象，就会将其回收。value 是强引用。

**为什么 key 要设计成弱引用：当内存不足时，JVM 主动回收弱引用对象**。一旦 key 被回收，ThreadLocalMap 在 进行 get 和 set 的时候就会对 key 为 null 的 Entry 进行清理。



- 强引用是指通过 `new` 关键字创建的对象的默认引用方式。当一个对象被强引用所引用时，即使内存空间不足，垃圾回收器也不会回收该对象，宁愿抛出 OutOfMemoryError。

  ``` java
  Object obj = new Object();
  ```

- 弱引用是一种较强度较弱的引用方式。当一个对象只被弱引用所引用时，在垃圾回收器进行垃圾回收时，无论内存空间是否充足，该对象都会被回收。

  ``` java
  WeakReference<Object> weakRef = new WeakReference<>(new Object());
  ```

  

如果一个线程一直在运行，并且其 `ThreadLocalMap` 中的 Entry.value 一直指向某个强引用对象，那么这个对象就不会被回收，从而导致内存泄漏。当 Entry 非常多时，可能就会引发更严重的内存溢出问题。（ThreadLocal 内存泄露）

**避免内存泄漏问题**：使用完 ThreadLocal 后，及时调用 `remove()` 方法释放内存空间。`remove()` 方法会将当前线程的 ThreadLocalMap 中的所有 key 为 null 的 Entry 全部清除。



**ThreadLocalMap 源码系列：**

 虽然被叫做 Map，其实它是 **没有实现 Map 接口** 的，但是结构还是和 HashMap 比较类似的，主要关注的是两个要素：元素数组 和 散列方法。

- 元素数组：一个 table 数组，存储 Entry 类型的元素，Entry 是 ThreaLocal 弱引用作为 key，Object 作为 value 的结构。
- 散列方法：哈希取余法，取出 key 的 threadLocalHashCode，然后和 table 数组长度减一&运算（相当于取余）。

解决 Hash 冲突： 开放定址法(线性向后查找) 。

扩容机制：

- 扩容阈值：(len * 2) / 3
- rehash() 具体实现：清理过期的 Entry，然后还要根据条件判断`size >= threshold* 3/4`来决定是否需要扩容。
- resize() 具体实现：扩容成两倍，然后遍历重新散列，还是用 开放定制法。



父子线程共享数据：

不能用 ThreadLocal，但可以用 InheritableThreadLocal，在 Thread.init 的时候，如果父线程的inheritableThreadLocals 不为空，就把它赋给当前线程（子线程）的 inheritableThreadLocals。



### Java 内存模型 JMM



Java 内存模型（Java Memory Model）是一种 **抽象的模型，并不真实存在**，简称 JMM，定义了线程内存和主内存之间的抽象关系：线程之间的共享变量存储在 主内存（Main Memory）中，每个线程都有一个私有的 本地内存（Local Memory），本地内存中存储了共享变量的副本，用来进行线程内部的读写操作。本地内存可能对应于 CPU 缓存、寄存器或者其他硬件和编译器优化。



为什么线程用自己的内存？

- 提高并发性能，避免内存访问竞争。
- 避免指令重排序对最终结果产生影响。



并发编程的重要概念：

- **原子性**：要么全部执行，要么全部不执行。（synchronized）
- **可见性**：一个线程修改，其它线程能够立即看到。（volatile，final 和 synchronized）
- **有序性**：从前往后依次执行代码，并发时有可能会发生指令重排。（synchronized 和 volatile）



指令重排序：（依次经历）

- 编译器优化的重排序
- 指令集并行的重排序
- 内存系统的重排序



指令重排序的限制规则：**happens-before 和 as-if-serial** 

- happens-before：前者执行的结果对后者可见
  - 两个操作存在 happens-bofore 关系，并不意味着必须要按照指定的顺序运行，只要不影响结果就可以重排。
  - 六大规则：程序顺序规则、监视器锁规则、volatile 变量规则、start() 规则、join() 规则
- as -if-serial:**单线程程序的执行结果不能被改变**
  - 编译器、runtime 和处理器都必须遵守 as-if-serial 语义
  - 编译器和处理器都不会对存在数据依赖的操作做重排序



volatile 关键字主要有两个作用，一个是保证变量的内存可见性，一个是禁止指令重排序。

- 保证变量可见性：当线程对 volatile 变量写操作时，JMM 会在写入后插入一个 Store-Barrier（写屏障）指令，这个指令会强制将本地内存中的变量值刷新到主内存中。当线程对 volatile 变量读操作时，JMM 会插入一个 Load-Barrier（读屏障）指令，这个指令会强制让本地内存中的变量值失效，从而重新从主内存中读取最新的值。
- 禁止指令重排序：
  - 写 volatile 变量的操作之前的操作不会被编译器重排序到写操作之后。
  - 读 volatile 变量的操作之后的操作不会被编译器重排序到读操作之前。
  - 通过这两条规则，保证了 volatile 变量的写操作总是发生在任何后续读操作之前。



### 锁



synchronized 是最常用的锁，它使用简单，并且可以保证线程安全，避免多线程并发访问时出现数据不一致的情况。尽管synchronized 随着版本更迭不断轻量化，但仍是悲观锁。

可以用在方法和代码块中：

- 修饰方法：同一时间只允许一个线程执行该方法。
  - 如果加在 静态方法 static 上，锁的是这个类的 Class 对象，因为静态方法是属于类级别的。
- 修饰代码块：synchronized 后面的括号中指定了要锁定的对象，可以是 this，也可以是其他对象。



synchronized 加锁：（JVM 帮我们 lock 和 unlock）

- 修饰方法时：JVM 采用 ACC_SYNCHRONIZED 标记符来实现同步
- 修饰代码块时：JVM 采用 monitorenter、monitorexit 两个指令来实现同步
- 三者都是**基于 Monitor 实现**，Monitor 又是由 **ObjectMonitor  实现** 的。



保证可见性：

- 线程加锁前，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值。
- 线程加锁后，其它线程无法获取主内存中的共享变量。
- 线程解锁前，必须把共享变量的最新值刷新到主内存中。

保证有序性：

- 因为 as-if-serial 规则，所以能保证结果的有序性。无法保证指令不重排。

保证可重入：

- 锁对象的时候有一个计数器，获取锁 + 1，释放锁 - 1。



在对象头里，有一个叫做 Mark Word 的结构，其中有一个锁状态标志，用来记录锁的状态。

锁升级的过程：无锁 --> 偏向锁 --> 轻量级锁 --> 重量级锁

- 偏向锁：首次获得锁记录线程 ID，目的是消除同一线程的后续锁获取和释放的开销。如果另一个线程尝试获取这个锁，偏向模式会被撤销，并且锁会升级为轻量级锁。
- 轻量级锁：多个线程在不同时段获取同一把锁，即不存在锁竞争的情况，也就没有线程阻塞。
- 自旋锁：获取轻量级锁失败时，先进行自旋，反正立即进入阻塞状态。
- 锁粗化：当一系列锁操作在单一线程中完成时，将多个锁操作合并为一个更大范围的锁操作，减少锁请求次数。
- 锁消除：JIT 在运行时进行代码分析，消除不可能被多个线程访问的锁。

![image-20240520192100286](.././assets/image-20240520192100286.png)



| 区别       | synchronized     | ReentrantLock                  |
| ---------- | ---------------- | ------------------------------ |
| 锁实现机制 | 对象头监视器模式 | 依赖 AQS                       |
| 灵活性     | 不灵活           | 支持相应中断、超时、尝试获取锁 |
| 释放锁形式 | 自动释放锁       | 显式调用 unlock()              |
| 支持锁类型 | 非公平锁         | 公平锁 和 非公平锁             |
| 条件队列   | 单条件队列       | 多个条件队列                   |
| 可重入支持 | 支持             | 支持                           |



AQS，全称是 AbstractQueuedSynchronizer，中文意思是抽象队列同步器。

AQS 的思想是，如果被请求的共享资源空闲，则当前线程能够成功获取资源；否则，它将进入一个等待队列，当有其他线程释放资源时，系统会挑选等待队列中的一个线程，赋予其资源。

通过维护一个volatile 修饰的 int 类型的状态 和一个先进先出（FIFO）的队列，来实现对共享资源的管理。

支持两种同步方式：

- 独占模式：每次只能有一个线程持有锁
- 共享模式：多个线程可以同时获取锁



**ReentrantLock** 是可重入的独占锁，同一个线程可以重复获取同一个锁，其他线程会被阻塞。

``` java
ReentrantLock lock = new ReentrantLock();  // 默认构造方法是 非公平锁
ReentrantLock lock = new ReentrantLock(true);  // 有参构造方法传入true来创建公平锁
```

- 公平锁：锁会授予等待时间最长的线程

- 非公平锁：锁可能会授予刚刚请求它的线程，而不考虑等待时间。



CAS（Compare-and-Swap）是一种乐观锁的实现方式，全称为“比较并交换”，是一种无锁的原子操作。

CAS 是乐观锁，线程执行的时候不会加锁，它会假设此时没有冲突，然后完成某项操作；**如果因为冲突失败了就重试，直到成功为止**。

CAS 的三个值：

- V：要更新的变量var
- E：预期值expected
- N：新值new

判断 V 是否等于 E，如果等于，将 V 的值设置为 N；如果不等，说明已经有其它线程更新了 V，于是当前线程放弃更新，什么都不做。这里的 E 预期值本质上指的是旧值。

CAS 的三个问题：

- ABA 问题：无法知晓某个值改成其他后又改回来的情况
  - 解决：每次变量更新时，不仅更新变量的值，还更新一个版本号
- 循环性能开销：一直自旋的性能开销
  - 解决：限制自旋次数
- 只能保证一个变量的原子操作：无法保证多个变量的原子性
  - 改用锁来保证
  - 合并变量，封装成一个对象，通过 AtomicReference 来保证原子性



保证原子性的方法：

- 使用原子类：AtomicInteger
- 使用 juc 包下的锁：ReentrantLock
- 使用 synchronized



AtomicInteger 的原理：使用 CAS 实现。



死锁的四个必要条件：

- 互斥条件
- 持有并等待条件
- 不可剥夺条件
- 循环等待条件



避免死锁：至少破坏死锁发生的一个条件

- 破坏互斥条件：通常不可行，因为加锁就是为了互斥。
- 破坏持有并等待条件：一次性申请所有资源。
- 破坏不可剥夺条件：申请不到进一步资源时，释放已有资源。
- 破坏循环等待条件：对资源进行排序，线程按序申请。



如何排查死锁问题：

1. 在 Linux 中，可以先使用top, ps 等命令查看进程状态
2. 然后使用 JDK 自带性能监控工具：jps, jstat, jinfo, jmap, jstack, jcmd。或者可视化性能监控工具：JConsole, VisualVM（这些工具也可以用来查看 JVM 信息）



**线程同步** ：在多线程环境下如何安全地访问和修改共享资源的问题。

实现方式有 6 种：互斥量、读写锁、条件变量、自旋锁、屏障、信号量

在 Java 中，synchronized 和 Lock 接口是实现线程同步的常用方式。

- synchronized：属于典型的互斥量，它保证了同一时间只有一个线程可以访问共享资源。
- Lock：ReentrantLock



- 悲观锁：每次访问共享资源都会产生冲突
  - synchronized 关键字 和 Lock 接口
- 乐观锁：对共享资源的访问不会产生冲突
  - 使用 CAS 来保证线程执行的安全性



### 并发工具类



**CountDownLatch 倒计数器**，有两个常见的应用场景：

- 协调子线程结束动作：等待所有子线程运行结束
- 协调子线程开始动作：统一各线程动作开始的时机

核心方法：

- await()：等待 latch 降为 0
- await(long timeout, TimeUnit unit)：等待 latch 降为 0，但是可以设置超时时间。
- countDown()：latch 数量减 1；
- getCount()：获取当前的 latch 数量。



CyclicBarrier 同步屏障：允许一组线程互相等待，直到达到某个公共屏障点（barrier），然后再继续执行。

核心还是 await()



| CyclicBarrier                                                | CountDownLatch                                               |
| :----------------------------------------------------------- | :----------------------------------------------------------- |
| CyclicBarrier 面向的是线程数                                 | CountDownLatch 面向的是任务数                                |
| 在使用 CyclicBarrier 时，你必须在构造中指定参与协作的线程数，这些线程必须调用 await()方法 | 使用 CountDownLatch 时，则必须要指定任务数，至于这些任务由哪些线程完成无关紧要 |
| CyclicBarrier 可以在所有的线程释放后重新使用                 | CountDownLatch 在计数器为 0 时不能再使用                     |
| 在 CyclicBarrier 中，如果某个线程遇到了中断、超时等问题时，则处于 await 的线程都会出现问题 | 在 CountDownLatch 中，如果某个线程出现问题，其他线程不受影响 |



Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。

Semaphore 的本质就是**协调多个线程对共享资源的获取**。

可以用于做流量控制，特别是公用资源有限的应用场景，比如数据库连接。

使用方式：首先线程使用 Semaphore 的 acquire()方法获取一个许可证，使用完之后调用 release()方法归还许可证。还可以用 tryAcquire()方法尝试获取许可证。



Exchanger（交换者）是一个用于线程间协作的工具类。Exchanger 用于进行线程间的数据交换。它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。

如果第一个线程先执行 exchange()方法，它会一直等待第二个线程也执行 exchange 方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产出来的数据传递给对方。



ConcurrentHashMap 实现原理：

在 JDK 7 时：采用的是分段锁机制（Segment Locking），整个 Map 被分为若干段，每个段都可以独立地加锁。因此，不同的线程可以同时操作不同的段，从而实现并发访问。

- 由 Segment 数组结构和 HashEntry 数组构成的。
- put：和 HashMap 非常类似，只不过是先定位到具体的 Segment，然后通过 ReentrantLock 去操作而已。
- get：通过 hash(key) 定位到 segment，再遍历链表定位到具体的元素上。value是 volatile 的，不需要加锁。

在 JDK 8 后：不再使用分段锁，而是使用了一种更加精细化的锁——桶锁，以及 CAS 无锁算法。每个桶（Node 数组的每个元素）都可以独立地加锁，从而实现更高级别的并发访问。读操作通过 volatile 保持可见性，写操作通过 CAS 实现无锁更新。

- CAS + synchronized 来保证并发安全性，整个容器只分为一个 Segment，即 table 数组。
- put：计算 hash，遍历 node 数组，如果 node 是空的话，就通过 CAS+自旋的方式初始化；如果 node 非空，判断 node[i] ，为空则通过 CAS + 自旋写入数据，非空则用和 HashMap 一样，拉链法解决冲突，链表长度超过 8 则转换红黑苏，多加一个使用 synchronized写入数据。如果需要扩容，则 CAS + synchronized 实现扩容。
- get：通过 key 的 hash 进行定位，多一个判断 hash 值是否小于 0 。小于 0 说明是一个特殊节点，需要调用节点的 find 进行查找。



ConcurrentHashMap 是 HashMap 的线程安全版本，使用了 CAS、synchronized、volatile 来确保线程安全。

对比 HashMap 的优势：

- 允许并发，效率高。
- 读操作使用 volatile，不需要加锁

保证可见性：volatile

保证原子性：synchronized



CopyOnWriteArrayList 是一个线程安全的 ArrayList，它遵循写时复制（Copy-On-Write）的原则，即在写操作时，会先复制一个新的数组，然后在新的数组上进行写操作，写完之后再将原数组引用指向新数组。



### 线程池



线程池：管理线程的池子。线程池能够复用已创建的线程，避免创建和销毁开销的同时，还提高了响应速度。

工作流程：核心线程池干不完的放入任务队列，任务队列满了放入最大线程池（干完后多出来的线程会销毁），最大线程池还干不完执行拒绝策略。

核心参数：

- corePoolSize：核心线程池
- maximumPoolSize：最大线程池
- keepAliveTime：非核心线程存活时间
- unit：非核心线程存活时间单位
- workQueue：工作队列
- threadFactory：创建线程使用工厂
- handler：拒绝策略
  - AbortPolicy：拒绝任务，抛出异常。（默认策略）
  - CallerRunsPolicy：使用调用者线程来执行任务
  - DiscardPolicy：直接拒绝任务
  - DiscardOldestPolicy：丢弃工作队列中最老的请求，执行新任务。

常用的阻塞队列（工作队列）：

- ArrayBlockingQueue：数组实现有界策略（先进先出，适合固定大小的线程池）
- LinkedBlockingQueue：链表结构队列（不指定大小，默认是 Integer.MAX_VALUE）
- PriorityBlockingQueue：有优先级无界阻塞队列
- DelayQueue：延迟执行队列（二插堆实现，类似与 PriorityBlockingQueue）
- SynchronousQueue：无元素存储阻塞队列（实际上它不是一个真正的队列，因为没有容量。每个插入操作必须等待另一个线程的移除操作，同样任何一个移除操作都必须等待另一个线程的插入操作。）



线程池提交 execute 和 submit 区别：

- execute() 用于提交不需要返回值的任务
- submit()方法用于提交需要返回值的任务。线程池会返回一个 future 类型的对象，通过这个 future 对象可以判断任务是否执行成功，并且可以通过 future 的 get()方法来获取返回值



关闭线程池：shutdown() 和 shutdownNow()

- shutdownNow()能立即停止线程池，正在跑的和正在等待的任务都停下了。（interrupt 中断，无法响应中断请求的任务可能永远无法终止）
- shutdown()只是关闭了提交通道，用 submit()是无效的；而内部的任务该怎么跑还是怎么跑，跑完再彻底停止线程池。



如何配置线程数：

- 对于 CPU 密集型：减少上下文切换，所以将核心线程数设置为处理器核心数或核心数加一。
- 对于 IO 密集型：线程经常处于等待状态，所以可以设置成 核心数的两倍，提高 CPU 利用率。



创建线程池的方式主要有四种，本质都是通过 Excutors 创建（不推荐直接使用）：

- newFixedThreadPool (固定数目线程的线程池)
  - （n, n, 0, LQ）
  - 适用于处理 CPU 密集型的任务，长期执行任务。
- newCachedThreadPool (可缓存线程的线程池)
  - （0, max, 60s, SQ）
  - 并发执行大量短期的小任务
- newSingleThreadExecutor (单线程的线程池)
  - （1, 1, 0, LQ）
  - 适用于串行执行任务的场景，一个任务一个任务地执行。
- newScheduledThreadPool (定时及周期执行的线程池)
  - （n, max, 0, DQ）
  - scheduleAtFixedRate() ：按某种速率周期执行
  - scheduleWithFixedDelay()：在某个延迟后执行
  - 周期性执行任务的场景，需要限制线程数量的场景

前三种线程池的构造直接调用 ThreadPoolExecutor 的构造方法。上面（核心线程数，最大线程数，存活时间，工作队列缩写）



线程池异常处理方式：

- try-catch
- submit 执行，Future.get 接受异常
- 重写 ThreadPoolExecutor.afterExcute()，处理传递的异常引用
- 实例化时，传入自己的 ThreadFactory，设置 Thread.UncaughtExceptionHandler 处理为检测的异常。



线程池的五个状态：RUNNING,SHUTDOWN,STOP,TIDYING,TERMINATED。

RUNNING 通过 shutdown() 进入 SHUTDOWN，通过 shutdownNow() 进入 STOP。两者都没任务时，即为 TIDYING，执行完 terminal() 后即为 TERMINATED.



线程池提供了几个 setter 方法来设置线程池的参数。

setCorePoolSize(), setKeepAliveTime(), setMaximunPoolSize() 等等。

另外可以 用配置中心配置，或者 自己实现线程池，监听参数变化。



线程池调优：事前评估 --> 监控/告警 --> 动态调整 --> 事后观察 

注意事项：

- 合适的线程池大小（CPU 密集还是 IO 密集）
- 任务队列的选择（尽量有界队列）
- 尽量使用自定义的线程池（newFixedThreadPool 和 newScheduledThreadPool 队列无限大，容易导致内存溢出；newCachedThreadPool 最大线程无限大，可能导致负载过高 ）



单机线程池执行断电处理：对阻塞队列持久化；正在处理任务事务控制；断电之后正在处理任务的回滚，通过日志恢复该次操作；服务器重启后阻塞队列中的数据再加载。



### 并发容器和框架



Fork/Join 框架是 Java7 提供的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。

核心：**分而治之** 和 **工作窃取算法**

**分治思想**：将一个规模为 N 的问题分解为 K 个规模较小的子问题，这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解。（Fork 分，Join 合）

**工作窃取算法**：大任务拆成了若干个小任务，把这些小任务放到不同的队列里，各自创建单独线程来执行队列里的任务。干完活的线程窃取干活慢的线程里面的任务。（通常采用双端队列，自己执行一端拿，被窃取时另一端拿）

ForkJoinTask 与一般 Task 的主要区别在于它需要实现 compute 方法，用于判断是否需要进一步划分任务。





## JVM



### 引言



JVM，也就是 Java 虚拟机，它是 Java 实现跨平台的基石。

Java 程序：**编译器** 将 **.java 源代码** 编译成与平台无关的 **.class 字节码**，然后 **JVM** 对字节码进行解释，翻译为对应平台的 **机器码** 运行。



JVM 大致可以划分为三个部门：类加载器、运行时数据区和执行引擎。

- 类加载器：加载 Class 文件，读取到内存中
- 运行时数据区：方法区、堆、栈、程序计数器和本地方法栈
- 执行引擎：执行字节码，包括虚拟处理器、即时编译器 JIT 和 垃圾回收器



### 内存管理



垃圾回收 GC：释放垃圾占用的空间

**垃圾判断算法：**

- 引用计数算法：保存对象被引用的次数
- 可达性分析算法：引用链连接垃圾回收根 GC roots 开始的依次向下的对象，一个对象如果到垃圾回收根之间没有任务引用链，则表明其不可达，需要被回收。
  - GC Roots，是一组必须活跃的引用，不是对象，它们是程序运行时的起点，是一切引用链的源头。
  - 在 Java 中，GC Roots 包括以下几种：虚拟机栈中的引用，本地方法栈中 Java Native Interface (JNI) 的引用，类静态变量，运行时常量池中的常量

**垃圾回收算法：**

- 标记清理算法：标记出来然后清理（内存碎片问题）
- 复制算法：容量划分为一半，存活对象会被复制到另一半的一侧（浪费一半空间）
- 标记整理算法：标记然后将所有存活对象移到一侧。（移动成本高）
- 分代收集算法：融合上述 3 种基本的算法思想。新生代使用复制算法，老年代使用标记清理或标记整理算法。
  - 新生代：Eden 和 两个 Survivor，默认大小比例 8:1:1
  - 发生垃圾收集时，将 Eden 和 Survivor 中仍然存活的对象一次性复制到另外一块 Survivor 空间上，然后清理。

**垃圾收集器：**

- 新生代算法：
  - Serial：单线程，复制算法。
  - ParNew：多线程，复制算法
  - Parallel Scavenge 收集器：多线程，复制算法。主要关注吞吐量（吞吐量 = 运行时间/ (收集时间 + 运行时间)）
- 老年代算法：
  - Serial Old：单线程，标记整理算法。
  - Parallel Old：多线程，标记整理算法，关注吞吐量。

- CMS (Concurrent Mark-Sweep) 收集器：**一种以获取最短回收停顿时间为目标的收集器。**第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。
  - 初始标记：STW，从 GC Roots 出发标记可达对象 
  - 并发标记：STW，从初始标记出发标记可达对象
  - 重新标记：短暂 STW，完成剩余标记任务，并发中的少量改动。
  - 并发清除：清除未被标记对象
  - 优点：**并发收集、低停顿**
  - 缺点：内存碎片多（标记清除算法）；并发能力依赖CPU 资源；并发清除会产生浮动垃圾
- G1 (Garbage-First) 收集器：一款面向服务器的垃圾收集器，主要针对配备多颗处理器及大容量内存的机器。**以极高概率满足 GC 停顿时间要求的同时，还具备高吞吐量性能特征。在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来)** 。（解决了 CMS 内存碎片的问题）
  - 划分为多个 Region，每个区域都可以扮演新生代，老年代，或者一个专门对大对象设计的大对象区（超过 Region 的一半即为大对象）
  - 并发标记：找出垃圾对象
  - 混合收集：计算回收价值，优先回收价值高的 Region
  - 可预测的停顿：短暂 STW，用户可以设置期望停顿时间，G1 会尽量在时间内完成垃圾收集。
- ZGC (Z Garbage Collector) 收集器：低延时，牺牲了一定的吞吐量。

垃圾回收名称及含义：

- Minor GC/ Young GC：发生在新生代的垃圾收集，包含 Eden 区和两个 Survivor 区（发生在 Eden 去没有足够空间时）
- Major GC/ Old GC：发生在老年代的垃圾收集，CMS 特有行为。
- Mixed GC：G1特有行为，在一次 GC 中同时清理新生代和老年代。
- Full GC：最彻底的垃圾清理，涉及整个堆和方法区(元空间)。
  - 触发条件：
  - Young GC 之前检查老年代：如果 Young GC 之前发现`老年代可用的连续内存空间` < `新生代历次Young GC后升入老年代的对象总和的平均大小`，本次 Young GC 后可能升入老年代的对象大小，可能超过了老年代当前可用内存空间。（可能超过，先清理）
  - Young GC 之后老年代空间不足：执行 Young GC 发现老年代没有足够空间。（实际超过）
  - 老年代空间不足：老年代内存占用率高，自动触发。
  - 空间分配担保失败：新生代 To 区放不下 Eden 和 Survivor 的拷贝对象；新生代对象需要晋升到老年代但是放不下
    - 晋升条件：长期存活对象、大对象、动态年龄判定
  - 方法区内存空间不足：永久代空间不足
  - System.gc() 命令



JVM 的内存结构：

- 程序计数器：当前线程所执行的字节码行号指示器
- 虚拟机栈：执行方法时会创建一个栈帧放入栈中（方法调用结束自动释放，不需要垃圾收集器）
- 本地方法栈：存放 native 方法
- 堆：存储对象（垃圾收集器管理区域）
- 方法区：逻辑概念，存储代码缓存。

前面三者是线程私有的，后面两者是线程共享的。

内存结构变化：

- JDK1.6 使用永久代实现方法区
- JDK1.7 时发生了一些变化，将字符串常量池存放在堆上。永久代保存类常量池、运行时常量池。
- JDK1.8 时彻底干掉了永久代，而在 **直接内存** 中划出一块区域作为**元空间**，运行时常量池、类常量池都移动到元空间。

使用元空间替代永久代：放到内存中不容易内存溢出。



对象创建过程：

1. 类加载检查：没有被加载过就执行类加载过程
2. 分配堆内存
3. 对象内存初始化，初始化零值（数值类型0，布尔类型false，对象类型null）
4. 设置对象头，对象头包含对象是哪个类的实例，对象的哈希码，对象的 GC 分代年龄等信息。
5. 执行 `<init>` 方法，赋予预期值

对象销毁过程：对象不再被任何引用指向时，就变成垃圾。垃圾收集器通过可达性分析判断对象是否存活，不可达则回收。



在堆内存分配对象时，主要使用两种策略：指针碰撞和空闲列表。

- 指针碰撞：JVM 维护一个指针，指向下一个可用地址。分配内存时，每次移动一定距离直到成功分配。（适合年轻代，碎片化不严重，标记清除和标记整理算法）
- 空闲列表：JVM 维护一个空闲列表，记录所有空闲内存块。分配内存时，遍历列表，找到足够大的空间放入。放入后的多余空间加入空闲列表。（适合老年代，碎片化严重，复制算法）



JVM 如何保证线程安全：

线程不安全：分配给A时，还没有修改指针，就会B分配内存。

解决方案：**CAS 分配重试 或者 TLAB 本地线程分配缓冲**，为每个线程分配本地缓冲区，用完本地缓冲区后分配新的才需要同步锁定。



对象的内存布局：（由 JVM 定义，不同的实现可能不同，以下是 HotSpot 实现 JVM）

- 对象头：标记字（8个字节）、类型指针（指向对象所属类，可以被压缩，压缩前4压缩后8）、数组长度（数组对象才有的字段，4字节）
- 实例数据：存储了对象的具体信息
- 对齐填充：使对象的大小总是 8 字节的倍数，在尾部的填充。



一般来说，目前的操作系统都是 64 位的，并且 JDK 8 中的压缩指针是默认开启的，因此在 64 位 JVM 上，`new Object()`的大小是 16 字节（12 字节的对象头 + 4 字节的对齐填充），对象引用 `Object referenc;` 占用的内存大小为 4 字节。



对象访问方式：

- 句柄访问：堆中划分内存作为句柄池，保存对象实例数据（在堆的实例池中）和类型数据（在方法区中）各自具体的地址信息。
  - 优势：reference 存储的是稳定的句柄地址，不担心对象回收而需要改动 reference
- 直接指针访问：reference 存储的就是对象地址（实例数据，在对中），其中还有一个指针指向类型数据。
  - 优势：访问速度快，少了一次指针定位的时间开销。（HotSpot 虚拟机中主要使用的）



- 内存溢出：分配内存时，由于没有足够的内存空间满足其需求，抛出 OutOfMemoryError
- 内存泄漏：程序使用完内存后没有释放，导致这部分内存无法使用。久而久之，导致内存溢出。
  - 通常发生在长期存活的对象持有短期存活对象的引用，而长期存活的对象又没有及时释放对短期存活对象的引用，从而导致短期存活对象无法被回收。



内存泄漏：

- 静态集合类：静态集合的生命周期和 JVM 一致，不能被释放
- 单例模式：单例对象在初始化后会以静态变量的方式在 JVM 的整个生命周期中存在。
- 连接未释放：创建的连接不再使用时，需要调用 **close** 方法关闭连接，否者 GC 无法回收。
- 变量作用域过大：一个变量的定义作用域大于其使用范围
- hash 值发生改变：无法找到存入HashMap、HashSet的对象也就无法销毁。
- ThreadLocal 使用不当：ThreadLocal 中 key 的弱引用导致内存泄漏，使用后 remove 进行清除。（key 被清除 ，value 没有被清除）



- 强引用：普通存在的引用赋值。（不会回收）
- 软引用：还有点用，但非必须的对象。（抛出 OOM 前回收，仍溢出再抛出）
- 弱引用：非必须的对象（只能生存到下一次垃圾收集发生）
- 虚引用：不影响生存时间，也无法用来获取实例。设置它只是为了能在这个对象被收集器回收时收到一个系统通知（一定被回收）

引用强度从上到下逐渐减弱



finalize() 是一次回收前的再判断。可达性分析发现没有引用链会第一次标记，然后进行一次筛选，有必要执行 finalize() 且成功在 finalize 中关联到引用链中就可以避免被回收。



STW Stop The World：垃圾回收时，暂停所有用户进程的行为。

OopMap：一个数据结构（映射表），类加载完成后，HotSpot 把对象内什么偏移量上是什么类型的数据保存其中。在 JIT 中，也会在安全点生成OopMap，记录下栈上和寄存器里哪些位置是引用。

- 安全点包括：循环末尾，方法临返回前/调用方法的 call 指令后，可能抛异常的位置
- 只有在安全点才能进行垃圾收集



对象不一定分配在堆中。编译期间，JIT 会优化代码，目的是减少内存对分配压力，其中有一种重要的技术叫做逃逸分析。

逃逸分析：分析指针动态范围的方法，它同编译器优化原理的指针分析和外形分析相关联。（通俗点说，就是对象还可能被外部调用）

逃逸分析的好处：

- 栈上分配：分配到栈上，随栈帧出栈而销毁，减少垃圾收集压力。
- 同步消除：不会逃逸就说明无法被其他线程访问，读写没有竞争，可以消除同步措施。
- 标量替换：标量是指不可拆分的基本数据类型。不会逃逸说明这个标量无法被外部访问，所以可以不创建，而直接用若干个成员变量替代，在栈上分配和读写。



### JVM 调优



常用工具：

- 操作系统工具
  - top：显示系统整体资源使用情况
  - vmstat：监控内存和 CPU
  - iostat：监控 IO 使用
  - netstat：监控网络使用
- JDK 性能监控工具
  - jps：虚拟机进程查看
  - jstat：虚拟机运行时信息查看
  - jinfo：虚拟机配置查看
  - jmap：内存映像（导出）
  - jhat：堆转储快照分析
  - jstack：Java 堆栈跟踪
  - jcmd：实现上面除了 jstat 外所有命令的功能



可视化工具：JConsole，VisualVM，Java Mission Control等等



**堆配置：**

- -Xms: 初始堆大小
- -Xmx: 最大堆大小
- -XX:NewSize=n: 设置新生代大小
- -XX:NewRatio=n: 设置老年代和新生代的比值。例如默认 n = 3 表示老年代和新生代的比值为 3:1
- -XX:SurvivorRatio=n: 年轻代中 Eden 区与一个 Survivor 区的比值。例如默认 n = 8 表示 8:1:1，一个 Survivor 区占整个年轻代的 1/10
- -XX:MaxPermSize=n: 设置持久代大小

**收集器设置：**

- -XX:+UseSerialGC:设置串行收集器
- -XX:+UseParallelGC:设置并行收集器
- -XX:+UseParalledlOldGC:设置并行年老代收集器
- -XX:+UseConcMarkSweepGC:设置并发收集器

**并行收集器设置**

- -XX:ParallelGCThreads=n:设置并行收集器收集时使用的 CPU 数。并行收集线程数
- -XX:MaxGCPauseMillis=n:设置并行收集最大的暂停时间（如果到这个时间了，垃圾回收器依然没有回收完，也会停止回收）
- -XX:GCTimeRatio=n:设置垃圾回收时间占程序运行时间的百分比。公式为：1/(1+n)
- -XX:+CMSIncrementalMode:设置为增量模式。适用于单 CPU 情况
- -XX:ParallelGCThreads=n:设置并发收集器年轻代手机方式为并行收集时，使用的 CPU 数。并行收集线程数

**打印 GC 回收的过程日志信息**

- -XX:+PrintGC
- -XX:+PrintGCDetails
- -XX:+PrintGCTimeStamps
- -Xloggc:filename

Boolean类型：-XX:+或者-XX:- （代表一个属性，+表示属性开启，-表示属性关闭）

k-v键值型：属性key=属性值value



JVM 调优是一个复杂的过程，主要包括对堆内存、垃圾收集器、JVM 参数等进行调整和优化。

线上 CPU 占用过高如何排查：

1. top 列出各个进程占用情况
2. top -Hp 进程 ID 列出对应进程占用情况
3. 打印进程堆栈信息：
   1. printf "%x\n" PID 把线程 ID 转换为 16 进制。
   2. jstack PID 打印出进程的所有线程信息，从打印出来的线程信息中找到上一步转换为 16 进制的线程 ID 对应的线程信息。
4. 根据堆栈信息定位具体业务逻辑，找问题。



内存飚高如果是发生在 java 进程上，一般是因为创建了大量对象所导致，持续飚高说明垃圾回收跟不上对象创建的速度，或者内存泄露导致对象无法回收。

优化 Minor GC 频繁问题：通常情况下，由于新生代空间较小，Eden 区很快被填满，就会导致频繁 Minor GC，因此可以通过增大新生代空间`-Xmn`来降低 Minor GC 的频率。

频繁 Full GC的原因：

- 大对象
- 内存泄漏
- 长生命周期的对象
- 程序 Bug
- 显示调用了 gc 方法
- JVM 参数设置



### 虚拟机执行



- 解释：将源代码 **逐行** 转换为机器码。
- 编译：将源代码 **一次性** 转换为机器码。



Java 一般被称为“解释型语言”，因为 Java 代码在执行前，需要先将源代码编译成字节码，然后在运行时，再由 JVM 的解释器“逐行”将字节码转换为机器码，然后执行。

JIT 会将热点代码放入 CodeCache，保存机器码。下次就可以直接执行了。



类加载机制：JVM 把 Class 文件中描述类的数据结构加载到内存中，并对数据进行校验、解析和初始化，最终形成可以被 JVM 直接使用的类型。

- 类加载器：加载类文件，将类文件加载到内存中，生成 Class 对象。
  - 启动类加载器：加载 Java 的核心类库
  - 拓展类加载器：加载 Java 的标准扩展库
  - 应用程序加载器：加载系统类路径和用户定义的类路径下的类库，我们编写的任何类都是由应用程序类加载器加载的，除非显式使用自定义类加载器。
  - 用户自定义加载器：加载网络上的类、执行热部署或为了安全目的自定义的加载方式。
- 类加载过程：加载、验证、准备、解析和初始化
  - 加载：获取字节码
  - 链接：转换字节码
    - 验证：验证字节码
    - 准备：赋默认值
    - 解析：将类的符号引用解析为直接引用
  - 初始化：赋予期望值
- 双亲委派模型：依次递归父类加载器，直到最顶层。如果父类加载器无法完成，子类加载器才会尝试去自己加载。
  - 好处：避免重复加载，保证安全性和一致性。
  - 不想打破双亲委派模型：重写 findClass() 方法，无法被父类加载器加载的类会通过这个方法加载
  - 想打破双亲委派模型：重写 loadClass() 方法



类的生命周期：加载 --> 验证 --> 准备 --> 解析 --> 初始化 --> 使用 --> 卸载

验证、准备、解析三个部分统称为连接（Linking）



实现一个 **热部署**（Hot Deployment）功能通常涉及到 **类的加载和卸载机制**，使得在不重启应用程序的情况下，能够动态替换或更新应用程序的组件。

1. 使用文件监控机制（如 Java NIO 的 WatchService）来监控类文件或配置文件的变更。当监控到文件变更时，触发热部署流程。
2. 创建一个自定义类加载器，继承自`java.lang.ClassLoader`，重写`findClass()`方法，实现类的加载。



Tomcat 是主流的 Java Web 服务器之一，为了实现一些特殊的功能需求，自定义了一些类加载器。

Tomcat 破坏了**双亲委派原则**，提供隔离的机制，为每个 web 容器单独提供一个 WebAppClassLoader 加载器。每一个 WebAppClassLoader 负责加载本身的目录下的 class 文件，加载不到时再交 CommonClassLoader 加载，这和双亲委派刚好相反。



## Redis



### 基础



Redis (Remote Dictionary Service) ，是一种基于键值对（key-value）的 NoSQL 数据库。

Redis 中的 value 支持 string（字符串）、hash（哈希）、 list（列表）、set（集合）、zset（有序集合）、Bitmaps（位图）、 HyperLogLog（基数估算）、GEO（地理信息定位）等多种数据结构。



- Redis：数据存储在 **内存** 中的 NoSQL 数据库，读写性能非常好，是互联网技术领域中使用最广泛的缓存中间件。
- MySQL：数据存储在 **硬盘 **中的关系型数据库，适用于需要事务支持和复杂查询的场景。



Redis 的应用：

- 缓存：最常见的用途，提高响应速度和吞吐量。
- 计数器：Redis 的原子递增操作可以实现计数器。
- 排行榜： ZSet 非常适合用来实现排行榜.
- 分布式锁：Redisson

五种基本类型：（key 都是字符串，value 有如下类型）

- String：字符串、数字、二进制。
  - key：`user_id:1:name` --> value：`jim` 
- Hash：Map 集合
  - key：`user_id:1` --> value：`{name:'jim', age:18}`
- list：有序的字符串列表
- set：唯一无序
- Zset：有序唯一，还多了一个排序属性 score



Redis 为什么快：

- 基于内存的数据存储
- 单线程模型
- IO 多路复用：监听，到达就处理。
- 高效的数据结构

Redis6.0 的多线程是用多线程来处理数据的**读写和协议解析**，但是 Redis**执行命令**还是单线程的。

Redis 的性能瓶颈在于⽹络 IO ⽽⾮ CPU，使⽤多线程能提升 IO 读写的效率，从⽽整体提⾼ Redis 的性能。

一个普通服务器的 Redis 实例通常可以达到每秒数万到几十万的 QPS



### 持久化



RDB 持久化 、 AOF 持久化、混合持久化。

- RDB 持久化：创建快照
  - 触发条件
    - save 命令：保存所有数据，会阻塞。
    - bgsave 命令：异步创建快照。
    - 自动触发：
      - 配置文件设置，`save 900 1` 表示如果至少有一个键被修改，900s后触发。
      - 通过 SHUTDOWN 正常关闭 Redis；
      - 主从节点建立连接时，主节点自动触发，生成 RDB 文件，然后发送给从节点。
  - 优缺点：恢复大数据集的速度比较快，但是可能会丢失最后一次快照以后的数据。
- AOF 持久化：追加写命令到 AOF 文件中
  - 工作流程操作：命令写入 （append）、文件同步（fsync）、文件重写（rewrite）、重启加载 （load）
    - 命令写入：写命令（比如 SET, LPUSH, SADD 等修改数据的命令）追加到 AOF 缓冲区（buffer）的末尾
    - 文件同步：持久化到磁盘的 AOF 文件
      - always：每次写命令都会同步
      - everysec(默认)：每秒同步一次
      - no：只会在AOF 关闭或 Redis 关闭时执行
    - 文件重写：AOF 文件会逐渐增大，所以需要重写。
      - 重写过程：将当前数据库状态转化成一系列写命令保存到新的 AOF 文件中（去重），不会解析原始文件。
      - 重写操作由 bgrewriteaof 完成，创建子线程执行，不会阻塞。
      - 重写过程中，新的写命令追加到 旧的 AOF 文件以及缓冲区中。重写完成后，缓冲区命令追加到新的 AOF 文件中，然后切换到新的 AOF 文件。
    - 重启加载：读取 AOF 文件中的所有命令并重新执行，恢复数据库。
  - 优缺点：数据的完整性比较高，但是对于大数据集，AOF 文件可能会比较大，恢复的速度比较慢。

- **混合持久化：**在 AOF 重写的时候同时生成一份 RDB 快照，然后将这份快照作为 AOF 文件的一部分，最后再附加新的写入命令。前半部分是 RDB ，后半部分是 AOF 。恢复数据的时候先加载 RDB 然后通过 AOF 记录的命令恢复。



恢复过程：把 RDB 或者 AOF 文件拷贝到 Redis 的数据目录下，如果使用 AOF 恢复，配置文件开启 AOF，然后启动 redis-server 即可。

Redis 启动时：如果 AOF 持久化开启并且存在 AOF 文件时，加载 AOF，否则加载 RDB。加载成功后，启动成功。文件如果存在问题，启动失败并打印错误信息。 



### 高可用



可以通过主从复制、哨兵模式和集群模式来实现高可用。

- 主从复制：实现读写分离。
  - Redis 主从复制支持 **主从同步** 和 **从从同步** 两种。
  - 作用：数据冗余（热备份）、故障恢复（主挂从上）、负载均衡（主写从读）、高可用基石（后两者的基础）
  - 拓扑结构：一主一从、一主多从、树状主从结构
  - 同步过程包括：全量复制和部分复制
    - 全量复制：一般是初次复制场景
    - 部分复制：复制时网络中断，补发数据通过部分复制。
- 哨兵模式：监控主节点和从节点的状态，保证系统的可用性。
  - 通过哨兵节点完成对数据节点的监控、下线、故障转移。
  - 三个定时监控：主从信息获取，哨兵信息发布，节点心跳检测（向主从节点以及其他哨兵发送）
  - 主观下线和客观下线
    - 主观下线：哨兵节点认为某个节点有问题。（心跳检测没有回应）
    - 客观下线：超过一定数量 quorum 的哨兵节点认为主节点有问题。（ quorum 的值建议设置为哨兵个数的二分之一加 1）
  - 领导者选举：每个哨兵发送命令给其余哨兵，其余哨兵如果是第一次收到该命令则同意，否则拒绝。如果每个哨兵获得的同意数大于等于 max(quorum, num(sentinels) / 2 + 1) 则成为Leader。如果没有哨兵满足则进行下一轮选举。
  - 领导者实现故障转移：选择节点成为主节点；向其余节点发送命令，使其成为新主节点的从节点；监视老主节点，上下后通知其成为新主节点的从节点。
    - 选择主节点的参考依据：响应时间短、从节点优先级高、复制偏移量大（越大越完整）、runid 小
- 集群模式：通过分片存储数据，解决高可用和分布式问题。（哈希映射）
  - 数据分区：增加容量。每个主节点都可以读写，提高响应速度。
    - 节点取余分区：节点哈希取余。缺点是扩容或者缩容时，需要重新映射。
    - 一致性哈希分区：将哈希值空间组织成一个环，数据项和节点都映射到这个环上。数据项由其哈希值直接映射到环上，然后顺时针分配到遇到的第一个节点。优点是加入和删除节点只影响后一个节点。缺点是如果节点分布不均匀，会导致部分节点压力过大，以及当节点故障时，压力都打到后一个节点。
    - 虚拟槽分区：每个键通过哈希算法映射到槽上，**每个集群节点负责一定范围的槽**。槽的个数是2 的 14 次方，和 HashMap 中数组长度是 2 的幂次方一样，能够保证扩容后，大部分数据停留在扩容前的位置，少部分需要迁移。
  - 高可用：支持主从复制和主节点的自动故障转移（与哨兵类似）



### 缓存设计



缓存穿透、缓存击穿和缓存雪崩

- 缓存穿透：查询数据库也不存在的数据
  - 解决方案：
    - 非法请求限制
    - 缓存空值：数据库不命中后即在数据库中缓存空值
      - 消耗内存，通过设置较短过期时间。
      - 数据不一致，过期时间内数据库新增该数据。得通过消息队列或者其他异步方式清理缓存空值。
    - 布隆过滤器：布隆过滤器没有的，数据库一定没有
- 缓存击穿：某个热点数据缓存过期，大量请求打到数据库（可以认为是缓存雪崩的子集）
  - 解决方案：
    - 加锁更新：查询数据库时加锁，防止并发查询，查到后写入数据库。
    - 异步刷新过期时间
- 缓存雪崩：缓存数据大量过期或者宕机，大量请求打到数据库。
  - 过期解决方案：
    - 设置不同过期时间
    - 加锁更新
    - 异步刷新过期时间
  - 宕机解决方案：
    - 集群部署
    - 限流和降级



布隆过滤器（Bloom Filter）是一种空间效率极高的概率型数据结构，用于快速检查一个元素是否存在于一个集合中。

布隆过滤器由一个长度为 m 的位数组和 k 个哈希函数组成。

添加元素时，k 个哈希计算 k 个位置，将对应位置设置为 1。

布隆过滤器判断存在不一定真的存在，判断不存在一定不存在。



缓存和数据库一致性如何保证：先更新数据库，再删除缓存。（还是有一小段时间数据不一致）

两者都更新的话很容易数据不一致。如果先删除在更新，可能会产生脏数据。即缓存删除成功，读取数据写入缓存，数据库删除成功。（更新数据库的速度比删除缓存的速度要慢得多。）

一致性要求高的解决方案：

- 引入消息队列保证最终一致性（代码侵入性）
- 数据库订阅 + 消息队列（降低代码侵入性）
- 延迟双删（延时时间需要仔细考量和测试）
- 设置缓存过期时间兜底

保证本地缓存 Caffeine 和分布式缓存 Redis 的一致：

- 本地缓存过期时间：过期了从分布式缓存中获取
- 使用 Redis 的 Pub/Sub 机制，Redis 缓存变化时，发布消息。本地缓存订阅这个消息。
- 引入消息队列，更新 Redis 的缓存变化到本地缓存。



热 key：短时间内被频繁访问的键。

监控热 key：记录 key 和 调用次数。包括客户端，代理端和 Redis 服务端。Redis 可以通过 monitor 和 bigkeys 来分析。

处理热 key：

- 把热 key 打散到不同的服务器，降低压⼒。
- 加入二级缓存，加载到 JVM 中，后续直接 JVM 读取。



缓存预热：提前把数据库里的数据刷到缓存里。



热 key 重建：

- 互斥锁：只允许一个线程重建缓存
- 永不过期：不设置过期时间 + 定时构建缓存（服务器宕机）



无底洞问题：增加缓存服务器并不能提升性能。

因为批量数据需要从不同节点获取，分布式系统需要多次 网络IO。

解决方案：

- 命令本身的优化，减少批量操作。
- 减少网络通信次数
- 降低接入成本，长连接/连接池/NIO (New IO 多路非阻塞 IO)等



### Redis 运维



内存不足：修改配置文件、通过命令动态设置内存上限、修改内存淘汰策略、使用集群模式横向扩容

过期数据回收策略：

- 惰性删除：访问的时候发现过期才删除
- 定期删除：每个一段时间随机测试一批 key，删除过期 key。（过期占比大，继续随机测试）

Redis 阻塞排查：

- API 或数据结构使用不合理：慢查询、大对象
- CPU 饱和问题：并发极限、命令内存
- 持久化相关阻塞：fork阻塞、AOF刷盘阻塞、HugePage 写操作阻塞



大 key：存储了大量数据的键

找到大 key：bigkeys 命令，redis-rdb-tools

如何处理：删除大 key；压缩和拆分 key。



### Redis 应用



使用 Redis 实现异步队列：

- 使用 list 作为队列，lpush 生产消息，rpop 死循环来消费消息（消耗 CPU）
- 使用 list 作为队列，lpush 生产消息，brpop 消费消息（brpop 是 rpop 的阻塞版本，list 有值才消费，只能实现一对一队列）
- 使用 Redis 的 pub/sub 来进行消息的发布/订阅（不可靠的，不保证订阅者一定能够收到）

使用 Redis 实现延时队列：

- 使用 Zset 来实现

  - 任务添加到 Zset，score 保存任务执行的时间戳，value 为任务内容
  - 定期获取 score 小于当前时间戳的任务执行
  - 执行完后删除

  

Redis 支持简单的事务，可以将多个命令打包，然后一次性的，按照顺序执行。（不支持回滚）

主要通过 multi、exec、discard、watch 等命令来实现：

- multi 命令开始一个事务，之后的命令被保存到队列中。
- exec 命令触发事务的执行。原子执行队列中的任务。
- discard 可以取消事务，清空队列。
- watch 监视一个或多个键，当 multi 后 exec 前，被监视的键发生改变，则取消事务，返回错误。



Redis 提供三种将客户端多条命令打包发送给服务端执行的方式：

- Pipelining(管道)：最简单。优点：节省了RTT，减少了上下文切换。
- Transactions(事务) 
- Lua Scripts(Lua 脚本) ：lua 脚本原子执行，可以定制命令，打包命令减少网络开销。



Redis 实现分布式锁：

- V1 setnx：当获取锁后没有 del 就出现异常，即出现死锁。
- V2 锁超时释放：给锁加过期时间 expire 命令。（两条命令不是原子执行，也可能出现死锁）
- V3 set ：`set key value ex 5 nx` 过期时间ex 为 5s，nx 保证 key 值不存在才能 set 成功。

专业轮子： Redisson



### 底层结构



底层数据结构看 小林 coding



SDS 对比 C语言字符串 的优势：

- **多增加 len 表示当前字符串的长度**：这样就可以直接获取长度了，复杂度 O(1)；
- **自动扩展空间**：当 SDS 需要对字符串进行修改时，首先借助于 `len` 和 `alloc` 检查空间是否满足修改所需的要求，如果空间不够的话，SDS 会自动扩展空间，避免了像 C 字符串操作中的溢出情况；
- **有效降低内存分配次数**：C 字符串在涉及增加或者清除操作时会改变底层数组的大小造成重新分配，SDS 使用了 **空间预分配** 和 **惰性空间释放** 机制，简单理解就是每次在扩展时是成倍的多分配的，在缩容是也是先留着并不正式归还给 OS；
- **二进制安全**：C 语言字符串只能保存 `ascii` 码，对于图片、音频等信息无法保存，SDS 是二进制安全的，写入什么读取就是什么，不做任何过滤和限制；



使用 `keys` 指令可以扫出指定模式的 key 列表，但会导致线程阻塞。

`scan` 指令可以无阻塞的提取出指定模式的 `key` 列表，但是可能重复（客户端去重）且花费时间更长。



秒杀场景中，关键要 **错峰削峰** 和 **限流**。

- 错峰削峰：缓存预热，消息队列，多阶段多时间窗口，插入答题系统
- 限流：令牌桶算法，维护一个容器，按照固定的速率往容器中放令牌（token），当请求到来时，从容器中取出一个令牌，如果容器中没有令牌，则拒绝请求。






## Spring



### 基础



**Spring 是一个轻量级、非入侵式的控制反转 (IoC) 和面向切面 (AOP) 的框架。**

企业级开发的标配基本就是 **Spring 5** + **Spring Boot 2** + **JDK 8**

IoC 的核心思想是将对象的创建和管理交给外部容器来完成，而不是在应用程序中直接创建对象。

AOP 的核心概念是将程序的横切关注点（cross-cutting concerns）与主要业务逻辑分离开来，使得这些关注点可以独立地被定义、管理和重用。



**Spring 的特性：**

1. **IoC** 和 **DI** 的支持：可以维护所有对象的创建和依赖关系，实现**高内聚低耦合**的设计理念。

2. AOP 编程的支持：可以方便的实现对程序进行权限拦截、运行监控等切面功能。

3. 声明式事务的支持：支持通过配置就来完成对事务的管理，而不需要通过硬编码的方式。

4. 快捷测试的支持：Junit 提供支持，可以通过**注解**快捷地测试 Spring 程序。

5. 快速集成功能：方便集成各种优秀框架（Mybatis、Quartz等）

6. 复杂 API 模板封装：封装 API 的提供使得应用难度大大降低（JDBC、JavaMail、远程调用等）



Spring 框架是分模块存在，除了最核心的`Spring Core Container`是必要模块之外，其他模块都是 可选，大约有 20 多个模块。

**Spring Core**：Spring 核心，它是框架最基础的部分，提供 IoC 和依赖注入 DI 特性。



**Spring 常用的注解：**

- Web

  1. `@Controller`：用于标注控制层组件。

  2. `@RestController`：是`@Controller` 和 `@ResponseBody` 的结合体，返回 JSON 数据时使用。

  3. `@RequestMapping`：用于映射请求 URL 到具体的方法上，还可以细分为：
     - `@GetMapping`：只能用于处理 GET 请求（查）
     - `@PostMapping`：只能用于处理 POST 请求（增）
     - `@DeleteMapping`：只能用于处理 DELETE 请求（删）

  4. `@ResponseBody`：直接将返回的数据放入 HTTP 响应正文中，一般用于返回 JSON 数据

  5. `@RequestBody`：表示一个方法参数应该绑定到 Web 请求体。

  6. `@PathVariable`：用于接收路径参数，比如 `@RequestMapping(“/hello/{name}”)`，这里的 name 就是路径参数。

  7. `@RequestParam`：用于接收请求参数。比如 `@RequestParam(name = "key") String key`，这里的 key 就是请求参数。

- 容器

  1. `@Component`：标识一个类为 Spring 组件，使其能够被 Spring 容器自动扫描和管理。

  2. `@Service`：标识一个业务逻辑组件（服务层）。比如 `@Service("userService")`，这里的 userService 就是 Bean 的名称。

  3. `@Repository`：标识一个数据访问组件（持久层）。

  4. `@Autowired`：按类型自动注入依赖。

  5. `@Configuration`：用于定义配置类，可替换 XML 配置文件。

  6. `@Value`：用于将 Spring Boot 中 application.properties 配置的属性值赋值给变量。

- AOP

  1. `@Aspect` 用于声明一个切面，可以配合其他注解一起使用，比如：

  2. `@After`：在方法执行之后执行。

  3. `@Before`：在方法执行之前执行。

  4. `@Around`：方法前后均执行。

  5. `@PointCut`：定义切点，指定需要拦截的方法。

- 事务
  1.   `@Transactional`，用于声明一个方法需要事务支持。



Spring中用到的设计模式：

1. 工厂模式：IoC容器可以看做一个巨大的工厂
2. 代理模式：AOP的实现就是基于代理模式的
3. 单例模式：容器中的 bean 默认都是单例的
4. 模板模式：JdbcTemplate，HibernateTemplate 等使用了模板方法模式
5. 观察者模式：事件驱动模型就是观察者模式经典的应用
6. 适配器模式：Spring MVC 中的 HandlerAdaper 使用了适配器模式
7. 策略模式：Resource 接口，它的不同实现类，会根据不同的策略去访问资源



### IoC



**IoC（控制反转，Inversion of Control）**，就是由容器来控制对象的生命周期和对象之间的关系。以前是我们想要什么就自己创建什么，现在是我们需要什么容器就帮我们送来什么。

**DI（依赖注入 ，Dependency Injection）**，控制反转这个词太宽泛，并不能很好地解释这个框架的具体实现。

IoC 降低了对象之间的耦合度，使得程序更加灵活，更加易于维护。



Spring IoC 的实现机制：

- 订单（Bean 定义）：注册、定义；获取、单例
- 工厂（Spring 容器）：资源加载、实例创建、单例、实例缓存
- 仓库（HashMap）



BeanFactory 是 Spring 的“心脏”，ApplicantContext 是完整的“身躯”。

- BeanFactory（Bean 工厂）是 Spring 框架的基础设施，面向 Spring 本身。（手动挡）
  - BeanFactory 采用的是延迟初始化的方式
- ApplicantContext（应用上下文）建立在 BeanFactoty 基础上，面向使用 Spring 框架的开发者。（自动挡）
  - ApplicationContext 会在启动时预先创建并初始化所有的 Bean



Spring 的 IoC 容器工作的过程，其实可以划分为两个阶段：**容器启动阶段**和**Bean 实例化阶段**。

- **容器启动阶段**：主要做的工作是加载和解析配置文件，保存到对应的 Bean 定义中。
- **4 种方法实例化 Bean**：
  - 构造方法的方式：类上使用注解，通过构造方法注入依赖
  - 静态工厂的方式：静态方法创建
  - 实例工厂的方式：依赖于某个类的实例来创建 Bean
  - FactoryBean 接口实例化的方式：通过实现 FactoryBean 接口，可以自定义实例化逻辑，这对于构建复杂的初始化逻辑非常有用。



Spring Bean 的生命周期：

**实例化**（Instantiation）、**属性赋值**（Populate）、**初始化**（Initialization）、**销毁**（Destruction）



Bean 依赖配置的方式有三种：**直接编码方式**、**配置文件方式**、**注解方式**。



Spring 支持**构造方法注入**、**属性注入**、**工厂方法注入**,其中工厂方法注入，又可以分为**静态工厂方法注入**和**非静态工厂方法注入**。



Spring 的 **自动装配** 是指 Spring 容器根据一定的规则自动地将 Bean 之间的依赖关系进行注入。

Spring 提供了 4 种自动装配类型：byType, byName, constructor, autodetect



Spring 的 Bean 主要支持五种作用域：

- singleton：容器进存在一个 Bean 实例（默认作用域）
- prototype：每次从容器重调用 Bean 时，都会返回一个新的实例。
- 以下三个作用域只在 Web 应用中适用：
  - request：每次 HTTP 请求都会产生一个新的 Bean，仅在当前请求内有效。
  - session：同一个 HTTP Session 共享一个 Bean
  - gobalSession：同一个全局 Session 共享一个 Bean



Spring 中的单例 Bean **不是线程安全的**。

如果单例 Bean 只进行查询，那么这个单例 Bean 是线程安全的。比如 Spring mvc 的 Controller、Service、Dao 等，这些 Bean 大多是无状态的，只关注于方法本身。

解决方法：将 Bean 中的成员变量保存在 ThreadLocal 中



**循环依赖**只发生在 Singleton 作用域的 Bean 之间。

AB 循环依赖，A 实例化的时候，发现依赖 B，创建 B 实例，创建 B 的时候发现需要 A，创建 A1 实例......

**Spring 可以解决的循环依赖：**当循环依赖的实例都采用 setter 方法注入时，Spring 支持，都采用构造器注入的时候，不支持；构造器注入和 setter 注入同时存在的时候，看命。

**解决方式：**

Singleton 的 Bean 要初始化完成，需要经历 实例化、属性复制、初始化。

注入发生在 属性赋值，Spring 可以**通过三级缓存来解决循环依赖**。

1. 一级缓存 : `Map<String,Object>` **singletonObjects**，单例池，用于保存实例化、属性赋值（注入）、初始化完成的 bean 实例
2. 二级缓存 : `Map<String,Object>` **earlySingletonObjects**，早期曝光对象，用于保存实例化完成的 bean 实例
3. 三级缓存 : `Map<String,ObjectFactory<?>>` **singletonFactories**，早期曝光对象工厂，用于保存 bean 创建工厂，以便后面有机会创建代理对象。

例子：A、B 发生循环依赖，A 实例的初始化过程:

1. 创建 A 实例，放入三级缓存，虽然 A 还不完整，但先曝光出来让大家知道。
2. A 注入属性时，发生依赖 B，去实例化 B
3. B 注入属性时，发生依赖 A，依次从一级到三级缓存查询 A，发生三级缓存有 A，把 A 放入二级缓存，删除三级缓存的 A。B实例化完成，放入一级缓存。
4. A 属性复制，顺利从一级缓存拿到 B。A 对象创建完成，删除二级缓存的 A，放入一级缓存。
5. 一级缓存中保存着实例化和初始化都完成的 A, B 对象。

之所以 Spring 能解决 setter 注入的循环依赖，是因为其实例化和属性赋值是分开的，里面有操作的空间。如果都是构造器注入的话，那么都得在实例化这一步完成注入，没有可操作的空间。

**需要三级缓存而不只用二级** 是为了生成代理对象。如果是没有代理的情况下，使用二级缓存解决循环依赖也是 OK 的。但是如果存在代理，三级没有问题，二级就不行了。（代理对象通常用于在访问目标对象之前或之后执行额外的操作）

因为三级缓存中放的是⽣成具体对象的匿名内部类，获取 Object 的时候，它可以⽣成代理对象，也可以返回普通对象。使⽤三级缓存主要是为了保证不管什么时候使⽤的都是⼀个对象。

假设只有⼆级缓存的情况，往⼆级缓存中放的显示⼀个普通的 Bean 对象，Bean 初始化过程中，通过 BeanPostProcessor 去⽣成代理对象之后，覆盖掉⼆级缓存中的普通 Bean 对象，那么可能就导致取到的 Bean 对象不一致了。



实现@Autowired 的功能，也是通过后置处理器来完成的。这个后置处理器就是 AutowiredAnnotationBeanPostProcessor。



### AOP



AOP（面向切面编程，Aspect-oriented Programming），就是把一些业务逻辑中的相同代码抽取到一个独立的模块中，让业务逻辑更加清爽。

AOP 的核心是**动态代理**，可以使用 JDK 动态代理来实现，也可以使用 CGLIB 来实现。

AOP，也就是面向切面编程，是一种编程范式，旨在提高代码的模块化。比如说可以将日志记录、事务管理等分离出来，来提高代码的可重用性。



AOP 的核心概念包括切面（Aspect）、连接点（Join Point）、通知（Advice）、切点（Pointcut）和织入（Weaving）等。

① 像日志打印、事务管理等都可以抽离为切面，可以声明在类的方法上。

② 在 Spring AOP 中，连接点总是表示方法的执行。

③ Spring AOP 支持五种类型的通知：前置通知、后置通知、环绕通知、异常通知、最终通知等。

④ 在 AOP 中，切点用于指定我们想要在哪些连接点上执行通知的规则。

⑤ 织入是指将切面应用到目标对象并创建新的代理对象的过程。Spring AOP 默认在运行时通过动态代理方式实现织入。

像 `@Transactional` 注解，就是一个典型的 AOP 应用，它就是通过 AOP 来实现事务管理的。我们只需要在方法上添加 `@Transactional` 注解，Spring 就会在方法执行前后添加事务管理的逻辑。



Spring 的 AOP 是通过 动态代理来实现的，动态代理主要有两种方式：JDK 动态代理和 CGLIB 代理。

- JDK 动态代理是**基于接口**的代理方式，它使用 Java 原生的 `java.lang.reflect.Proxy` 类和 `java.lang.reflect.InvocationHandler` 接口来创建和管理代理对象。
- CGLIB（Code Generation Library）是一个第三方代码生成库，它**通过继承方式实现代理，不需要接口**，被广泛应用于 Spring AOP 中，用于提供方法拦截操作。




Spring AOP 属于运行时增强。

AspectJ AOP 属于编译时增强。



###  事务



Spring 事务的本质其实就是数据库对事务的支持，没有数据库的事务支持，Spring 是无法提供事务功能的。Spring 只提供统一事务管理接口，具体实现都是由各数据库自己实现，数据库事务的提交和回滚是通过数据库自己的事务机制实现。



事务管理可以分为两大类：声明式事务管理和编程式事务管理。

- **编程式事务管理**：需要在代码中显式调用事务管理的 API 来控制事务的边界，比较灵活，但是代码侵入性较强，不够优雅。
- **声明式事务管理**：这种方式使用 Spring 的 AOP 来声明事务，将事务管理代码从业务代码中分离出来。优点是代码简洁，易于维护。但缺点是不够灵活，只能在预定义的方法上使用事务。

Spring 推荐通过 @Transactional 注解的方式来实现声明式事务管理，也是日常开发中最常用的。

不足的地方是，声明式事务管理最细粒度只能作用到方法级别，无法像编程式事务那样可以作用到代码块级别。



SQL 标准定义了四个隔离级别，Spring 都支持，并且提供了对应的机制来配置它们，定义在 TransactionDefinition 接口中。

1. ISOLATION_DEFAULT：使用数据库默认的隔离级别，MySQL 默认的是可重复读，Oracle 默认的读已提交。

2. ISOLATION_READ_UNCOMMITTED：读未提交，允许事务读取未被其他事务提交的更改。这是隔离级别最低的设置，可能会导致“脏读”问题。

3. ISOLATION_READ_COMMITTED：读已提交，确保事务只能读取已经被其他事务提交的更改。这可以防止“脏读”，但仍然可能发生“不可重复读”和“幻读”问题。

4. ISOLATION_REPEATABLE_READ：可重复读，确保事务可以多次从一个字段中读取相同的值，即在这个事务内，其他事务无法更改这个字段，从而避免了“不可重复读”，但仍可能发生“幻读”问题。

5. ISOLATION_SERIALIZABLE：串行化，这是最高的隔离级别，它完全隔离了事务，确保事务序列化执行，以此来避免“脏读”、“不可重复读”和“幻读”问题，但性能影响也最大。



**事务的传播机制**定义了在方法被另一个事务方法调用时，这个方法的事务行为应该如何。

Spring 默认的事务传播行为是 PROPAFATION_REQUIRED，即如果多个 `ServiceX#methodX()` 都工作在事务环境下，且程序中存在这样的调用链 `Service1#method1()->Service2#method2()->Service3#method3()`，那么**这 3 个服务类的 3 个方法都通过 Spring 的事务传播机制工作在同一个事务中。**



**只有通过 Spring 容器的 AOP 代理调用的公开方法（public method）上的`@Transactional`注解才会生效**。在 protected 和 private 方法上不会生效。

Spring 的声明式事务管理是通过 AOP（面向切面编程）和代理机制实现的。

声明式事务 `@Transactional` 失效：

- 应用在非 public 修饰的方法上
- 注解属性 propagation 设置错误
- 注解属性 roolbackFor 设置错误
- 同一个类中方法调用（最常见）
  - 类 Test 下有 A, B 两个方法。A 调用了 B。A没有声明注解事务，B有。当 A 调用 B 时，B 的事务失效。
  - 由 Spring AOP 代理造成的，因为只有事务方法被当前类以外的代码调用时，才会由 Spring 生成的代理对象来管理。



### MVC



Spring MVC 是基于模型-视图-控制器的 Web 框架，它的工作流程也主要是围绕着 Model、View、Controller 这三个组件展开的。

![三分恶面渣逆袭：Spring MVC的工作流程](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/spring-e29a122b-db07-48b8-8289-7251032e87a1.png)



### Spring Boot



Spring Boot 的优点非常多，比如说：

1. 通过 Intellij IDEA 或者官方的 Spring Initializr 就可以快速创建新项目，只需要选择需要的依赖就可以五分钟内搭建一个项目骨架。
2. Spring Boot 内嵌了 Tomcat、Jetty、Undertow 等容器，不需要在服务器上部署 WAR 包了，直接运行 jar 包就可以启动项目，超级方便。
3. Spring Boot 无需再像以前一样在 web.xml、applicationContext.xml 等配置文件里配置大量的内容，大部分初始工作 Spring Boot 都帮我们做好了。例如，如果项目中添加了 spring-boot-starter-web，Spring Boot 会自动配置 Tomcat 和 Spring MVC。
4. Spring Boot 允许我们通过 yaml 来管理应用的配置，比传统的 properties 文件更加简洁。
5. Spring Boot 提供了一系列的 Starter，可以快速集成常用的框架，例如 Spring Data JPA、Spring Security、MyBatis 等。
6. Spring Boot 提供了一系列的 Actuator，可以帮助我们监控和管理应用，比如健康检查、审计、统计等。
7. 配合 Spring Cloud 可以快速构建微服务架构。



Spring MVC 是基于 Spring 框架的一个模块，提供了一种 Model-View-Controller（模型-视图-控制器）的开发模式。

Spring Boot 旨在简化 Spring 应用的配置和部署过程，提供了大量的自动配置选项，以及运行时环境的内嵌 Web 服务器（默认 Tomcat ），这样就可以更快速地开发一个 SpringMVC 的 Web 项目。



**自动装配是指容器利用反射技术，根据 Bean 的类型、名称等自动注入所需的依赖。**

开启自动装配的注解是`@EnableAutoConfiguration`。Spring Boot 为了进一步简化，直接通过 `@SpringBootApplication` 注解一步搞定，这个注解包含了 `@EnableAutoConfiguration` 注解。



**自定义一个 SpringBoot Starter：（Javabetter）**

1. 创建一个新的 Maven 项目，加入必要的依赖和配置。（spring-boot-autoconfigure 和 spring-boot-starter）
2. 创建自动配置类
3. 创建配置属性类
4. 创建简单服务类
5. 配置 spring.factories
6. 打包这个项目 `mvn clean install`
7. 在其他项目中引入这个依赖，然后注入使用。

必要性：有很多模块需要用到同一个包，最坏的做法是每个模块各自引入。



**自定义 starter 方式（尚硅谷）：**

1. 创建 `xxx-starter` 项目，引入 `spring-boot-starter` 基础依赖。

2. 编写模块功能，引入模块所有需要的依赖，编写 `xxxAutoConfiguration` 自动配置类

3. 编写配置文件，加入启动需要加载的自动配置类

   ``` bash
   # 文件名
   META-INF/Spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports
   # 在上面这个文件中加入自动配置类
   com.atguigu.boot3.starter.robot.RobotAutoConfiguration
   ```

4. 其他项目引入即可使用



三种自定义 starter 方式：

1. 创建新的项目，将公共的代码（即要抽取的业务）复制进来，然后引入必要的配置依赖。（后续步骤都需要在引用项目中导入这个 starter 的依赖）

2. 基本抽取：创建自动配置类 `AutoConfiguration`，import 导入必要内容，或者直接new出来然后 `@Bean`，只要实现把组件放入容器中即可（同时`@Configuration` ，这样别人就可以跨包导入了），然后在 **引用的项目中 import 自动配置类**。（ SpringBoot 的默认扫描规则，只扫描自己主程序所在的包以及子包，所以需要 import 自动配置类）`@Import(RobotAutoConfiguratin.class)`

3. 使用 Enable 机制：import 写到 自定义的注解 里面，然后 **引用的项目就可以直接加上自定义注解** 即可。

4. 完全自动配置： 依赖 SpringBoot 的 SPI 机制。在下面这个文件中加入自动配置类即可

   ```bash
   META-INF/Spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports
   ```

   









Spring Boot 应用通常有一个带有 main 方法的主类，这个类上标注了 `@SpringBootApplication` 注解，它是整个应用启动的入口。这个注解组合了 `@SpringBootConfiguration`、`@EnableAutoConfiguration` 和 `@ComponentScan`，这些注解共同支持配置和类路径扫描。

`SpringApplication.run()` 方法负责准备和启动 Spring 应用上下文（ApplicationContext）环境，包括：

- 扫描配置文件，添加依赖项
- 初始化和加载 Bean 定义
- 启动内嵌的 Web 服务器



`@SpringBootApplication` 是 Spring Boot 的核心注解，经常用于主类上，作为项目启动入口的标识。它是一个组合注解：

- `@SpringBootConfiguration`：继承自 `@Configuration`，标注该类是一个配置类，相当于一个 Spring 配置文件。
- `@EnableAutoConfiguration`：告诉 Spring Boot 根据 pom.xml 中添加的依赖自动配置项目。例如，如果 spring-boot-starter-web 依赖被添加到项目中，Spring Boot 会自动配置 Tomcat 和 Spring MVC。
- `@ComponentScan`：扫描当前包及其子包下被`@Component`、`@Service`、`@Controller`、`@Repository` 注解标记的类，并注册为 Spring Bean。



Spring Boot 在启动时能够找到主类上的`@SpringBootApplication`注解，是因为它利用了 Java 的反射机制和类加载机制，结合 Spring 框架内部的一系列处理流程。

当运行一个 Spring Boot 程序时，通常会调用主类中的`main`方法，这个方法会执行`SpringApplication.run()`，比如：

```java
@SpringBootApplication
public class MyApplication {
    public static void main(String[] args) {
        SpringApplication.run(MyApplication.class, args);
    }
}
```

`SpringApplication.run(Class<?> primarySource, String... args)`方法接收两个参数：第一个是主应用类（即包含`main`方法的类），第二个是命令行参数。`primarySource`参数提供了一个起点，Spring Boot 通过它来加载应用上下文。

Spring Boot 利用 Java 反射机制来读取传递给`run`方法的类（`MyApplication.class`）。它会检查这个类上的注解，包括`@SpringBootApplication`



Spring Boot 的默认包扫描路径是以启动类 `@SpringBootApplication` 注解所在的包为根目录的，即默认情况下，Spring Boot 会扫描启动类所在包及其子包下的所有组件。

如果需要自定义包扫描路径，可以在`@SpringBootApplication`注解上添加`@ComponentScan`注解，指定要扫描的包路径。



### Spring Cloud



微服务化的核心就是将传统的一站式应用，根据业务拆分成一个一个的服务，彻底地去耦合，每一个微服务提供单个业务功能的服务，一个服务做一件事情，从技术角度看就是一种小而独立的处理过程，类似进程的概念，能够自行单独启动或销毁，拥有自己独立的数据库。



**主流微服务框架**：Spring Cloud Netflix；Spring Cloud Alibaba；SpringBoot + Dubbo + ZooKeeper





### SpringTask

SpringTask 是 Spring 框架提供的一个轻量级的任务调度框架，它允许我们开发者通过简单的注解来配置和管理定时任务。

- `@Scheduled`：最常用的注解，用于标记方法为计划任务的执行点。支持 corn 表达式。
- `@EnableScheduling`：用于开启定时任务的支持。





## MyBatis

短链接用的是 Mybatis-Plus

以后再看吧



### 基础



Mybatis 是一个半 ORM（对象关系映射）框架，它内部封装了 JDBC，开发时只需要关注 SQL 语句本身，不需要花费精力去处理加载驱动、创建连接、创建 statement 等繁杂的过程。程序员直接编写原生态 sql，可以严格控制 sql 执行性能，灵活度高。

ORM (Object Relational Mapping) 对象关系映射 是一种为了解决关系型数据库数据与简单 Java 对象（POJO）的映射关系的技术。因为需要手动编写 SQL，所以被称为半自动 ORM 映射工具。



JDBC 的不足：

- 数据库连接创建和释放消耗系统性能。（mybatis-config.xml 中配置数据链接池，使用连接池统一管理数据库连接）
- SQL 语句写在代码中不易维护（sql 语句配置在 XXXXmapper.xml 文件中与 java 代码分离）
- 向 SQL 语句传参麻烦（Mybatis 自动将 java 对象映射至 sql 语句）
- 对结果集解析麻烦（Mybatis 自动将 sql 执行结果映射至 java 对象）



MyBatis 基本使用的过程：

1. 创建 SqlSessionFactory
2. 通过 SqlSessionFactory 创建 SqlSession
3. 通过 sqlsession 执行数据库操作
4. 调用 session.commit()提交事务
5. 调用 session.close()关闭会话

 

mapper 中如何传递多个参数：

- 顺序传参法（不直观，不建议使用）
- @Param 注解传参法（推荐使用）
- Map 传参法（适合传递多个参数，且参数易变能灵活传递的情况）
- Java Bean 传参法（需要建立实体类，推荐使用）



实体属性名和表中字段名不一样怎么办？

-  SQL 语句中定义字段名的别名
-  resultMap 中的\<result>来映射



- 当使用 `#{}` 时，MyBatis 会在 SQL 执行之前，将占位符替换为问号 `?`，并使用参数值来替代这些问号。
- 当使用 `${}` 时，参数的值会直接替换到 SQL 语句中去，而不会经过预处理。





## MySQL



### 基础

MySQL，它是一个开源的关系型数据库管理系统。（Redis 是非关系型数据库）

关系型一般以表记录信息，非关系型一般以集合，键值对记录信息。



- 内连接：两张表中匹配关系的记录（交集）
- 外连接：两张表中匹配关系的记录 + 某张表的其余记录
  - 左连接：匹配关系的记录，左表的其余记录，右表部分 null 填充
  - 右连接：匹配关系的记录，右表的其余记录，左表部分 null 填充（比较别扭，可以通过左连接实现）
  - 全外连接：匹配关系的记录，两表的其余记录，另一个表部分用 null 填充
- 交叉连接：没有匹配关系进行筛选。笛卡尔积在 SQL 的实现（两行表各有 m, n 行数据，则返回 m* n 行记录）



**数据库三大范式：**

- 第一范式：每一列都是不可分割的基本数据单元
- 第二范式：每一列都和主键直接相关，不能是部分相关（主要针对联合主键）
- 第三范式：非主键列 **只依赖于主键列，不依赖于其他非主键列**

实际开发过程中，三大范式反而可能让表的设计变的复杂，同时降低查询效率（需要多表连接），所以需要实际考量。



- char：定长，不足部分空格填充，存取速度快，最多存放 255 个字符。2^8 - 1

- varchar：变长，是多长存多长，存取速度慢，最多存放 65532 个字符。2^16 - 1(null) - 2(变长) （utf8 还需要 /3，如果是多字段，比如两个 varchar，那两个的总和小于等于 65535 - 2 - 1 - 2 - 1.



- blob：存储二进制，没有字符集
- text：存储大字符串，有一个字符集，可以排序和比较



DATETIME 和 TIMESTAMP：

相同点：表现形式都是 `YYYY-MM-DD HH:MM:SS` ；都包含日期和时间；都可以存微秒

不同点：日期范围，前者大；存储空间，前者 8 字节，后者 4 字节；时区相关，前者无关，后者有关；默认值，前者null，后者当前时间。



in 语句是把外表和内表作 hash 连接，而 exists 语句是对外表作 loop 循环，每次 loop 循环再对内表进行查询。

子查询表大的用 exists，子查询表小的用 in



货币在数据库中 MySQL 常用 Decimal 和 Numric 类型表示，这两种类型被 MySQL 实现为同样的类型。DECIMAL 和 NUMERIC 值作为**字符串存储**，而不是作为二进制浮点数，以便保存那些值的小数精度。



- utf8mb3：3 个字节的 UTF-8 编码。

- utf8mb4：4 个字节的 UTF-8 编码，支持 emoji 4 字节。

mb 是 multi-byte 的缩写



在不再需要一张表的时候，用 drop；在想删除部分数据行时候，用 delete；在保留表而删除所有数据的时候用 truncate。

- DML，数据操纵语言。insert、delete、update、select等。

- DDL，数据定义语言。Create、Alter、Drop、truncate等。



`UNION` 和 `UNION ALL` 是 MySQL 中用于合并查询结果的两种方法，它们的区别在于 `UNION` 会去除重复的行，而 `UNION ALL` 则会保留所有行，不进行去重。



按照性能排序：count(*) = count(1) > count(主键字段) > count(字段) 

count() 是**统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个**。

count(1)、 count(*)、 count(主键字段)在执行的时候，如果表里存在二级索引，优化器就会选择二级索引进行扫描。所以尽量在数据表上建立二级索引，这样优化器会自动采用 key_len 最小的二级索引进行扫描，相比于扫描主键索引效率会高一些。同时要避免使用 count(普通字段)



执行顺序：FROM, ON, JOIN, WHERE, GROUP BY, CUBE/ROLLUP, HAVING, SELECT, DISTINCT, ORDER BY, LIMIT



常见操作指令：

- 数据库：

``` sql
CREATE DATABASE database_name;
DROP DATABASE database_name;
USE database_name;
```

- 表操作：

``` sql
CREATE TABLE table_name (
    column1 datatype,
    column2 datatype,
    ...
);
DROP TABLE table_name;
SHOW TABLES;
DESCRIBE table_name;
ALTER TABLE table_name ADD column_name datatype;
-- CRUD
INSERT INTO table_name (column1, column2, ...) VALUES (value1, value2, ...);
SELECT column_names FROM table_name WHERE condition;
UPDATE table_name SET column1 = value1, column2 = value2 WHERE condition;
DELETE FROM table_name WHERE condition;
-- 索引和约束的创建修改
CREATE INDEX index_name ON table_name (column_name);
ALTER TABLE table_name ADD PRIMARY KEY (column_name);
ALTER TABLE table_name ADD CONSTRAINT fk_name FOREIGN KEY (column_name) REFERENCES parent_table (parent_column_name);
```

- 用户和权限管理

``` sql
CREATE USER 'username'@'host' IDENTIFIED BY 'password';
GRANT ALL PRIVILEGES ON database_name.table_name TO 'username'@'host';
REVOKE ALL PRIVILEGES ON database_name.table_name FROM 'username'@'host';
DROP USER 'username'@'host';
```

- 事务控制

``` sql
START TRANSACTION;
COMMIT;
ROLLBACK;
```



常用的函数：

- 字符串函数（一般就用单引号）

  - `CONCAT('x', 'x')`: 连接两个或多个字符串，逗号分隔。

  - `LENGTH('x')`: 返回字符串的长度。

  - `SUBSTRING('x', 1,2)`: 从字符串中提取子字符串。索引从 1 开始，两边都包含。

  - `REPLACE('xxy','x','y')`: 替换字符串中的某部分。

  - `LOWER('X')` 和 `UPPER('x')`: 分别将字符串转换为小写或大写。

  - `TRIM(' x ')`: 去除字符串两侧的空格或其他指定字符。

- 数值函数

  - `ABS(-1)`: 返回一个数的绝对值。
  - `CEILING(12.3)`: 返回大于或等于给定数值的最小整数，向上取整。
  - `FLOOR(12.3)`: 返回小于或等于给定数值的最大整数，向下取整。
  - `ROUND(12.23, 1)`: 四舍五入到指定的小数位数。
  - `MOD(10, 3)`: 返回除法操作的余数。

- 日期和时间函数

  - `NOW()`: 返回当前的日期和时间。
  - `CURDATE()`: 返回当前的日期。
  - `CURTIME()`: 返回当前的时间。
  - `DATE_ADD(CURDATE(), INTERVAL 10 DAY)` 和 `DATE_SUB()`: 在日期上加上或减去指定的时间间隔。
  - `DATEDIFF('2024-12-31', '2024-01-01')`: 返回两个日期之间的天数。
  - `DAY(CURDATE())`, `MONTH()`, `YEAR()`: 分别返回日期的日、月、年部分。

- 汇总函数

  - `SUM()`: 计算数值列的总和。
  - `AVG()`: 计算数值列的平均值。
  - `COUNT()`: 计算某列的行数。
  - `MAX()` 和 `MIN()`: 分别返回列中的最大值和最小值。
  - `GROUP_CONCAT()`: 将多个行值连接为一个字符串。

- 格式化函数

  - `FORMAT(1234567.8945, 2)`: 格式化数字为格式化的字符串，通常用于货币显示。保留 2 位小数

- 类型转换函数

  - `CAST('2024-01-01' AS DATE)`: 将一个值转换为指定的数据类型。
  - `CONVERT('123', SIGNED INTEGER)`: 类似于`CAST()`，用于类型转换。

当不同数据类型的值进行运算或比较时，会发生隐式数据类型转换。

数据类型隐式转换会导致意想不到的结果，所以要尽量避免隐式转换，使用类型转换函数进行显式转换。



要查询第 3 到第 10 条记录，可以通过 offset 偏移量 + limit 行数 （偏移量从0开始）

``` sql
SELECT * FROM table_name LIMIT 2, 8;
```



### 数据库架构



逻辑架构：

- 客户端：连接处理、授权认证
- Server 层：核心服务功能，包括查询解析、分析、优化、缓存以及所有内置函数。还包括存储过程、触发器、视图等。
- 存储引擎层：负责数据的存储和提取



SQL 查询：

1. 连接器：建立连接，管理连接、校验用户身份；
2. 查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块；
3. 解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；
4. 执行 SQL：执行 SQL 共有三个阶段：
   - 预处理阶段：检查表或字段是否存在；将 `select *` 中的 `*` 符号扩展为表上的所有列。
   - 优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；
   - 执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端；



### 存储引擎



存储引擎：

- InnoDB：支持事务、行级锁、外键（MySQL默认存储引擎）
- MyISAM：不支持事务、外键，支持表级锁
- MEMORY：存在在内存中



| 功能           | InnoDB | MyISAM | MEMORY |
| :------------- | :----- | :----- | :----- |
| 支持事务       | Yes    | No     | No     |
| 支持全文索引   | Yes    | Yes    | No     |
| 支持 B+ 树索引 | Yes    | Yes    | Yes    |
| 支持哈希索引   | Yes    | No     | Yes    |
| 支持外键       | Yes    | No     | No     |

如果在创建表时没有指定主键，且没有任何唯一性约束（如唯一索引），MySQL InnoDB 存储引擎将会自动创建一个隐藏的主键索引`GEN_CLUST_INDEX`。同时将将第一个声明为 `NOT NULL` 的列作为主键的一部分

如果在创建表时没有显式定义主键，但是有唯一性约束（如唯一索引），MySQL InnoDB 存储引擎会根据唯一索引来保证数据的唯一性。InnoDB 存储引擎会自动选择一个唯一性索引作为隐藏的主键索引`GEN_CLUST_INDEX`



### 日志



日志文件主要包括：

- 错误日志 Error Log
- 慢查询日志 Slow Query Log：记录执行时间长的 SQL 语句
- 一般查询日志 General Query Log：记录所有连接信息以及 SQL 语句
- 二进制日志 bin log：记录所有修改了数据库状态的 SQL 语句以及其执行时间
  - 用于数据恢复和主从复制
  - 默认不开启，开启需要再 配置文件 中配置参数
- 重作日志 redo log：记录对 InnoDB表 的写操作，不是 SQL 级别，而是物理级别
  - 持久化是写到内存中`redo log buffer`，之后通过 `fsync` 写入磁盘
  - 写入磁盘的时机：
    - `redo log buffer` 容量消耗一半左右
    - 事务提交时
    - 后台线程
      - 正常关闭服务时
      - 触发checkpoint规则：环形写位置`write_pos`追上 擦除位置`checkpoint`
- 回滚日志 undo log：记录数据被修改前的值



bin log 和 redo log：

- **记录范围**：bin log 会记录所有存储引擎的日志，而 redo log 只记 InnoDB 存储引擎的日志。
- **记录内容**：bin log 记录逻辑修改。而 redo log 记录的物理修改。
- **写入时间**：bin log 仅在事务提交前进行提交一次。而在事务进行的过程中，却不断写入 redo log 中。
- **写入方式**：bin log 是追加写入，不会覆盖已经写的文件。redo log 是循环写入和擦除。



MySQL 在执行更新语句的时候，在服务层进行语句的解析和执行，在引擎层进行数据的提取和存储；同时在服务层对 binlog 进行写入，在 引擎层 InnoDB 内进行 redo log 的写入。

redo log 将事务的提交操作（事务完成后）分为两个阶段执行：（只提交一次无法保证两者的一致性）

-  binlog 写入之前`prepare`状态的写入
-  binlog 写入之后`commit`状态的写入



### SQL 优化



慢 SQL：超过 1 s

考虑维度：

- IO 成本：数据量上避免用 `*`，数据从哪里读（通过索引查询，尽量避免回表）
- CPU 成本：避免复杂的查询条件

如何定位慢 SQL：

- 慢查询日志
- 服务监控



SQL 优化：

- 避免不必要的列（只查需要的列，避免`*`）
- 分页优化（offset + limit 有性能问题，数据库需要扫描 offset + limit 行的数据）
  - 延迟关联：适用于需要从多个表中获取数据且主表行数较多的情况。它首先从索引表中检索出需要的行 ID（这里还是通过 offset + limit），然后再根据这些 ID 去关联其他的表获取详细信息。（这个方式减少了 JION 操作涉及的字段）
  - 书签：记住上次查询最后一行的值，避免扫描大量不需要的行
- 索引优化
  - 利用覆盖索引：要尽量使查的字段叶子节点都有，避免回表查询。（可以通过添加联合索引实现）
  - 正确使用联合索引：创建的时候区分度大（重复小）的字段排前面，使用的时候遵循最左匹配原则（不遵循索引会失效）
  - 适当使用前缀索引：前缀索引可以降低索引空间占用，提高查询效率。比如邮箱后面几位都是类似的，适合用。
  - 主键索引最好自增且长度小一点：自增使得新增数据是追加，而不用页分裂。长度小可以让二级索引的子结点小，节省空间占用。
  - 索引设置非空：空会让优化器难以优化，同时还占用物理空间。
  - **防止索引失效：**
    - 避免使用 `!=`和 `<>`：这两个操作符会导致无法只用索引，可以分成 `> or <` 来实现
    - 避免where子句中索引使用函数运算：会导致索引失效，因为数据库需要对每列应用函数再进行比较。
    - 避免where子句中 or 前后一个是索引列，一个不是索引列。
    - 避免模糊查询时候有通配符在最左侧。
- JOIN 优化
  - 优化子查询：使用 JOIN 代替子查询
  - 小表驱动大表：
  - 适当增加冗余字段：高频查询场景下，通过增加冗余字段避免 JOIN 操作。
  - 避免 join 太多的表：可以分成多次简单查询，然后再应用层组合
- 排序优化
  - 利用索引扫描做排序：根据排序需求设置索引
- UNION 优化
  - 条件下推：将 where 子句推到 union 的各个子查询中
  - UNION ALL 代替 UNION



explain 是 MySQL 提供的一个用于查看查询执行计划的工具，可以帮助我们分析查询语句的性能瓶颈，找出慢 SQL 的原因。

- type：表示 MySQL 在表中找到所需行的方式，性能从最优到最差分别为：system > const > eq_ref > ref > range > index > ALL
- key：实际使用的索引
- key_len：决定使用的索引长度
- rows：估算需要扫描的行数（可以用来粗略count()）



### 索引



- 功能分类
  - 主键索引：主键唯一且非空
  - 唯一索引：保证唯一但允许空值
  - 普通索引：加速查询
  - 全文索引：特定于文本数据的索引，提高文本搜索效率
- 数据结构
  - B+ 树索引：适合范围查询
  - 哈希索引：MEMORY 支持的索引，类似 HashMap，通过拉链法解决冲突。
    - 除了适合 = 和 in 查询，其他（范围查询、排序、模糊查询等）没啥优势。
- 存储位置
  - 聚簇索引：叶子结点保存了所有列信息
  - 非聚簇索引：叶子节点只包含索引值和主键值，如果查询包含其他字段，还需要回表



索引就像目录，能够帮助我们更快找到内容。同时，通过索引能够较少 IO 操作，且其时间复杂度为 O(logn).

可以没有索引，没有就直接全表扫描。



创建索引的注意点：

- 选择合适的字段：
  - 经常作为查询、排序、分组的列
  - 区分度高的字段（重复少）
  - 更新少的字段
- 避免过多索引
- 利用前缀索引和联合索引：字符串类型的列可以考虑前缀索引。联合索引要将常用的过滤条件放在前面。



索引不适合：数据表小、频繁更新的字段。

索引不是越多越好：占用磁盘空间；降低更新表的效率，因为不仅要更新数据还要更新 B+ 树。



为了减少 IO 次数，所以用 B树 这种结构，矮胖型，而不是二叉树那种，那种一次能读取的内容太少了。

B+ 树更进一步，非叶子节点只有索引，更加矮胖，减少 IO 次数。

**B+ 树的优势：**高效的磁盘 IO；支持范围查询；查询性能稳定，O(logn)



在 InnoDB 存储引擎中，B+树的高度一般为 2-4 层，就可以满足千万级数据的存储。查找数据的时候，**一次页的查找代表一次 IO**，当我们通过主键索引查询的时候，最多只需要 2-4 次 IO 就可以了。

页 16KB，假设主键 8KB，指针 6KB，则非叶子结点能存 16 * 1024 / 14 = 1170 条索引。

假设叶子节点能存 16 条数据，则树深为 2 时，能存 1170 * 16 = 18720 条数据。树深为 3 时，能存 1170 * 1170 * 16 = 21902400 条数据，已经是千万级别。



- InnoDB 采用的是聚簇索引，如果没有显式定义主键，InnoDB 会选择一个唯一的非空列作为隐式的聚簇索引；如果这样的列也不存在，InnoDB 会自动生成一个隐藏的行 ID 作为聚簇索引。
- MyISAM 采用的是非聚簇索引，表数据存储在一个地方，而索引存储在另一个地方，索引指向数据行的物理位置。



**回表**：如果查询的数据不在二级索引里，就需要先在二级索引找到主键值，需要去聚簇索引中获得数据行。

**覆盖索引**：一个索引包含了查询语句所需的所有数据，避免回表。

**最左前缀原则**：使用联合索引（即包含多列的索引）时，查询条件**从索引的最左列开始并且不跳过中间的列**。

``` sql
 -- 联合索引 ABC，这个还是会走索引的
 A=1 AND B IN (2, 3) AND C>3
 -- 会走索引，但不是定位到精确行，只是用来缩小范围
 a=1,c=1
 -- 不走索引，a都没了怎么走
 b=1,c=1
 -- 会走索引，精确定位
 a=1,c=1,b=1
 -- 不会走索引
 c = 5;
```



索引下推：优化数据查询，二级索引查询时，找到二级索引1 后不回表判断。交给存储引擎进行判断。



### 锁



锁的分类：

- 锁粒度：
  - 表锁
  - 页锁
  - 行锁
- 兼容性：
  - 共享锁（读锁）
  - 排它锁（写锁）
- 加锁机制：
  - 乐观锁：提交更新的时候才检查（通过版本号或者时间戳，事务 + where 子句实现）
  - 悲观锁：主动锁定数据（行锁、表锁）
- 锁模式：
  - 记录锁：直接锁定某行数据
    - 使用唯一性索引进行等值查询且匹配到数据时候，就会将其锁定
  - 间隙锁：锁定某些间隙区间的，左开右开
    - 使用等值查询或者范围查询，并且没有命中，就会将对应的间隙区间锁定
  - 临键锁：间隙锁加上它右边的记录组成的**左开右闭区间**，即间隙锁和记录锁的组合（**默认行锁类型**）
    - 使用范围查询，并且命中了部分记录，此时锁住的就是临键区间
    - 当使用唯一性索引，等值查询匹配到一条记录的时候，临键锁会退化成记录锁；没有匹配到任何记录的时候，退化成间隙锁。
  - 意向锁：**表级锁**，解决的是表锁和行锁共存的问题。
    - 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；
    - 在使用 InnoDB 引擎的表里对某些记录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；
    - **意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（*lock tables ... read*）和独占表锁（*lock tables ... write*）发生冲突。**
    - 表锁和行锁是满足读读共享、读写互斥、写写互斥的。
    - **意向锁的目的是为了快速判断表里是否有记录被加锁**。
  - 插入意向锁：插入一条记录时需要判断一下插入位置是不是被别的事务加了间隙锁，属于特殊的间隙锁。



### 事务



四个基本特性（ACID）：

- **原子性 Atomicity：**要么全部完成，要么全部不完成。undo log 回滚日志来保证的。
- **一致性 Consistency：**操作前后，数据满足完整性约束。通过 持久性 + 原子性 + 隔离性 来保证；
- **隔离性 Isolation：**每个事务都有一个完整的数据空间，对其他并发事务是隔离的。MVCC或锁机制来保证的。**（重点）**
- **持久性 Durability：**事务结束后，数据修改是永久的。 redo log 重做日志来保证的。



隔离级别：

- **读未提交**：指一个事务还没提交时，它做的变更就能被其他事务看到；（脏读、不可重复度、幻读）
- **读提交**：指一个事务提交之后，它做的变更才能被其他事务看到；（不可重复读、幻读）
  - 每次读取数据前都生成一个 ReadView（属于 MVCC 机制）
- **可重复读**：指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，**默认隔离级别**（幻读）
  - 第一次读操作时生成一个 ReadView
- **串行化**：会对记录加上**读写锁**，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；



MVCC 多版本并发控制，要用来解决数据库并发问题。

MVCC 允许读操作访问数据的一个旧版本快照，同时写操作创建一个新的版本，这样读写操作就可以并行进行，不必等待对方完成。

MVCC 是通过版本链和 ReadView 机制来实现的。

- 版本链：InnoDB 中，每行数据都有两个隐藏列：`DB_TRX_ID`事务ID；`DB_ROLL_PTR`指向旧版本的指针。
- ReadView 读视图：
  - 四个重要信息：
    - creator_trx_id：创建该 Read View 的事务的事务 id。
    - m_ids ：创建 Read View 时，当前数据库中「活跃事务」的**事务 id 列表**，**启动了但还没提交的事务**。
    - min_trx_id ：创建 Read View 时，当前数据库中「活跃事务」中事务 **id 最小的事务**，也就是 m_ids 的最小值。
    - max_trx_id ：这个并不是 m_ids 的最大值，而是**创建 Read View 时当前数据库中应该给下一个事务的 id 值**，也就是**全局事务中最大的事务 id 值 + 1**；
  - 假设 读的这行数据的写事务 ID 是 x
    - x < min_trx_id：可见
    - x >= max_trx_id：不可见
    - x not in m_ids：非活跃事务可见
    - x  in m_ids：活跃事务不可见



### 高可用/性能



主从集群：主机负责读写操作，从机只负责读操作。

分离读写操作：程序代码封装和中间件封装



主从复制的过程：

1. 主服务器的 bin log 记录所有修改数据库状态的语句
2. 主服务器的一个线程负责读取 bin log 发送给从服务器
3. 从服务器接收 bin log 后写入自己的中继日志 relay log
4. 从服务器的一个线程读取中继日志 relay log 并应用更改完成同步



主从同步延迟：主从不同步，存在延迟。比如当从服务器在进行 relay log 的 SQL 时间较长时候，容易积压主服务器新的 SQL

解决方法：

- 写操作后的读操作指定发给数据库主服务器（让从服务器安心同步，代码侵入性强）
- 读从机失败后再读一次主机（主机压力过大）
- 关键业务读写操作全部指向主机，非关键业务采用读写分离



分库：垂直分库 和 水平分库

分表：垂直分表 和 水平分表

短链接用了水平分表

水平分表的三种路由方式：

- **范围路由**：选取有序的数据列作为路由条件
- **Hash 路由**：选取一个或多个列的值进行 Hash 运算
- **配置路由**：用一张独立的路由配置表来记录路由信息



不停机扩容：

1. **在线双写，查询走老库**
2. **在线双写，查询走新库**
3. **旧库下线**



常用的分库分表中间件：sharingsphere、Mycat



### 运维

懒得看，看了也记不住。



### SQL 题











## RocketMQ



### 基础

消息队列的优点：

1. 解耦：生产者只负责生产消息，消费者只负责消费消息
2. 异步：可以将耗时任务放到队列中异步处理
3. 削峰：大量请求时，起到缓冲作用



为什么选择 RocketMQ：面向用户的 C 端系统，具有一定的并发量，对性能也有比较高的要求，所以选择了低延迟、吞吐量比较高，可用性比较好的 RocketMQ（阿里做的，有活跃的中文社区）



RocketMQ 在稳定性上值得信赖，经过双11的多次考验。缺点是没有实现 MQ 核心中的 JMS（Java Message Service）接口



消息队列有两种模型：**队列模型 **和 **发布/订阅模型**。

- 队列模型：一个队列可以存储多个生产者的消息，一个队列也可以有多个消费者，但是消费者之间是竞争关系，也就是说每条消息只能被一个消费者消费。（任务分发，请求-响应）
- 发布-订阅模式：消息的发送方称为发布者（Publisher），消息的接收方称为订阅者（Subscriber），服务端存放消息的容器称为主题（Topic），和 队列模式 的区别在于 一份消息数据是否可以被多次消费。（事件通知，实时广播）



RocketMQ 使用的消息模型是标准的发布-订阅模型。

RocketMQ 中，订阅者的概念是通过消费组（Consumer Group）来体现的。一条消息被 Consumer Group1 消费过，也会再给 Consumer Group2 消费。消费组中包含多个消费者，同一个组内的消费者是竞争消费的关系，每个消费者负责消费组内的一部分消息。

由于消息需要被不同的组进行多次消费，所以消费完的消息并不会立即被删除，这就需要 RocketMQ 为每个消费组在每个队列上维护一个消费位置（Consumer Offset）（相当于下标，之前的是消费过的，可以删除）

RocketMQ 消息的组成部分：Message, Topic, Tag(相当于子主题，可以没有), Group, MessageQueue， Offset

![img](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/nice-article/weixin-mianznxrocketmqessw-e470b972-f4ac-4b76-bcde-0df5d4765ca7.jpg)



消息消费模式有两种：**Clustering**（集群消费）和 **Broadcasting**（广播消费）。

默认情况下就是集群消费，这种模式下 **一个消费者组共同消费一个主题的多个队列，一个队列只会被一个消费者消费**，如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。

而广播消费消息会发给消费者组中的每一个消费者进行消费。



RocketMQ 的基本架构：（四个部分组成，为了保证高可用，一般每一部分都是集群部署的）

- NameServer，（邮局管理机构，发现）无状态服务器
  - 和 kafka 使用的 Zookeeper 类似
  - 功能：和 Broker 节点保持长连接；维护 Topic 的路由信息
- Broker，（邮局，存）消息存储和中转角色
  - 内部维护 消费者队列，用来存储信息的索引。真正存储信息的地方是 CommitLog 日志文件。
  - 单个 Broker 与 所有 Nameserver 保持长连接，定时将 Topic 同步到 NameServer（通信底层通过 Netty）
- Producer 生产者，（发信人，发）
  - 将消息通过负载均衡的方式发送到 Broker 集群
  - 有三种方式发送：同步，异步，单向（只发不收，异步是发送后不等待响应）
- Consumer 消费者，（收信人，收）
  - 支持 集群消费 和 广播消费：一个队列指会被同一个消费组中的 一个/所有 消费者消费
  - PUSH 和 PULL：前者是 被动消费，注册消费监听器，触发后才开始消费。后者是 主动消费，主动拉取到消息消费。



### 进阶





保证消息不丢失（以下三个地方会丢失）：

- 生产阶段：通过请求确认机制，保证消息的可靠传递
- 存储阶段：配置可靠性优先的 Broker 参数来避免因为宕机丢失消息（刷盘机制，持久化到日志）
- 消费阶段：消费完成再发送消费确认



处理消息重复：

- RocketMQ 选择确保消息投递成功，不丢失，但有可能造成消息重复。
- 处理消息重复，需要业务端自己保证。主要有以下两种方式：
  - 业务幂等：保证消费逻辑的幂等性
  - 消息去重：对重复消息无法消费（消息唯一编号，可以建立一个表保存消费记录）



处理消息积压（也就是提升消费能力）：

- 消费者扩容：当 MessageQueue > Consumer
- 消息迁移 Queue 扩容：当 MessageQueue <= Consumer，新建一个临时 Topic 扩容 Queue，然后消费者转发消息到 Queue，扩容消费者去消费，结束后恢复原状。



顺序消费的实现：

- 全局顺序消息：消除所有的并发处理，将 Topic 的读写队列数设置为 1，然后生产者和消费者的并发设置为 1
- 部分顺序消息：生产者把需要 顺序消费 的内容放到 同一个 MessageQueue 中，同时消费者按序处理，不能并发处理。



消息过滤的实现：

有两种方案：在 Broker 段按照 Consumer 的去重逻辑过滤；在 Consumer 端过滤。一般采用后者，实现简单。

消息过滤有三种方式：

1. 根据 Tag 过滤：简单高效
2. SQL 表达式过滤：更加灵活
3. Filter Server 过滤：最灵活，用户可以自定义函数过滤



延时消息：

RocketMQ 支持延时消息的，只需要在生产消息的时候设置消息的延时级别。

RocketMQ 实现延时消息的方式：临时存储 + 定时任务。Broker 收到延时消息先发送到 主题 (SCHEDULE_TOPIC_XXXX) 的响应时间段的 MessageQueue 中，然后通过定时任务轮询，到期后投递到目标 Topic



实现分布式消息事务：

半消息：Producer 发送给 Broker，但标记为 "暂时不可投递"  状态，需要 Producer 执行完 本地事务 二次确认后，Consumer 才能消费。

依赖半消息，可以实现分布式消息事务。关键在于二次确认以及消息回查。Broker 收到 Producer 段的二次确认才可消费，没收到则 回查 Producer。



死信队列：消息消费失败达到最大重试次数后，不丢弃消息，而是将消息加入到的一个特殊队列，用于处理死信消息。

死信消息特点：不会再被 Consumer 正常消费；有效期与正常消息相同，超时后自动删除。

死信队列特点：

- 和 消费者组 Consumer Group 一对一
- 消费者组 没有死信消息，则不会创建对应的死信队列
- 一个死信队列包含其对应消费者组的所有死信信息，不管该消息属于哪个 Topic



RocketMQ 的高可用主要是在体现在 Broker 的读和写的高可用，Broker 的高可用是通过 **集群** 和 **主从** 实现。主负责读和写，从只负责读。

生产者只能写入主，消费者可以从主或从读，不需要配置，当主不可用或者繁忙时，自动回到从。

发送端写的高可用：相同 Broker 名称，不同 bokerid 的机器组成 Broker 组。一个不可用可以切换另一个使用。





### 原理



RocketMQ 是一个分布式消息队列，消息队列 + 分布式系统 

RocketMQ 整体工作流程：

1. Broker 在启动的时候去向所有的 NameServer 注册，并保持长连接，每 30s 发送一次心跳
2. Producer 在发送消息的时候从 NameServer 获取 Broker 服务器地址，根据负载均衡算法选择一台服务器来发送消息
3. Conusmer 消费消息的时候同样从 NameServer 获取 Broker 地址，然后主动拉取消息来消费

![RocketMQ整体工作流程](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/nice-article/weixin-mianznxrocketmqessw-ec571bd4-fa24-4ada-87ab-f761a7dfdf3f.jpg)



RocketMQ 为什么不选择 Zookeeper 作为注册中心？

1. 基于可用性考虑：Zookeeper 关注 CAP 里面中的 CP，在选举的时候集群不可用。
2. 基于性能考虑：NameServer 实现轻量，Zookeeper 的写是不可拓展的。
3. 持久化机制：Zookeeper 对每一个写请求都会写日记 + 定期保存镜像，方案太重了，没有必要。
4. 消息发送应该弱依赖注册中心：生产者会缓存从 NameServer 获取到的 Broker 地址。 



Broker 保存数据：

- CommitLog：消息主体以及元数据的存储主体。
- ConsumeQueue：消息消费队列，引入的目的主要是提高消息消费的性能，作为消费消息的索引，保存 offset, size, tag.
- Indexfile：提供了一种可以通过 key 或时间区间来查询消息的方法。

总结：RocketMQ 采用的是混合型的存储结构，即为 Broker 单个实例下所有的队列共用一个日志数据文件（即为 CommitLog）来存储。

RocketMQ 使用 Broker 端的后台服务线程—ReputMessageService 不停地分发请求并异步构建 ConsumeQueue（逻辑消费队列）和 IndexFile（索引文件）数据。



RocketMQ 对文件的读写巧妙地利用了操作系统的一些高效文件读写方式——**PageCache、顺序读写、零拷贝**。

零拷贝比较常见的实现方式是**mmap**，这种机制在 Java 中是通过 MappedByteBuffer 实现的。

mmap 是让文件的内容直接映射到内存中的方法，减少了数据在内核空间和用户空间之间的复制次数



RocketMQ 提供了两种刷盘策略：

- 同步刷盘：消息到达 Broker 后，刷到 commitLog 后才返回成功消息。
- 异步刷盘：消息到达 Broker 后就返回成功消息，然后唤醒一个线程去持久化。



RocketMQ 中的负载均衡都在 Client 端完成：

- Producer 的负载均衡：索引递增随机取模
- Consumer 的负载均衡：
  - Consumer 将心跳包发送到 Broker，提供负载均衡的依据。
  - 实现核心类：RebalanceImpl

消息消费队列在同一消费组不同消费者之间的负载均衡，其核心设计理念是在一个消息消费队列在同一时间只允许被同一消费组内的一个消费者消费，一个消息消费者能同时消费多个消息队列。



RocketMQ 长轮询：Consumer 拉取消息，如果对应的 Queue 如果没有数据，Broker 不会立即返回，而是把 PullReuqest hold 起来，等待 queue 有了消息后，或者长轮询阻塞时间到了，再重新处理该 queue 上的所有 PullRequest。












# Others



**为什么重写equals()方法，就一定要重写 hashCode() 方法？**

如果你只重写了`equals()`方法而没有重写`hashCode()`方法，那么可能会出现两个相等的对象（根据你的`equals()`方法判断）**在哈希表中被视为不同的键**，这会导致一些不可预见的行为和错误。



Java中 :: 的作用

`::` 是Java 8引入的方法引用（Method Reference）的符号。方法引用允许你直接使用现有方法，而不是创建一个新的Lambda表达式。使用方法引用可以使代码更简洁、更易读。

``` java
list.forEach(s -> s.toUpperCase());
list.forEach(String::toUpperCase);
```





**基本数据类型（Primitive Data Types）和引用数据类型（Reference Data Types）**

1. **基本数据类型**：

   - 整数类型：byte、short、int、long
   - 浮点类型：float、double
   - 字符类型：char
   - 布尔类型：boolean

   这些类型存储的是实际的数据值，它们直接存储在内存中，因此通常称为"值类型"。基本数据类型具有固定的大小，不依赖于操作系统或Java虚拟机。

2. **引用数据类型**：

   - 类（Class）
   - 接口（Interface）
   - 数组（Array）

   引用数据类型是通过引用指向对象在堆内存中的存储位置。换句话说，它们存储的是对象的引用而不是对象本身。在Java中，创建对象时，实际的对象数据存储在堆内存中，而变量存储的是对象的引用，这个引用指向实际对象的内存地址。

**简而言之，基本数据类型存储的是实际的数据值，而引用数据类型存储的是对象的引用。**



**幂等**

**幂等性是指一个操作无论执行多少次，结果都是相同的。**在计算机科学中，特别是在网络通信和分布式系统中，幂等性是一个重要的概念，因为它可以确保在重试操作时不会产生意外的副作用或错误。





**Java 内存管理**

Java 内存区域和内存模型是理解 Java 内存管理的重要概念。以下是它们的基本介绍：

1. **Java 内存区域**： Java 虚拟机在运行时会将内存划分为不同的区域，每个区域都有自己的特定作用和生命周期。主要的内存区域包括：
   - **程序计数器（Program Counter Register）**：线程私有，用于指示当前线程执行的字节码指令位置。
   - **虚拟机栈（Java Virtual Machine Stacks）**：线程私有，包含栈帧（Stack Frame），每个方法调用都会创建一个栈帧，用于存储局部变量、操作数栈、动态链接、方法出口等信息。
   - **本地方法栈（Native Method Stack）**：线程私有，用于支持执行本地（Native）方法的栈。
   - **堆（Heap）**：被所有线程共享，用于存储对象实例和数组，是垃圾收集器管理的主要区域。
   - **方法区（Method Area）**：被所有线程共享，用于存储类的元信息、静态变量、常量等数据。
   - **运行时常量池（Runtime Constant Pool）**：方法区的一部分，用于存储编译时生成的常量，如字符串常量、类和方法的符号引用等。
2. **Java 内存模型**： Java 内存模型（Java Memory Model，JMM）定义了 Java 程序中多线程并发访问共享变量的行为规则，保证多线程程序在不同的平台上的一致性。主要包括以下几个方面：
   - **主内存与工作内存**：所有线程共享的内存区域称为主内存，每个线程有自己的工作内存，线程的操作都在工作内存中进行，然后通过主内存实现线程之间的通信。
   - **原子性**：对基本数据类型的读写操作具有原子性，但对于非 volatile 变量的读写操作不具备原子性。
   - **可见性**：如果一个线程修改了共享变量的值，其他线程能够立即看到修改后的值（前提是变量需要使用 volatile 关键字修饰或通过同步机制保证可见性）。
   - **有序性**：程序执行的顺序按照程序的顺序执行，但是多线程环境下，由于指令重排序等因素，可能导致程序的执行顺序出现变化。

Java 内存区域和内存模型是理解 Java 程序运行时内存管理和多线程并发的重要基础。对于开发者来说，理解这些概念有助于编写高效、安全的 Java 程序。



**Java 中常见的关键词及其作用**



1. **public**：表示公共的，可以被其他类访问。
2. **private**：表示私有的，只能在当前类中访问。
3. **protected**：表示受保护的，可以被同一包中的类访问，也可以被子类访问。
4. **static**：表示静态的，可以用来修饰变量、方法和代码块，静态成员属于类而不是对象，可以通过类名直接访问。
5. **final**：表示不可变的，可以用来修饰类、方法和变量。修饰类时表示类不可被继承，修饰方法时表示方法不可被重写，修饰变量时表示变量的值不可修改。
6. **abstract**：表示抽象的，可以用来修饰类和方法。修饰类时表示类为抽象类，不能被实例化，修饰方法时表示方法为抽象方法，只有声明而没有实现，需要子类实现。
7. **interface**：表示接口，可以用来定义一组抽象方法和常量，实现多继承和规范类的行为。
8. **extends**：表示继承，用来建立类与类之间的继承关系。
9. **implements**：表示实现接口，用来建立类与接口之间的实现关系。
10. **this**：表示当前对象的引用，用来访问当前对象的成员变量和方法。
11. **super**：表示父类对象的引用，用来访问父类的成员变量和方法。
12. **new**：用来创建对象实例。
13. **return**：用来从方法中返回值。
14. **void**：表示无返回值的方法。
15. **if、else、switch、case**：条件语句，用来根据条件执行不同的代码块。
16. **for、while、do-while**：循环语句，用来重复执行一段代码。
17. **try、catch、finally**：异常处理语句，用来捕获和处理异常。
18. **throw、throws**：用来抛出异常和声明方法可能抛出的异常。
19. **synchronized**：同步关键字，用来实现线程同步。
20. **volatile**：用来修饰变量，保证多线程环境下的可见性和有序性。





**常用字符编码所占字节数？**

`utf8` :英文占 1 字节，中文占 3 字节，`unicode`：任何字符都占 2 个字节，`gbk`：英文占 1 字节，中文占 2 字节。



**常见的设计模式：**

1. **单例模式（Singleton Pattern）**：确保一个类只有一个实例，并提供一个全局访问点来访问该实例。
2. **工厂模式（Factory Pattern）**：定义一个用于创建对象的接口，但是由子类决定实例化哪个类。
3. **观察者模式（Observer Pattern）**：定义对象之间的一对多依赖关系，使得当一个对象状态改变时，其所有依赖对象都会得到通知并自动更新。
4. **策略模式（Strategy Pattern）**：定义一系列算法，并将每个算法封装起来，使它们可以相互替换。策略模式使得算法可以独立于使用它们的客户端而变化。
5. **装饰器模式（Decorator Pattern）**：动态地给一个对象添加一些额外的职责，就增加功能来说，装饰器模式比生成子类更灵活。
6. **适配器模式（Adapter Pattern）**：将一个类的接口转换成客户希望的另一个接口，使得原本因接口不匹配而无法一起工作的两个类可以一起工作。
7. **代理模式（Proxy Pattern）**：为其他对象提供一种代理以控制对这个对象的访问。代理对象在客户端和目标对象之间起到中介作用，可以用来增加额外的功能。
8. **模板方法模式（Template Method Pattern）**：定义一个算法的框架，将其中的某些步骤延迟到子类中实现。模板方法使得子类可以在不改变算法结构的情况下重新定义算法的某些步骤。



CAP 理论：

在一个分布式系统中，一致性（Consistency）、可用性（Availability）和分区容错性（Partition Tolerance）这三个属性无法同时得到满足，最多只能同时满足其中的两个，必须牺牲其中一个。

- 一致性（Consistency）：所有节点看到的数据是一致的。这意味着在进行数据读取操作时，无论请求发送到哪个节点，用户都能得到最新、一致的数据。
- 可用性（Availability）：系统提供的服务必须一直处于可用状态，即使系统中的某些节点出现故障，也能保证用户的请求得到响应。
- 分区容错性（Partition Tolerance）：系统在面临网络分区（网络中的某些节点无法相互通信）的情况下仍然能够正常运行。

cap理论中三者不能100%满足，而p又是分布式系统必须的，所以要在ac中取舍一个降级。根据不同场景来取舍a或者c
